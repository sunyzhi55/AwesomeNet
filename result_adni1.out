Namespace(batch_size=8, drop_ratio=0, name='experiment_name', cli_dir='./csv/ADNI_Clinical.csv', model='AweSomeNet', seed=42, n_splits=5, data_parallel=0, mri_dir='/data3/wangchangmiao/shenxy/ADNI/ADNI1/MRI', pet_dir='/data3/wangchangmiao/shenxy/ADNI/ADNI1/PET', csv_file='./csv/ADNI1_match.csv', best_result_model_path='best_result.pth', device='cuda:0', workers=0, init_type='kaiming', init_gain=0.02, class_num=2, m=0.999, checkpoints_dir='./checkpoints', epochs=200, print_freq=1, save_epoch_freq=20, beta1=0.5, lr=0.001, lr_decay=0.95, lr_policy='cosine', interpolation_lambda=20.0, logs='./logs.txt')
exp:AweSomeNet  seed -> 42
Fold 1/5
[DEBUG] Observer init successfully, program start @2025-04-07_21-44

The name of model will run <class 'Net.AweNet.AweSomeNet'>
Use model : {'Name': 'AweSomeNet', 'Model': <class 'Net.AweNet.AweSomeNet'>, 'dataset': <class 'Dataset.MriPetCliDataset'>, 'shape': (96, 128, 96), 'Loss': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Lr': 0.001, 'Run': <function run_main_for_awesome_net at 0x7f274773b790>, 'Scheduler': <function get_scheduler at 0x7f274c7ad670>}


===============================================

model parameters: 17357958

===============================================

Prepare completed for fold 1! Launch training!ðŸš€
start training
Epoch: 1/200
Training Epoch 1, LR 0.001000:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 1, LR 0.001000:   6%|â–Œ         | 1/18 [00:04<01:17,  4.58s/batch]Training Epoch 1, LR 0.001000:  11%|â–ˆ         | 2/18 [00:04<00:33,  2.12s/batch]Training Epoch 1, LR 0.001000:  17%|â–ˆâ–‹        | 3/18 [00:05<00:20,  1.33s/batch]Training Epoch 1, LR 0.001000:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:13,  1.04batch/s]Training Epoch 1, LR 0.001000:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:15,  1.21s/batch]Training Epoch 1, LR 0.001000:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.07batch/s]Training Epoch 1, LR 0.001000:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.31batch/s]Training Epoch 1, LR 0.001000:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.54batch/s]Training Epoch 1, LR 0.001000:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.16s/batch]Training Epoch 1, LR 0.001000:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.09batch/s]Training Epoch 1, LR 0.001000:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.31batch/s]Training Epoch 1, LR 0.001000:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.54batch/s]Training Epoch 1, LR 0.001000:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.13s/batch]Training Epoch 1, LR 0.001000:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.10batch/s]Training Epoch 1, LR 0.001000:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.32batch/s]Training Epoch 1, LR 0.001000:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.54batch/s]Training Epoch 1, LR 0.001000:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.06s/batch]Training Epoch 1, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 1, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 1:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.85s/batch]Evaluating Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.68s/batch]Evaluating Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.01s/batch]Evaluating Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.49batch/s]Evaluating Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.11s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [1/200]:, train_loss=0.068, 
train_confusionMatrix:
tensor([[88,  2],
        [51,  3]], device='cuda:0')
train_accuracy=0.6319444179534912, 
train_recall=0.0555555559694767, 
train_precision=0.6000000238418579, 
train_specificity=0.9777777791023254, 
train_balance_acc=0.5166666507720947,
 train_f1_score=0.10169491171836853,
 train_auc=0.4273662567138672

Epoch [1/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[ 0, 19],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=1.0, 
eval_precision=0.40625, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5777778029441833,
 eval_auc=0.5506073236465454


Best model saved to ././checkpoints_2025-04-07_21-44/AweSomeNet_best_model_fold1.pth


Epoch: 2/200
Training Epoch 2, LR 0.000976:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 2, LR 0.000976:   6%|â–Œ         | 1/18 [00:03<01:05,  3.85s/batch]Training Epoch 2, LR 0.000976:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 2, LR 0.000976:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 2, LR 0.000976:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 2, LR 0.000976:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.41s/batch]Training Epoch 2, LR 0.000976:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.06s/batch]Training Epoch 2, LR 0.000976:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.18batch/s]Training Epoch 2, LR 0.000976:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.42batch/s]Training Epoch 2, LR 0.000976:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.18s/batch]Training Epoch 2, LR 0.000976:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.06batch/s]Training Epoch 2, LR 0.000976:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.29batch/s]Training Epoch 2, LR 0.000976:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.51batch/s]Training Epoch 2, LR 0.000976:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.14s/batch]Training Epoch 2, LR 0.000976:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.09batch/s]Training Epoch 2, LR 0.000976:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.32batch/s]Training Epoch 2, LR 0.000976:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.53batch/s]Training Epoch 2, LR 0.000976:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 2, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 2, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 2:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 2:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.12s/batch]Evaluating Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.78s/batch]Evaluating Epoch 2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.04s/batch]Evaluating Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.45batch/s]Evaluating Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.16s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [2/200]:, train_loss=0.066, 
train_confusionMatrix:
tensor([[89,  0],
        [55,  0]], device='cuda:0')
train_accuracy=0.6180555820465088, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=1.0, 
train_balance_acc=0.5,
 train_f1_score=0.0,
 train_auc=0.5814095735549927

Epoch [2/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[19,  0],
        [13,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.38461536169052124


Best model saved to ././checkpoints_2025-04-07_21-44/AweSomeNet_best_model_fold1.pth


Epoch: 3/200
Training Epoch 3, LR 0.000905:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 3, LR 0.000905:   6%|â–Œ         | 1/18 [00:04<01:09,  4.07s/batch]Training Epoch 3, LR 0.000905:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.92s/batch]Training Epoch 3, LR 0.000905:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.23s/batch]Training Epoch 3, LR 0.000905:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 3, LR 0.000905:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.41s/batch]Training Epoch 3, LR 0.000905:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:14,  1.17s/batch]Training Epoch 3, LR 0.000905:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:10,  1.09batch/s]Training Epoch 3, LR 0.000905:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:09<00:07,  1.33batch/s]Training Epoch 3, LR 0.000905:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.26s/batch]Training Epoch 3, LR 0.000905:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.00batch/s]Training Epoch 3, LR 0.000905:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.23batch/s]Training Epoch 3, LR 0.000905:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.45batch/s]Training Epoch 3, LR 0.000905:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:15<00:06,  1.25s/batch]Training Epoch 3, LR 0.000905:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.00batch/s]Training Epoch 3, LR 0.000905:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:16<00:02,  1.22batch/s]Training Epoch 3, LR 0.000905:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.44batch/s]Training Epoch 3, LR 0.000905:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.24s/batch]Training Epoch 3, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.02batch/s]Training Epoch 3, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.08s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 3:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 3:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.94s/batch]Evaluating Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.72s/batch]Evaluating Epoch 3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.00s/batch]Evaluating Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.49batch/s]Evaluating Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.12s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [3/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[89,  1],
        [53,  1]], device='cuda:0')
train_accuracy=0.625, 
train_recall=0.018518518656492233, 
train_precision=0.5, 
train_specificity=0.9888888597488403, 
train_balance_acc=0.5037037134170532,
 train_f1_score=0.0357142873108387,
 train_auc=0.5827159881591797

Epoch [3/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[19,  0],
        [13,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.38866397738456726


Epoch: 4/200
Training Epoch 4, LR 0.000796:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 4, LR 0.000796:   6%|â–Œ         | 1/18 [00:03<01:07,  3.95s/batch]Training Epoch 4, LR 0.000796:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.86s/batch]Training Epoch 4, LR 0.000796:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.20s/batch]Training Epoch 4, LR 0.000796:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 4, LR 0.000796:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:20,  1.57s/batch]Training Epoch 4, LR 0.000796:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:14,  1.17s/batch]Training Epoch 4, LR 0.000796:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:10,  1.08batch/s]Training Epoch 4, LR 0.000796:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:09<00:07,  1.32batch/s]Training Epoch 4, LR 0.000796:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.19s/batch]Training Epoch 4, LR 0.000796:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.06batch/s]Training Epoch 4, LR 0.000796:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.28batch/s]Training Epoch 4, LR 0.000796:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.50batch/s]Training Epoch 4, LR 0.000796:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.13s/batch]Training Epoch 4, LR 0.000796:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.10batch/s]Training Epoch 4, LR 0.000796:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.32batch/s]Training Epoch 4, LR 0.000796:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.54batch/s]Training Epoch 4, LR 0.000796:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.27s/batch]Training Epoch 4, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.01s/batch]Training Epoch 4, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 4:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 4:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.20s/batch]Evaluating Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.82s/batch]Evaluating Epoch 4:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.06s/batch]Evaluating Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.43batch/s]Evaluating Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.18s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [4/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[86,  3],
        [55,  0]], device='cuda:0')
train_accuracy=0.5972222089767456, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=0.966292142868042, 
train_balance_acc=0.483146071434021,
 train_f1_score=0.0,
 train_auc=0.5922369956970215

Epoch [4/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[16,  4],
        [ 7,  5]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.4166666567325592, 
eval_precision=0.5555555820465088, 
eval_specificity=0.800000011920929, 
eval_balance_acc=0.6083333492279053,
 eval_f1_score=0.4761904776096344,
 eval_auc=0.5625


Best model saved to ././checkpoints_2025-04-07_21-44/AweSomeNet_best_model_fold1.pth


Epoch: 5/200
Training Epoch 5, LR 0.000658:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 5, LR 0.000658:   6%|â–Œ         | 1/18 [00:04<01:11,  4.18s/batch]Training Epoch 5, LR 0.000658:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.96s/batch]Training Epoch 5, LR 0.000658:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.25s/batch]Training Epoch 5, LR 0.000658:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.09batch/s]Training Epoch 5, LR 0.000658:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.38s/batch]Training Epoch 5, LR 0.000658:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 5, LR 0.000658:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 5, LR 0.000658:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.43batch/s]Training Epoch 5, LR 0.000658:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.23s/batch]Training Epoch 5, LR 0.000658:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.03batch/s]Training Epoch 5, LR 0.000658:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.25batch/s]Training Epoch 5, LR 0.000658:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.47batch/s]Training Epoch 5, LR 0.000658:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.08s/batch]Training Epoch 5, LR 0.000658:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 5, LR 0.000658:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.36batch/s]Training Epoch 5, LR 0.000658:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.58batch/s]Training Epoch 5, LR 0.000658:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:00,  1.01batch/s]Training Epoch 5, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.22batch/s]Training Epoch 5, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 5:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 5:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.57s/batch]Evaluating Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 5:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [5/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[87,  2],
        [49,  6]], device='cuda:0')
train_accuracy=0.6458333134651184, 
train_recall=0.1090909093618393, 
train_precision=0.75, 
train_specificity=0.9775280952453613, 
train_balance_acc=0.5433095097541809,
 train_f1_score=0.190476194024086,
 train_auc=0.6377936601638794

Epoch [5/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[16,  3],
        [10,  3]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.23076923191547394, 
eval_precision=0.5, 
eval_specificity=0.8421052694320679, 
eval_balance_acc=0.5364372730255127,
 eval_f1_score=0.31578946113586426,
 eval_auc=0.5991902947425842


Epoch: 6/200
Training Epoch 6, LR 0.000505:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 6, LR 0.000505:   6%|â–Œ         | 1/18 [00:03<01:06,  3.89s/batch]Training Epoch 6, LR 0.000505:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 6, LR 0.000505:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 6, LR 0.000505:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 6, LR 0.000505:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 6, LR 0.000505:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 6, LR 0.000505:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.22batch/s]Training Epoch 6, LR 0.000505:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 6, LR 0.000505:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:11,  1.23s/batch]Training Epoch 6, LR 0.000505:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.03batch/s]Training Epoch 6, LR 0.000505:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.25batch/s]Training Epoch 6, LR 0.000505:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.47batch/s]Training Epoch 6, LR 0.000505:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.14s/batch]Training Epoch 6, LR 0.000505:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.09batch/s]Training Epoch 6, LR 0.000505:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.31batch/s]Training Epoch 6, LR 0.000505:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.53batch/s]Training Epoch 6, LR 0.000505:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.07s/batch]Training Epoch 6, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.15batch/s]Training Epoch 6, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 6:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 6:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:13,  4.40s/batch]Evaluating Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.90s/batch]Evaluating Epoch 6:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.11s/batch]Evaluating Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.37batch/s]Evaluating Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.23s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [6/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[82,  7],
        [42, 13]], device='cuda:0')
train_accuracy=0.6597222089767456, 
train_recall=0.23636363446712494, 
train_precision=0.6499999761581421, 
train_specificity=0.9213483333587646, 
train_balance_acc=0.5788559913635254,
 train_f1_score=0.3466666638851166,
 train_auc=0.680490255355835

Epoch [6/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[11,  9],
        [ 3,  9]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.75, 
eval_precision=0.5, 
eval_specificity=0.550000011920929, 
eval_balance_acc=0.6499999761581421,
 eval_f1_score=0.6000000238418579,
 eval_auc=0.6041666269302368


Epoch: 7/200
Training Epoch 7, LR 0.000352:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 7, LR 0.000352:   6%|â–Œ         | 1/18 [00:03<01:03,  3.76s/batch]Training Epoch 7, LR 0.000352:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 7, LR 0.000352:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 7, LR 0.000352:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.17batch/s]Training Epoch 7, LR 0.000352:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:20,  1.54s/batch]Training Epoch 7, LR 0.000352:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.16s/batch]Training Epoch 7, LR 0.000352:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:10,  1.10batch/s]Training Epoch 7, LR 0.000352:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.34batch/s]Training Epoch 7, LR 0.000352:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:12<00:13,  1.49s/batch]Training Epoch 7, LR 0.000352:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:12<00:09,  1.15s/batch]Training Epoch 7, LR 0.000352:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:06,  1.08batch/s]Training Epoch 7, LR 0.000352:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:13<00:04,  1.30batch/s]Training Epoch 7, LR 0.000352:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:15<00:06,  1.24s/batch]Training Epoch 7, LR 0.000352:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.02batch/s]Training Epoch 7, LR 0.000352:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:16<00:02,  1.23batch/s]Training Epoch 7, LR 0.000352:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.45batch/s]Training Epoch 7, LR 0.000352:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.14s/batch]Training Epoch 7, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.09batch/s]Training Epoch 7, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.08s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 7:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 7:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.80s/batch]Evaluating Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.66s/batch]Evaluating Epoch 7:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.03batch/s]Evaluating Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.54batch/s]Evaluating Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.08s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [7/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[83,  6],
        [43, 12]], device='cuda:0')
train_accuracy=0.6597222089767456, 
train_recall=0.2181818187236786, 
train_precision=0.6666666865348816, 
train_specificity=0.932584285736084, 
train_balance_acc=0.5753830671310425,
 train_f1_score=0.3287671208381653,
 train_auc=0.6933605670928955

Epoch [7/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[21,  0],
        [10,  1]], device='cuda:0')
eval_accuracy=0.6875, 
eval_recall=0.09090909361839294, 
eval_precision=1.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5454545617103577,
 eval_f1_score=0.1666666716337204,
 eval_auc=0.6363636255264282


Best model saved to ././checkpoints_2025-04-07_21-44/AweSomeNet_best_model_fold1.pth


Epoch: 8/200
Training Epoch 8, LR 0.000214:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 8, LR 0.000214:   6%|â–Œ         | 1/18 [00:03<01:07,  3.99s/batch]Training Epoch 8, LR 0.000214:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.88s/batch]Training Epoch 8, LR 0.000214:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 8, LR 0.000214:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 8, LR 0.000214:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:19,  1.47s/batch]Training Epoch 8, LR 0.000214:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.11s/batch]Training Epoch 8, LR 0.000214:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.14batch/s]Training Epoch 8, LR 0.000214:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.37batch/s]Training Epoch 8, LR 0.000214:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.28s/batch]Training Epoch 8, LR 0.000214:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:08,  1.01s/batch]Training Epoch 8, LR 0.000214:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.21batch/s]Training Epoch 8, LR 0.000214:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.43batch/s]Training Epoch 8, LR 0.000214:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.13s/batch]Training Epoch 8, LR 0.000214:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.10batch/s]Training Epoch 8, LR 0.000214:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.32batch/s]Training Epoch 8, LR 0.000214:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.54batch/s]Training Epoch 8, LR 0.000214:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 8, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.09batch/s]Training Epoch 8, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 8:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 8:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  4.00s/batch]Evaluating Epoch 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.74s/batch]Evaluating Epoch 8:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.01s/batch]Evaluating Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.48batch/s]Evaluating Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.13s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [8/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[82,  7],
        [39, 16]], device='cuda:0')
train_accuracy=0.6805555820465088, 
train_recall=0.290909081697464, 
train_precision=0.695652186870575, 
train_specificity=0.9213483333587646, 
train_balance_acc=0.6061286926269531,
 train_f1_score=0.41025641560554504,
 train_auc=0.6907048225402832

Epoch [8/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[13,  8],
        [ 7,  4]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.3636363744735718, 
eval_precision=0.3333333432674408, 
eval_specificity=0.6190476417541504, 
eval_balance_acc=0.4913420081138611,
 eval_f1_score=0.3478260934352875,
 eval_auc=0.6190476417541504


Epoch: 9/200
Training Epoch 9, LR 0.000105:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 9, LR 0.000105:   6%|â–Œ         | 1/18 [00:03<01:05,  3.87s/batch]Training Epoch 9, LR 0.000105:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 9, LR 0.000105:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 9, LR 0.000105:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 9, LR 0.000105:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:19,  1.48s/batch]Training Epoch 9, LR 0.000105:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.12s/batch]Training Epoch 9, LR 0.000105:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.13batch/s]Training Epoch 9, LR 0.000105:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.36batch/s]Training Epoch 9, LR 0.000105:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.22s/batch]Training Epoch 9, LR 0.000105:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.03batch/s]Training Epoch 9, LR 0.000105:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.26batch/s]Training Epoch 9, LR 0.000105:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.48batch/s]Training Epoch 9, LR 0.000105:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:06,  1.20s/batch]Training Epoch 9, LR 0.000105:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.03batch/s]Training Epoch 9, LR 0.000105:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.25batch/s]Training Epoch 9, LR 0.000105:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.47batch/s]Training Epoch 9, LR 0.000105:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.22s/batch]Training Epoch 9, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.09s/batch]Training Epoch 9, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 9:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 9:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.05s/batch]Evaluating Epoch 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.86s/batch]Evaluating Epoch 9:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.08s/batch]Evaluating Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.40batch/s]Evaluating Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.19s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [9/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[85,  5],
        [38, 16]], device='cuda:0')
train_accuracy=0.7013888955116272, 
train_recall=0.29629629850387573, 
train_precision=0.761904776096344, 
train_specificity=0.9444444179534912, 
train_balance_acc=0.6203703880310059,
 train_f1_score=0.4266666769981384,
 train_auc=0.760905385017395

Epoch [9/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[15,  5],
        [ 9,  3]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.25, 
eval_precision=0.375, 
eval_specificity=0.75, 
eval_balance_acc=0.5,
 eval_f1_score=0.30000001192092896,
 eval_auc=0.6791666746139526


Epoch: 10/200
Training Epoch 10, LR 0.000034:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 10, LR 0.000034:   6%|â–Œ         | 1/18 [00:03<01:07,  4.00s/batch]Training Epoch 10, LR 0.000034:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.89s/batch]Training Epoch 10, LR 0.000034:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 10, LR 0.000034:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 10, LR 0.000034:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 10, LR 0.000034:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.07s/batch]Training Epoch 10, LR 0.000034:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.17batch/s]Training Epoch 10, LR 0.000034:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.41batch/s]Training Epoch 10, LR 0.000034:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.11s/batch]Training Epoch 10, LR 0.000034:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:09,  1.13s/batch]Training Epoch 10, LR 0.000034:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:06,  1.10batch/s]Training Epoch 10, LR 0.000034:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.32batch/s]Training Epoch 10, LR 0.000034:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.04s/batch]Training Epoch 10, LR 0.000034:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.04batch/s]Training Epoch 10, LR 0.000034:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.26batch/s]Training Epoch 10, LR 0.000034:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.47batch/s]Training Epoch 10, LR 0.000034:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:00,  1.02batch/s]Training Epoch 10, LR 0.000034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.02s/batch]Training Epoch 10, LR 0.000034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 10:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 10:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.86s/batch]Evaluating Epoch 10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.71s/batch]Evaluating Epoch 10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.00batch/s]Evaluating Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.50batch/s]Evaluating Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.10s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [10/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[83,  6],
        [42, 13]], device='cuda:0')
train_accuracy=0.6666666865348816, 
train_recall=0.23636363446712494, 
train_precision=0.6842105388641357, 
train_specificity=0.932584285736084, 
train_balance_acc=0.5844739675521851,
 train_f1_score=0.3513513505458832,
 train_auc=0.7262512445449829

Epoch [10/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[14,  5],
        [10,  3]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.23076923191547394, 
eval_precision=0.375, 
eval_specificity=0.7368420958518982, 
eval_balance_acc=0.48380565643310547,
 eval_f1_score=0.2857142984867096,
 eval_auc=0.7085020542144775


Epoch: 11/200
Training Epoch 11, LR 0.001000:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 11, LR 0.001000:   6%|â–Œ         | 1/18 [00:04<01:11,  4.19s/batch]Training Epoch 11, LR 0.001000:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.96s/batch]Training Epoch 11, LR 0.001000:  17%|â–ˆâ–‹        | 3/18 [00:05<00:18,  1.25s/batch]Training Epoch 11, LR 0.001000:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.09batch/s]Training Epoch 11, LR 0.001000:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:19,  1.47s/batch]Training Epoch 11, LR 0.001000:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.11s/batch]Training Epoch 11, LR 0.001000:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.13batch/s]Training Epoch 11, LR 0.001000:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:09<00:07,  1.37batch/s]Training Epoch 11, LR 0.001000:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.20s/batch]Training Epoch 11, LR 0.001000:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.05batch/s]Training Epoch 11, LR 0.001000:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.27batch/s]Training Epoch 11, LR 0.001000:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.49batch/s]Training Epoch 11, LR 0.001000:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.19s/batch]Training Epoch 11, LR 0.001000:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.05batch/s]Training Epoch 11, LR 0.001000:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.27batch/s]Training Epoch 11, LR 0.001000:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.49batch/s]Training Epoch 11, LR 0.001000:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.07s/batch]Training Epoch 11, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.15batch/s]Training Epoch 11, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 11:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 11:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.70s/batch]Evaluating Epoch 11:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.66s/batch]Evaluating Epoch 11:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.03batch/s]Evaluating Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.54batch/s]Evaluating Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [11/200]:, train_loss=0.061, 
train_confusionMatrix:
tensor([[79, 10],
        [36, 19]], device='cuda:0')
train_accuracy=0.6805555820465088, 
train_recall=0.34545454382896423, 
train_precision=0.6551724076271057, 
train_specificity=0.8876404762268066, 
train_balance_acc=0.6165475249290466,
 train_f1_score=0.4523809552192688,
 train_auc=0.6884576082229614

Epoch [11/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[18,  0],
        [13,  1]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0714285746216774, 
eval_precision=1.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5357142686843872,
 eval_f1_score=0.13333334028720856,
 eval_auc=0.6388888955116272


Epoch: 12/200
Training Epoch 12, LR 0.000997:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 12, LR 0.000997:   6%|â–Œ         | 1/18 [00:03<01:06,  3.93s/batch]Training Epoch 12, LR 0.000997:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 12, LR 0.000997:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 12, LR 0.000997:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 12, LR 0.000997:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.43s/batch]Training Epoch 12, LR 0.000997:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.08s/batch]Training Epoch 12, LR 0.000997:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.16batch/s]Training Epoch 12, LR 0.000997:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.40batch/s]Training Epoch 12, LR 0.000997:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.23s/batch]Training Epoch 12, LR 0.000997:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.02batch/s]Training Epoch 12, LR 0.000997:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.25batch/s]Training Epoch 12, LR 0.000997:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.46batch/s]Training Epoch 12, LR 0.000997:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.18s/batch]Training Epoch 12, LR 0.000997:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.06batch/s]Training Epoch 12, LR 0.000997:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.28batch/s]Training Epoch 12, LR 0.000997:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.49batch/s]Training Epoch 12, LR 0.000997:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.05s/batch]Training Epoch 12, LR 0.000997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.17batch/s]Training Epoch 12, LR 0.000997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 12:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 12:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.05s/batch]Evaluating Epoch 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.76s/batch]Evaluating Epoch 12:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.03s/batch]Evaluating Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.46batch/s]Evaluating Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.14s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [12/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[66, 24],
        [33, 21]], device='cuda:0')
train_accuracy=0.6041666865348816, 
train_recall=0.3888888955116272, 
train_precision=0.46666666865348816, 
train_specificity=0.7333333492279053, 
train_balance_acc=0.5611110925674438,
 train_f1_score=0.42424243688583374,
 train_auc=0.5911522507667542

Epoch [12/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[ 4, 15],
        [ 3, 10]], device='cuda:0')
eval_accuracy=0.4375, 
eval_recall=0.7692307829856873, 
eval_precision=0.4000000059604645, 
eval_specificity=0.21052631735801697, 
eval_balance_acc=0.4898785352706909,
 eval_f1_score=0.5263158082962036,
 eval_auc=0.5789473652839661


Epoch: 13/200
Training Epoch 13, LR 0.000989:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 13, LR 0.000989:   6%|â–Œ         | 1/18 [00:03<01:04,  3.79s/batch]Training Epoch 13, LR 0.000989:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 13, LR 0.000989:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 13, LR 0.000989:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 13, LR 0.000989:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.45s/batch]Training Epoch 13, LR 0.000989:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:13,  1.10s/batch]Training Epoch 13, LR 0.000989:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.14batch/s]Training Epoch 13, LR 0.000989:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.37batch/s]Training Epoch 13, LR 0.000989:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.24s/batch]Training Epoch 13, LR 0.000989:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:08,  1.04s/batch]Training Epoch 13, LR 0.000989:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.18batch/s]Training Epoch 13, LR 0.000989:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.40batch/s]Training Epoch 13, LR 0.000989:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.18s/batch]Training Epoch 13, LR 0.000989:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.03batch/s]Training Epoch 13, LR 0.000989:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.25batch/s]Training Epoch 13, LR 0.000989:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.46batch/s]Training Epoch 13, LR 0.000989:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.13s/batch]Training Epoch 13, LR 0.000989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.10batch/s]Training Epoch 13, LR 0.000989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 13:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 13:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.87s/batch]Evaluating Epoch 13:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.69s/batch]Evaluating Epoch 13:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.01batch/s]Evaluating Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.52batch/s]Evaluating Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.10s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [13/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[67, 23],
        [25, 29]], device='cuda:0')
train_accuracy=0.6666666865348816, 
train_recall=0.5370370149612427, 
train_precision=0.557692289352417, 
train_specificity=0.7444444298744202, 
train_balance_acc=0.6407407522201538,
 train_f1_score=0.5471698045730591,
 train_auc=0.6711934208869934

Epoch [13/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[11,  7],
        [ 6,  8]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.5714285969734192, 
eval_precision=0.5333333611488342, 
eval_specificity=0.6111111044883728, 
eval_balance_acc=0.591269850730896,
 eval_f1_score=0.5517241358757019,
 eval_auc=0.6349206566810608


Epoch: 14/200
Training Epoch 14, LR 0.000976:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 14, LR 0.000976:   6%|â–Œ         | 1/18 [00:03<01:06,  3.93s/batch]Training Epoch 14, LR 0.000976:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 14, LR 0.000976:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 14, LR 0.000976:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 14, LR 0.000976:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 14, LR 0.000976:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 14, LR 0.000976:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.19batch/s]Training Epoch 14, LR 0.000976:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.41batch/s]Training Epoch 14, LR 0.000976:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.21s/batch]Training Epoch 14, LR 0.000976:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:08,  1.06s/batch]Training Epoch 14, LR 0.000976:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:06,  1.16batch/s]Training Epoch 14, LR 0.000976:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.38batch/s]Training Epoch 14, LR 0.000976:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.14s/batch]Training Epoch 14, LR 0.000976:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:04,  1.05s/batch]Training Epoch 14, LR 0.000976:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.16batch/s]Training Epoch 14, LR 0.000976:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.38batch/s]Training Epoch 14, LR 0.000976:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.00s/batch]Training Epoch 14, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]Training Epoch 14, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 14:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 14:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.74s/batch]Evaluating Epoch 14:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.64s/batch]Evaluating Epoch 14:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.56batch/s]Evaluating Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [14/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[72, 18],
        [32, 22]], device='cuda:0')
train_accuracy=0.6527777910232544, 
train_recall=0.40740740299224854, 
train_precision=0.550000011920929, 
train_specificity=0.800000011920929, 
train_balance_acc=0.6037037372589111,
 train_f1_score=0.4680851101875305,
 train_auc=0.6658436059951782

Epoch [14/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[19,  0],
        [13,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.4858299493789673


Epoch: 15/200
Training Epoch 15, LR 0.000957:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 15, LR 0.000957:   6%|â–Œ         | 1/18 [00:04<01:11,  4.23s/batch]Training Epoch 15, LR 0.000957:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.98s/batch]Training Epoch 15, LR 0.000957:  17%|â–ˆâ–‹        | 3/18 [00:05<00:18,  1.26s/batch]Training Epoch 15, LR 0.000957:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.08batch/s]Training Epoch 15, LR 0.000957:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.41s/batch]Training Epoch 15, LR 0.000957:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:12,  1.07s/batch]Training Epoch 15, LR 0.000957:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.17batch/s]Training Epoch 15, LR 0.000957:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.41batch/s]Training Epoch 15, LR 0.000957:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 15, LR 0.000957:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.10batch/s]Training Epoch 15, LR 0.000957:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 15, LR 0.000957:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.53batch/s]Training Epoch 15, LR 0.000957:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.11s/batch]Training Epoch 15, LR 0.000957:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 15, LR 0.000957:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.33batch/s]Training Epoch 15, LR 0.000957:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.55batch/s]Training Epoch 15, LR 0.000957:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.10s/batch]Training Epoch 15, LR 0.000957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.12batch/s]Training Epoch 15, LR 0.000957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 15:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 15:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.04s/batch]Evaluating Epoch 15:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.76s/batch]Evaluating Epoch 15:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.03s/batch]Evaluating Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.46batch/s]Evaluating Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.14s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [15/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[77, 13],
        [34, 20]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.37037035822868347, 
train_precision=0.6060606241226196, 
train_specificity=0.855555534362793, 
train_balance_acc=0.6129629611968994,
 train_f1_score=0.4597701132297516,
 train_auc=0.635185182094574

Epoch [15/200]:, eval_loss=0.018, 
eval_confusionMatrix:
tensor([[ 3, 17],
        [ 0, 12]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=1.0, 
eval_precision=0.4137931168079376, 
eval_specificity=0.15000000596046448, 
eval_balance_acc=0.574999988079071,
 eval_f1_score=0.5853658318519592,
 eval_auc=0.5791666507720947


Epoch: 16/200
Training Epoch 16, LR 0.000934:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 16, LR 0.000934:   6%|â–Œ         | 1/18 [00:04<01:10,  4.13s/batch]Training Epoch 16, LR 0.000934:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.94s/batch]Training Epoch 16, LR 0.000934:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.24s/batch]Training Epoch 16, LR 0.000934:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 16, LR 0.000934:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 16, LR 0.000934:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 16, LR 0.000934:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.22batch/s]Training Epoch 16, LR 0.000934:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 16, LR 0.000934:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.15s/batch]Training Epoch 16, LR 0.000934:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.09batch/s]Training Epoch 16, LR 0.000934:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.31batch/s]Training Epoch 16, LR 0.000934:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.52batch/s]Training Epoch 16, LR 0.000934:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.16s/batch]Training Epoch 16, LR 0.000934:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.07batch/s]Training Epoch 16, LR 0.000934:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.29batch/s]Training Epoch 16, LR 0.000934:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.51batch/s]Training Epoch 16, LR 0.000934:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.06s/batch]Training Epoch 16, LR 0.000934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 16, LR 0.000934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 16:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 16:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.85s/batch]Evaluating Epoch 16:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.68s/batch]Evaluating Epoch 16:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.02batch/s]Evaluating Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.52batch/s]Evaluating Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.09s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [16/200]:, train_loss=0.064, 
train_confusionMatrix:
tensor([[78, 11],
        [41, 14]], device='cuda:0')
train_accuracy=0.6388888955116272, 
train_recall=0.2545454502105713, 
train_precision=0.5600000023841858, 
train_specificity=0.8764045238494873, 
train_balance_acc=0.5654749870300293,
 train_f1_score=0.3499999940395355,
 train_auc=0.6247191429138184

Epoch [16/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[15,  5],
        [11,  1]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.0833333358168602, 
eval_precision=0.1666666716337204, 
eval_specificity=0.75, 
eval_balance_acc=0.4166666567325592,
 eval_f1_score=0.1111111119389534,
 eval_auc=0.5


Epoch: 17/200
Training Epoch 17, LR 0.000905:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 17, LR 0.000905:   6%|â–Œ         | 1/18 [00:03<01:07,  3.99s/batch]Training Epoch 17, LR 0.000905:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.88s/batch]Training Epoch 17, LR 0.000905:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 17, LR 0.000905:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 17, LR 0.000905:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 17, LR 0.000905:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 17, LR 0.000905:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 17, LR 0.000905:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 17, LR 0.000905:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.29s/batch]Training Epoch 17, LR 0.000905:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:08,  1.02s/batch]Training Epoch 17, LR 0.000905:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.20batch/s]Training Epoch 17, LR 0.000905:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.43batch/s]Training Epoch 17, LR 0.000905:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.17s/batch]Training Epoch 17, LR 0.000905:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.04batch/s]Training Epoch 17, LR 0.000905:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.26batch/s]Training Epoch 17, LR 0.000905:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.48batch/s]Training Epoch 17, LR 0.000905:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.09s/batch]Training Epoch 17, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.04batch/s]Training Epoch 17, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 17:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 17:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.04s/batch]Evaluating Epoch 17:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.76s/batch]Evaluating Epoch 17:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.03s/batch]Evaluating Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.46batch/s]Evaluating Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.14s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [17/200]:, train_loss=0.061, 
train_confusionMatrix:
tensor([[79, 10],
        [33, 22]], device='cuda:0')
train_accuracy=0.7013888955116272, 
train_recall=0.4000000059604645, 
train_precision=0.6875, 
train_specificity=0.8876404762268066, 
train_balance_acc=0.6438202261924744,
 train_f1_score=0.5057471394538879,
 train_auc=0.7101123332977295

Epoch [17/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[18,  1],
        [11,  2]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.1538461595773697, 
eval_precision=0.6666666865348816, 
eval_specificity=0.9473684430122375, 
eval_balance_acc=0.5506073236465454,
 eval_f1_score=0.25,
 eval_auc=0.38461539149284363


Epoch: 18/200
Training Epoch 18, LR 0.000873:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 18, LR 0.000873:   6%|â–Œ         | 1/18 [00:03<01:06,  3.92s/batch]Training Epoch 18, LR 0.000873:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 18, LR 0.000873:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 18, LR 0.000873:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 18, LR 0.000873:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 18, LR 0.000873:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 18, LR 0.000873:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.24batch/s]Training Epoch 18, LR 0.000873:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 18, LR 0.000873:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.05s/batch]Training Epoch 18, LR 0.000873:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 18, LR 0.000873:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.40batch/s]Training Epoch 18, LR 0.000873:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.61batch/s]Training Epoch 18, LR 0.000873:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.02batch/s]Training Epoch 18, LR 0.000873:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.24batch/s]Training Epoch 18, LR 0.000873:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.46batch/s]Training Epoch 18, LR 0.000873:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.66batch/s]Training Epoch 18, LR 0.000873:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.05s/batch]Training Epoch 18, LR 0.000873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 18, LR 0.000873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 18:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 18:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.64s/batch]Evaluating Epoch 18:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.59s/batch]Evaluating Epoch 18:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.59batch/s]Evaluating Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [18/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[79, 11],
        [29, 25]], device='cuda:0')
train_accuracy=0.7222222089767456, 
train_recall=0.46296295523643494, 
train_precision=0.6944444179534912, 
train_specificity=0.8777777552604675, 
train_balance_acc=0.67037034034729,
 train_f1_score=0.5555555820465088,
 train_auc=0.7329217791557312

Epoch [18/200]:, eval_loss=0.019, 
eval_confusionMatrix:
tensor([[ 0, 18],
        [ 0, 14]], device='cuda:0')
eval_accuracy=0.4375, 
eval_recall=1.0, 
eval_precision=0.4375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.6086956262588501,
 eval_auc=0.6230158805847168


Epoch: 19/200
Training Epoch 19, LR 0.000836:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 19, LR 0.000836:   6%|â–Œ         | 1/18 [00:03<01:06,  3.90s/batch]Training Epoch 19, LR 0.000836:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 19, LR 0.000836:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 19, LR 0.000836:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 19, LR 0.000836:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.36s/batch]Training Epoch 19, LR 0.000836:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 19, LR 0.000836:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 19, LR 0.000836:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 19, LR 0.000836:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.16s/batch]Training Epoch 19, LR 0.000836:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.08batch/s]Training Epoch 19, LR 0.000836:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.30batch/s]Training Epoch 19, LR 0.000836:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.52batch/s]Training Epoch 19, LR 0.000836:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.10s/batch]Training Epoch 19, LR 0.000836:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.12batch/s]Training Epoch 19, LR 0.000836:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.34batch/s]Training Epoch 19, LR 0.000836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.56batch/s]Training Epoch 19, LR 0.000836:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.02s/batch]Training Epoch 19, LR 0.000836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 19, LR 0.000836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 19:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 19:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.73s/batch]Evaluating Epoch 19:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.63s/batch]Evaluating Epoch 19:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.57batch/s]Evaluating Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [19/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[75, 14],
        [32, 23]], device='cuda:0')
train_accuracy=0.6805555820465088, 
train_recall=0.41818180680274963, 
train_precision=0.6216216087341309, 
train_specificity=0.8426966071128845, 
train_balance_acc=0.6304392218589783,
 train_f1_score=0.5,
 train_auc=0.718284010887146

Epoch [19/200]:, eval_loss=0.018, 
eval_confusionMatrix:
tensor([[ 1, 18],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.4375, 
eval_recall=1.0, 
eval_precision=0.4193548262119293, 
eval_specificity=0.05263157933950424, 
eval_balance_acc=0.5263158082962036,
 eval_f1_score=0.5909090638160706,
 eval_auc=0.5303643941879272


Epoch: 20/200
Training Epoch 20, LR 0.000796:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 20, LR 0.000796:   6%|â–Œ         | 1/18 [00:03<01:01,  3.60s/batch]Training Epoch 20, LR 0.000796:  11%|â–ˆ         | 2/18 [00:04<00:27,  1.72s/batch]Training Epoch 20, LR 0.000796:  17%|â–ˆâ–‹        | 3/18 [00:04<00:16,  1.12s/batch]Training Epoch 20, LR 0.000796:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.19batch/s]Training Epoch 20, LR 0.000796:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.36s/batch]Training Epoch 20, LR 0.000796:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 20, LR 0.000796:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:09,  1.21batch/s]Training Epoch 20, LR 0.000796:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 20, LR 0.000796:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.22s/batch]Training Epoch 20, LR 0.000796:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.03batch/s]Training Epoch 20, LR 0.000796:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.25batch/s]Training Epoch 20, LR 0.000796:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:04,  1.47batch/s]Training Epoch 20, LR 0.000796:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 20, LR 0.000796:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 20, LR 0.000796:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 20, LR 0.000796:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 20, LR 0.000796:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.18s/batch]Training Epoch 20, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]Training Epoch 20, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 20:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 20:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.62s/batch]Evaluating Epoch 20:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 20:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [20/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[82,  7],
        [33, 22]], device='cuda:0')
train_accuracy=0.7222222089767456, 
train_recall=0.4000000059604645, 
train_precision=0.7586206793785095, 
train_specificity=0.9213483333587646, 
train_balance_acc=0.6606741547584534,
 train_f1_score=0.523809552192688,
 train_auc=0.6896833777427673

Epoch [20/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 6, 15],
        [ 1, 10]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.9090909361839294, 
eval_precision=0.4000000059604645, 
eval_specificity=0.2857142984867096, 
eval_balance_acc=0.5974026322364807,
 eval_f1_score=0.5555555820465088,
 eval_auc=0.6796537041664124


Epoch: 21/200
Training Epoch 21, LR 0.000753:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 21, LR 0.000753:   6%|â–Œ         | 1/18 [00:03<01:05,  3.85s/batch]Training Epoch 21, LR 0.000753:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 21, LR 0.000753:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 21, LR 0.000753:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 21, LR 0.000753:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.37s/batch]Training Epoch 21, LR 0.000753:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 21, LR 0.000753:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 21, LR 0.000753:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.43batch/s]Training Epoch 21, LR 0.000753:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.22s/batch]Training Epoch 21, LR 0.000753:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.03batch/s]Training Epoch 21, LR 0.000753:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.25batch/s]Training Epoch 21, LR 0.000753:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.47batch/s]Training Epoch 21, LR 0.000753:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.08s/batch]Training Epoch 21, LR 0.000753:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 21, LR 0.000753:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 21, LR 0.000753:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.58batch/s]Training Epoch 21, LR 0.000753:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:00,  1.02batch/s]Training Epoch 21, LR 0.000753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.24batch/s]Training Epoch 21, LR 0.000753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 21:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 21:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.78s/batch]Evaluating Epoch 21:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.65s/batch]Evaluating Epoch 21:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.08s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [21/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[75, 14],
        [27, 28]], device='cuda:0')
train_accuracy=0.7152777910232544, 
train_recall=0.5090909004211426, 
train_precision=0.6666666865348816, 
train_specificity=0.8426966071128845, 
train_balance_acc=0.6758937835693359,
 train_f1_score=0.5773195624351501,
 train_auc=0.7423901557922363

Epoch [21/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 8, 12],
        [ 5,  7]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=0.5833333134651184, 
eval_precision=0.3684210479259491, 
eval_specificity=0.4000000059604645, 
eval_balance_acc=0.49166667461395264,
 eval_f1_score=0.4516128897666931,
 eval_auc=0.49583330750465393


Epoch: 22/200
Training Epoch 22, LR 0.000706:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 22, LR 0.000706:   6%|â–Œ         | 1/18 [00:03<01:06,  3.91s/batch]Training Epoch 22, LR 0.000706:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.86s/batch]Training Epoch 22, LR 0.000706:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 22, LR 0.000706:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 22, LR 0.000706:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.44s/batch]Training Epoch 22, LR 0.000706:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:13,  1.09s/batch]Training Epoch 22, LR 0.000706:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.15batch/s]Training Epoch 22, LR 0.000706:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.39batch/s]Training Epoch 22, LR 0.000706:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.27s/batch]Training Epoch 22, LR 0.000706:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.00batch/s]Training Epoch 22, LR 0.000706:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.22batch/s]Training Epoch 22, LR 0.000706:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.45batch/s]Training Epoch 22, LR 0.000706:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:06,  1.21s/batch]Training Epoch 22, LR 0.000706:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.03batch/s]Training Epoch 22, LR 0.000706:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.25batch/s]Training Epoch 22, LR 0.000706:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.47batch/s]Training Epoch 22, LR 0.000706:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.14s/batch]Training Epoch 22, LR 0.000706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.09batch/s]Training Epoch 22, LR 0.000706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 22:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 22:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.61s/batch]Evaluating Epoch 22:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 22:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [22/200]:, train_loss=0.055, 
train_confusionMatrix:
tensor([[80, 10],
        [26, 28]], device='cuda:0')
train_accuracy=0.75, 
train_recall=0.5185185074806213, 
train_precision=0.7368420958518982, 
train_specificity=0.8888888955116272, 
train_balance_acc=0.7037037014961243,
 train_f1_score=0.6086956262588501,
 train_auc=0.78847736120224

Epoch [22/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[15,  5],
        [10,  2]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.1666666716337204, 
eval_precision=0.2857142984867096, 
eval_specificity=0.75, 
eval_balance_acc=0.4583333432674408,
 eval_f1_score=0.21052631735801697,
 eval_auc=0.5958333015441895


Epoch: 23/200
Training Epoch 23, LR 0.000658:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 23, LR 0.000658:   6%|â–Œ         | 1/18 [00:03<01:04,  3.81s/batch]Training Epoch 23, LR 0.000658:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 23, LR 0.000658:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 23, LR 0.000658:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 23, LR 0.000658:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 23, LR 0.000658:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 23, LR 0.000658:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 23, LR 0.000658:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 23, LR 0.000658:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 23, LR 0.000658:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 23, LR 0.000658:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 23, LR 0.000658:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 23, LR 0.000658:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.20s/batch]Training Epoch 23, LR 0.000658:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.04batch/s]Training Epoch 23, LR 0.000658:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.26batch/s]Training Epoch 23, LR 0.000658:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.48batch/s]Training Epoch 23, LR 0.000658:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.09s/batch]Training Epoch 23, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.13batch/s]Training Epoch 23, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 23:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 23:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.74s/batch]Evaluating Epoch 23:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.74s/batch]Evaluating Epoch 23:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.02s/batch]Evaluating Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.48batch/s]Evaluating Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.11s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [23/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[77, 13],
        [27, 27]], device='cuda:0')
train_accuracy=0.7222222089767456, 
train_recall=0.5, 
train_precision=0.675000011920929, 
train_specificity=0.855555534362793, 
train_balance_acc=0.6777777671813965,
 train_f1_score=0.5744680762290955,
 train_auc=0.7316872477531433

Epoch [23/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.6416666507720947


Epoch: 24/200
Training Epoch 24, LR 0.000608:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 24, LR 0.000608:   6%|â–Œ         | 1/18 [00:04<01:12,  4.25s/batch]Training Epoch 24, LR 0.000608:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.99s/batch]Training Epoch 24, LR 0.000608:  17%|â–ˆâ–‹        | 3/18 [00:05<00:19,  1.27s/batch]Training Epoch 24, LR 0.000608:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:13,  1.08batch/s]Training Epoch 24, LR 0.000608:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.38s/batch]Training Epoch 24, LR 0.000608:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:12,  1.05s/batch]Training Epoch 24, LR 0.000608:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.19batch/s]Training Epoch 24, LR 0.000608:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.43batch/s]Training Epoch 24, LR 0.000608:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.32s/batch]Training Epoch 24, LR 0.000608:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:12<00:08,  1.07s/batch]Training Epoch 24, LR 0.000608:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:06,  1.14batch/s]Training Epoch 24, LR 0.000608:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.36batch/s]Training Epoch 24, LR 0.000608:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:15<00:06,  1.21s/batch]Training Epoch 24, LR 0.000608:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:04,  1.03s/batch]Training Epoch 24, LR 0.000608:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:16<00:02,  1.19batch/s]Training Epoch 24, LR 0.000608:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.41batch/s]Training Epoch 24, LR 0.000608:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.05s/batch]Training Epoch 24, LR 0.000608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.10batch/s]Training Epoch 24, LR 0.000608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 24:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 24:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.74s/batch]Evaluating Epoch 24:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.63s/batch]Evaluating Epoch 24:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.56batch/s]Evaluating Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [24/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[75, 14],
        [28, 27]], device='cuda:0')
train_accuracy=0.7083333134651184, 
train_recall=0.4909090995788574, 
train_precision=0.6585366129875183, 
train_specificity=0.8426966071128845, 
train_balance_acc=0.6668028831481934,
 train_f1_score=0.5625,
 train_auc=0.765066385269165

Epoch [24/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[14,  6],
        [10,  2]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.1666666716337204, 
eval_precision=0.25, 
eval_specificity=0.699999988079071, 
eval_balance_acc=0.4333333373069763,
 eval_f1_score=0.20000000298023224,
 eval_auc=0.5208333730697632


Epoch: 25/200
Training Epoch 25, LR 0.000557:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 25, LR 0.000557:   6%|â–Œ         | 1/18 [00:04<01:11,  4.18s/batch]Training Epoch 25, LR 0.000557:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.96s/batch]Training Epoch 25, LR 0.000557:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.25s/batch]Training Epoch 25, LR 0.000557:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.09batch/s]Training Epoch 25, LR 0.000557:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.41s/batch]Training Epoch 25, LR 0.000557:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:12,  1.07s/batch]Training Epoch 25, LR 0.000557:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.17batch/s]Training Epoch 25, LR 0.000557:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.41batch/s]Training Epoch 25, LR 0.000557:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.33s/batch]Training Epoch 25, LR 0.000557:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:12<00:08,  1.05s/batch]Training Epoch 25, LR 0.000557:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.18batch/s]Training Epoch 25, LR 0.000557:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.40batch/s]Training Epoch 25, LR 0.000557:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:15<00:05,  1.16s/batch]Training Epoch 25, LR 0.000557:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.07batch/s]Training Epoch 25, LR 0.000557:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.29batch/s]Training Epoch 25, LR 0.000557:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.50batch/s]Training Epoch 25, LR 0.000557:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.22s/batch]Training Epoch 25, LR 0.000557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.02batch/s]Training Epoch 25, LR 0.000557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 25:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 25:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.73s/batch]Evaluating Epoch 25:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.63s/batch]Evaluating Epoch 25:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.56batch/s]Evaluating Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [25/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[72, 17],
        [25, 30]], device='cuda:0')
train_accuracy=0.7083333134651184, 
train_recall=0.5454545617103577, 
train_precision=0.6382978558540344, 
train_specificity=0.8089887499809265, 
train_balance_acc=0.6772216558456421,
 train_f1_score=0.5882353186607361,
 train_auc=0.7679264545440674

Epoch [25/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[21,  0],
        [11,  0]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.6580086946487427


Epoch: 26/200
Training Epoch 26, LR 0.000505:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 26, LR 0.000505:   6%|â–Œ         | 1/18 [00:04<01:11,  4.18s/batch]Training Epoch 26, LR 0.000505:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.96s/batch]Training Epoch 26, LR 0.000505:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.25s/batch]Training Epoch 26, LR 0.000505:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.09batch/s]Training Epoch 26, LR 0.000505:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.38s/batch]Training Epoch 26, LR 0.000505:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.12s/batch]Training Epoch 26, LR 0.000505:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.13batch/s]Training Epoch 26, LR 0.000505:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:09<00:07,  1.37batch/s]Training Epoch 26, LR 0.000505:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.23s/batch]Training Epoch 26, LR 0.000505:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:08,  1.04s/batch]Training Epoch 26, LR 0.000505:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.18batch/s]Training Epoch 26, LR 0.000505:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.40batch/s]Training Epoch 26, LR 0.000505:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:15<00:06,  1.26s/batch]Training Epoch 26, LR 0.000505:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.00batch/s]Training Epoch 26, LR 0.000505:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:16<00:02,  1.22batch/s]Training Epoch 26, LR 0.000505:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.44batch/s]Training Epoch 26, LR 0.000505:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.15s/batch]Training Epoch 26, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.03batch/s]Training Epoch 26, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 26:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 26:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.72s/batch]Evaluating Epoch 26:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.63s/batch]Evaluating Epoch 26:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [26/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[71, 19],
        [24, 30]], device='cuda:0')
train_accuracy=0.7013888955116272, 
train_recall=0.5555555820465088, 
train_precision=0.6122449040412903, 
train_specificity=0.7888888716697693, 
train_balance_acc=0.6722222566604614,
 train_f1_score=0.582524299621582,
 train_auc=0.7442386746406555

Epoch [26/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.6375000476837158


Epoch: 27/200
Training Epoch 27, LR 0.000453:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 27, LR 0.000453:   6%|â–Œ         | 1/18 [00:03<01:07,  3.96s/batch]Training Epoch 27, LR 0.000453:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 27, LR 0.000453:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.20s/batch]Training Epoch 27, LR 0.000453:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 27, LR 0.000453:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.38s/batch]Training Epoch 27, LR 0.000453:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 27, LR 0.000453:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.19batch/s]Training Epoch 27, LR 0.000453:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.41batch/s]Training Epoch 27, LR 0.000453:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.22s/batch]Training Epoch 27, LR 0.000453:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.03batch/s]Training Epoch 27, LR 0.000453:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.26batch/s]Training Epoch 27, LR 0.000453:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.48batch/s]Training Epoch 27, LR 0.000453:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:06,  1.20s/batch]Training Epoch 27, LR 0.000453:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.04batch/s]Training Epoch 27, LR 0.000453:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.26batch/s]Training Epoch 27, LR 0.000453:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.47batch/s]Training Epoch 27, LR 0.000453:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.20s/batch]Training Epoch 27, LR 0.000453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.04batch/s]Training Epoch 27, LR 0.000453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 27:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 27:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.79s/batch]Evaluating Epoch 27:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.65s/batch]Evaluating Epoch 27:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.03batch/s]Evaluating Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.54batch/s]Evaluating Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.08s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [27/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[76, 13],
        [26, 29]], device='cuda:0')
train_accuracy=0.7291666865348816, 
train_recall=0.5272727012634277, 
train_precision=0.6904761791229248, 
train_specificity=0.8539325594902039, 
train_balance_acc=0.6906026601791382,
 train_f1_score=0.5979381203651428,
 train_auc=0.7752809524536133

Epoch [27/200]:, eval_loss=0.020, 
eval_confusionMatrix:
tensor([[ 1, 19],
        [ 0, 12]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=1.0, 
eval_precision=0.3870967626571655, 
eval_specificity=0.05000000074505806, 
eval_balance_acc=0.5249999761581421,
 eval_f1_score=0.5581395626068115,
 eval_auc=0.5708333253860474


Epoch: 28/200
Training Epoch 28, LR 0.000402:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 28, LR 0.000402:   6%|â–Œ         | 1/18 [00:03<01:04,  3.78s/batch]Training Epoch 28, LR 0.000402:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 28, LR 0.000402:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 28, LR 0.000402:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.16batch/s]Training Epoch 28, LR 0.000402:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 28, LR 0.000402:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 28, LR 0.000402:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 28, LR 0.000402:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 28, LR 0.000402:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.32s/batch]Training Epoch 28, LR 0.000402:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:08,  1.03s/batch]Training Epoch 28, LR 0.000402:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.18batch/s]Training Epoch 28, LR 0.000402:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.40batch/s]Training Epoch 28, LR 0.000402:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:06,  1.22s/batch]Training Epoch 28, LR 0.000402:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.03batch/s]Training Epoch 28, LR 0.000402:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.25batch/s]Training Epoch 28, LR 0.000402:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.46batch/s]Training Epoch 28, LR 0.000402:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.12s/batch]Training Epoch 28, LR 0.000402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.10batch/s]Training Epoch 28, LR 0.000402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 28:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 28:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.56s/batch]Evaluating Epoch 28:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 28:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [28/200]:, train_loss=0.053, 
train_confusionMatrix:
tensor([[75, 14],
        [21, 34]], device='cuda:0')
train_accuracy=0.7569444179534912, 
train_recall=0.6181818246841431, 
train_precision=0.7083333134651184, 
train_specificity=0.8426966071128845, 
train_balance_acc=0.7304391860961914,
 train_f1_score=0.6601941585540771,
 train_auc=0.8365679979324341

Epoch [28/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[12,  7],
        [11,  2]], device='cuda:0')
eval_accuracy=0.4375, 
eval_recall=0.1538461595773697, 
eval_precision=0.2222222238779068, 
eval_specificity=0.6315789222717285, 
eval_balance_acc=0.3927125334739685,
 eval_f1_score=0.1818181872367859,
 eval_auc=0.5627530217170715


Epoch: 29/200
Training Epoch 29, LR 0.000352:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 29, LR 0.000352:   6%|â–Œ         | 1/18 [00:04<01:09,  4.09s/batch]Training Epoch 29, LR 0.000352:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.93s/batch]Training Epoch 29, LR 0.000352:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.23s/batch]Training Epoch 29, LR 0.000352:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 29, LR 0.000352:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 29, LR 0.000352:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 29, LR 0.000352:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 29, LR 0.000352:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 29, LR 0.000352:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 29, LR 0.000352:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.13batch/s]Training Epoch 29, LR 0.000352:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 29, LR 0.000352:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 29, LR 0.000352:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 29, LR 0.000352:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.17batch/s]Training Epoch 29, LR 0.000352:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 29, LR 0.000352:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.60batch/s]Training Epoch 29, LR 0.000352:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.07s/batch]Training Epoch 29, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.09batch/s]Training Epoch 29, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 29:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 29:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.08s/batch]Evaluating Epoch 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.77s/batch]Evaluating Epoch 29:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.03s/batch]Evaluating Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.46batch/s]Evaluating Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.15s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [29/200]:, train_loss=0.052, 
train_confusionMatrix:
tensor([[77, 13],
        [19, 35]], device='cuda:0')
train_accuracy=0.7777777910232544, 
train_recall=0.6481481194496155, 
train_precision=0.7291666865348816, 
train_specificity=0.855555534362793, 
train_balance_acc=0.7518517971038818,
 train_f1_score=0.686274528503418,
 train_auc=0.8061728477478027

Epoch [29/200]:, eval_loss=0.020, 
eval_confusionMatrix:
tensor([[ 1, 20],
        [ 0, 11]], device='cuda:0')
eval_accuracy=0.375, 
eval_recall=1.0, 
eval_precision=0.35483869910240173, 
eval_specificity=0.0476190485060215, 
eval_balance_acc=0.523809552192688,
 eval_f1_score=0.523809552192688,
 eval_auc=0.5974025726318359


Epoch: 30/200
Training Epoch 30, LR 0.000304:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 30, LR 0.000304:   6%|â–Œ         | 1/18 [00:03<01:07,  3.96s/batch]Training Epoch 30, LR 0.000304:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 30, LR 0.000304:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 30, LR 0.000304:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 30, LR 0.000304:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.42s/batch]Training Epoch 30, LR 0.000304:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.08s/batch]Training Epoch 30, LR 0.000304:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.17batch/s]Training Epoch 30, LR 0.000304:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.40batch/s]Training Epoch 30, LR 0.000304:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.19s/batch]Training Epoch 30, LR 0.000304:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.06batch/s]Training Epoch 30, LR 0.000304:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.28batch/s]Training Epoch 30, LR 0.000304:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.49batch/s]Training Epoch 30, LR 0.000304:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.15s/batch]Training Epoch 30, LR 0.000304:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.08batch/s]Training Epoch 30, LR 0.000304:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.30batch/s]Training Epoch 30, LR 0.000304:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.51batch/s]Training Epoch 30, LR 0.000304:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.09s/batch]Training Epoch 30, LR 0.000304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.13batch/s]Training Epoch 30, LR 0.000304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 30:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 30:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.51s/batch]Evaluating Epoch 30:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.60s/batch]Evaluating Epoch 30:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [30/200]:, train_loss=0.055, 
train_confusionMatrix:
tensor([[77, 13],
        [24, 30]], device='cuda:0')
train_accuracy=0.7430555820465088, 
train_recall=0.5555555820465088, 
train_precision=0.6976743936538696, 
train_specificity=0.855555534362793, 
train_balance_acc=0.7055555582046509,
 train_f1_score=0.6185566782951355,
 train_auc=0.797325074672699

Epoch [30/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[19,  0],
        [11,  2]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.1538461595773697, 
eval_precision=1.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5769230723381042,
 eval_f1_score=0.2666666805744171,
 eval_auc=0.6437246799468994


Epoch: 31/200
Training Epoch 31, LR 0.000258:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 31, LR 0.000258:   6%|â–Œ         | 1/18 [00:03<01:05,  3.88s/batch]Training Epoch 31, LR 0.000258:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 31, LR 0.000258:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 31, LR 0.000258:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 31, LR 0.000258:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.37s/batch]Training Epoch 31, LR 0.000258:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 31, LR 0.000258:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 31, LR 0.000258:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.43batch/s]Training Epoch 31, LR 0.000258:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.25s/batch]Training Epoch 31, LR 0.000258:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.01batch/s]Training Epoch 31, LR 0.000258:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.24batch/s]Training Epoch 31, LR 0.000258:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.45batch/s]Training Epoch 31, LR 0.000258:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.06s/batch]Training Epoch 31, LR 0.000258:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.16batch/s]Training Epoch 31, LR 0.000258:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 31, LR 0.000258:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.59batch/s]Training Epoch 31, LR 0.000258:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.08s/batch]Training Epoch 31, LR 0.000258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.14batch/s]Training Epoch 31, LR 0.000258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 31:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 31:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.65s/batch]Evaluating Epoch 31:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.59s/batch]Evaluating Epoch 31:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.59batch/s]Evaluating Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [31/200]:, train_loss=0.053, 
train_confusionMatrix:
tensor([[79, 10],
        [22, 33]], device='cuda:0')
train_accuracy=0.7777777910232544, 
train_recall=0.6000000238418579, 
train_precision=0.7674418687820435, 
train_specificity=0.8876404762268066, 
train_balance_acc=0.7438202500343323,
 train_f1_score=0.6734693646430969,
 train_auc=0.7991828918457031

Epoch [31/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.6375000476837158


Epoch: 32/200
Training Epoch 32, LR 0.000214:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 32, LR 0.000214:   6%|â–Œ         | 1/18 [00:04<01:09,  4.09s/batch]Training Epoch 32, LR 0.000214:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.92s/batch]Training Epoch 32, LR 0.000214:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.23s/batch]Training Epoch 32, LR 0.000214:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 32, LR 0.000214:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.38s/batch]Training Epoch 32, LR 0.000214:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 32, LR 0.000214:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.19batch/s]Training Epoch 32, LR 0.000214:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.43batch/s]Training Epoch 32, LR 0.000214:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.14s/batch]Training Epoch 32, LR 0.000214:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.09batch/s]Training Epoch 32, LR 0.000214:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 32, LR 0.000214:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.53batch/s]Training Epoch 32, LR 0.000214:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.13s/batch]Training Epoch 32, LR 0.000214:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.10batch/s]Training Epoch 32, LR 0.000214:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.32batch/s]Training Epoch 32, LR 0.000214:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.54batch/s]Training Epoch 32, LR 0.000214:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.10s/batch]Training Epoch 32, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.12batch/s]Training Epoch 32, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 32:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 32:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.14s/batch]Evaluating Epoch 32:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.80s/batch]Evaluating Epoch 32:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.05s/batch]Evaluating Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.42batch/s]Evaluating Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.17s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [32/200]:, train_loss=0.052, 
train_confusionMatrix:
tensor([[79, 11],
        [18, 36]], device='cuda:0')
train_accuracy=0.7986111044883728, 
train_recall=0.6666666865348816, 
train_precision=0.7659574747085571, 
train_specificity=0.8777777552604675, 
train_balance_acc=0.7722222208976746,
 train_f1_score=0.7128713130950928,
 train_auc=0.8318929672241211

Epoch [32/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[18,  2],
        [11,  1]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0833333358168602, 
eval_precision=0.3333333432674408, 
eval_specificity=0.8999999761581421, 
eval_balance_acc=0.49166664481163025,
 eval_f1_score=0.13333334028720856,
 eval_auc=0.5833333730697632


Epoch: 33/200
Training Epoch 33, LR 0.000174:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 33, LR 0.000174:   6%|â–Œ         | 1/18 [00:04<01:16,  4.50s/batch]Training Epoch 33, LR 0.000174:  11%|â–ˆ         | 2/18 [00:04<00:33,  2.09s/batch]Training Epoch 33, LR 0.000174:  17%|â–ˆâ–‹        | 3/18 [00:05<00:19,  1.32s/batch]Training Epoch 33, LR 0.000174:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:13,  1.04batch/s]Training Epoch 33, LR 0.000174:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 33, LR 0.000174:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:12,  1.02s/batch]Training Epoch 33, LR 0.000174:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.23batch/s]Training Epoch 33, LR 0.000174:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 33, LR 0.000174:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.19s/batch]Training Epoch 33, LR 0.000174:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.01batch/s]Training Epoch 33, LR 0.000174:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.23batch/s]Training Epoch 33, LR 0.000174:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.45batch/s]Training Epoch 33, LR 0.000174:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.10s/batch]Training Epoch 33, LR 0.000174:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:04,  1.07s/batch]Training Epoch 33, LR 0.000174:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:16<00:02,  1.15batch/s]Training Epoch 33, LR 0.000174:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.37batch/s]Training Epoch 33, LR 0.000174:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.10s/batch]Training Epoch 33, LR 0.000174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.03batch/s]Training Epoch 33, LR 0.000174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 33:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 33:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 33:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.62s/batch]Evaluating Epoch 33:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.56batch/s]Evaluating Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [33/200]:, train_loss=0.052, 
train_confusionMatrix:
tensor([[77, 12],
        [21, 34]], device='cuda:0')
train_accuracy=0.7708333134651184, 
train_recall=0.6181818246841431, 
train_precision=0.739130437374115, 
train_specificity=0.8651685118675232, 
train_balance_acc=0.7416751384735107,
 train_f1_score=0.6732673048973083,
 train_auc=0.8414708971977234

Epoch [33/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[15,  5],
        [ 9,  3]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.25, 
eval_precision=0.375, 
eval_specificity=0.75, 
eval_balance_acc=0.5,
 eval_f1_score=0.30000001192092896,
 eval_auc=0.5833333730697632


Epoch: 34/200
Training Epoch 34, LR 0.000137:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 34, LR 0.000137:   6%|â–Œ         | 1/18 [00:03<01:03,  3.76s/batch]Training Epoch 34, LR 0.000137:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 34, LR 0.000137:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 34, LR 0.000137:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 34, LR 0.000137:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:20,  1.54s/batch]Training Epoch 34, LR 0.000137:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.16s/batch]Training Epoch 34, LR 0.000137:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:10,  1.10batch/s]Training Epoch 34, LR 0.000137:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.33batch/s]Training Epoch 34, LR 0.000137:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.20s/batch]Training Epoch 34, LR 0.000137:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.05batch/s]Training Epoch 34, LR 0.000137:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.27batch/s]Training Epoch 34, LR 0.000137:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.49batch/s]Training Epoch 34, LR 0.000137:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.14s/batch]Training Epoch 34, LR 0.000137:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.09batch/s]Training Epoch 34, LR 0.000137:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.31batch/s]Training Epoch 34, LR 0.000137:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.53batch/s]Training Epoch 34, LR 0.000137:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.06s/batch]Training Epoch 34, LR 0.000137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.16batch/s]Training Epoch 34, LR 0.000137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 34:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 34:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.68s/batch]Evaluating Epoch 34:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.63s/batch]Evaluating Epoch 34:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.57batch/s]Evaluating Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [34/200]:, train_loss=0.051, 
train_confusionMatrix:
tensor([[80,  9],
        [21, 34]], device='cuda:0')
train_accuracy=0.7916666865348816, 
train_recall=0.6181818246841431, 
train_precision=0.7906976938247681, 
train_specificity=0.898876428604126, 
train_balance_acc=0.7585291266441345,
 train_f1_score=0.6938775777816772,
 train_auc=0.8177732825279236

Epoch [34/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[20,  1],
        [ 9,  2]], device='cuda:0')
eval_accuracy=0.6875, 
eval_recall=0.1818181872367859, 
eval_precision=0.6666666865348816, 
eval_specificity=0.9523809552192688, 
eval_balance_acc=0.5670995712280273,
 eval_f1_score=0.2857142984867096,
 eval_auc=0.6103895902633667


Epoch: 35/200
Training Epoch 35, LR 0.000105:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 35, LR 0.000105:   6%|â–Œ         | 1/18 [00:03<01:06,  3.92s/batch]Training Epoch 35, LR 0.000105:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 35, LR 0.000105:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 35, LR 0.000105:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 35, LR 0.000105:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 35, LR 0.000105:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 35, LR 0.000105:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.22batch/s]Training Epoch 35, LR 0.000105:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 35, LR 0.000105:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:11,  1.22s/batch]Training Epoch 35, LR 0.000105:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.03batch/s]Training Epoch 35, LR 0.000105:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.25batch/s]Training Epoch 35, LR 0.000105:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.48batch/s]Training Epoch 35, LR 0.000105:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.08s/batch]Training Epoch 35, LR 0.000105:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 35, LR 0.000105:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 35, LR 0.000105:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 35, LR 0.000105:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.13s/batch]Training Epoch 35, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.08batch/s]Training Epoch 35, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 35:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 35:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.55s/batch]Evaluating Epoch 35:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.61s/batch]Evaluating Epoch 35:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.06batch/s]Evaluating Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [35/200]:, train_loss=0.051, 
train_confusionMatrix:
tensor([[80,  9],
        [21, 34]], device='cuda:0')
train_accuracy=0.7916666865348816, 
train_recall=0.6181818246841431, 
train_precision=0.7906976938247681, 
train_specificity=0.898876428604126, 
train_balance_acc=0.7585291266441345,
 train_f1_score=0.6938775777816772,
 train_auc=0.8396322727203369

Epoch [35/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[13,  6],
        [ 8,  5]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.38461539149284363, 
eval_precision=0.4545454680919647, 
eval_specificity=0.6842105388641357, 
eval_balance_acc=0.5344129800796509,
 eval_f1_score=0.4166666567325592,
 eval_auc=0.5587044358253479


Epoch: 36/200
Training Epoch 36, LR 0.000076:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 36, LR 0.000076:   6%|â–Œ         | 1/18 [00:04<01:09,  4.08s/batch]Training Epoch 36, LR 0.000076:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.92s/batch]Training Epoch 36, LR 0.000076:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.23s/batch]Training Epoch 36, LR 0.000076:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 36, LR 0.000076:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.44s/batch]Training Epoch 36, LR 0.000076:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.09s/batch]Training Epoch 36, LR 0.000076:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.16batch/s]Training Epoch 36, LR 0.000076:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.39batch/s]Training Epoch 36, LR 0.000076:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.22s/batch]Training Epoch 36, LR 0.000076:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.03batch/s]Training Epoch 36, LR 0.000076:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.26batch/s]Training Epoch 36, LR 0.000076:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.48batch/s]Training Epoch 36, LR 0.000076:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:15<00:06,  1.27s/batch]Training Epoch 36, LR 0.000076:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:04,  1.01s/batch]Training Epoch 36, LR 0.000076:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.21batch/s]Training Epoch 36, LR 0.000076:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.43batch/s]Training Epoch 36, LR 0.000076:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.16s/batch]Training Epoch 36, LR 0.000076: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.07batch/s]Training Epoch 36, LR 0.000076: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 36:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 36:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.01s/batch]Evaluating Epoch 36:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.74s/batch]Evaluating Epoch 36:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.02s/batch]Evaluating Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.48batch/s]Evaluating Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.13s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [36/200]:, train_loss=0.053, 
train_confusionMatrix:
tensor([[77, 13],
        [20, 34]], device='cuda:0')
train_accuracy=0.7708333134651184, 
train_recall=0.6296296119689941, 
train_precision=0.7234042286872864, 
train_specificity=0.855555534362793, 
train_balance_acc=0.7425925731658936,
 train_f1_score=0.6732673048973083,
 train_auc=0.8195472955703735

Epoch [36/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[14,  7],
        [ 8,  3]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.27272728085517883, 
eval_precision=0.30000001192092896, 
eval_specificity=0.6666666865348816, 
eval_balance_acc=0.4696969985961914,
 eval_f1_score=0.2857142984867096,
 eval_auc=0.5627705454826355


Epoch: 37/200
Training Epoch 37, LR 0.000053:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 37, LR 0.000053:   6%|â–Œ         | 1/18 [00:04<01:10,  4.14s/batch]Training Epoch 37, LR 0.000053:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.94s/batch]Training Epoch 37, LR 0.000053:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.24s/batch]Training Epoch 37, LR 0.000053:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 37, LR 0.000053:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.36s/batch]Training Epoch 37, LR 0.000053:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 37, LR 0.000053:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 37, LR 0.000053:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 37, LR 0.000053:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 37, LR 0.000053:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.10batch/s]Training Epoch 37, LR 0.000053:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 37, LR 0.000053:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.54batch/s]Training Epoch 37, LR 0.000053:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.12s/batch]Training Epoch 37, LR 0.000053:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 37, LR 0.000053:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.33batch/s]Training Epoch 37, LR 0.000053:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.54batch/s]Training Epoch 37, LR 0.000053:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.06s/batch]Training Epoch 37, LR 0.000053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 37, LR 0.000053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 37:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 37:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.68s/batch]Evaluating Epoch 37:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.61s/batch]Evaluating Epoch 37:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.06batch/s]Evaluating Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [37/200]:, train_loss=0.051, 
train_confusionMatrix:
tensor([[77, 12],
        [18, 37]], device='cuda:0')
train_accuracy=0.7916666865348816, 
train_recall=0.6727272868156433, 
train_precision=0.7551020383834839, 
train_specificity=0.8651685118675232, 
train_balance_acc=0.7689478993415833,
 train_f1_score=0.7115384340286255,
 train_auc=0.8510724902153015

Epoch [37/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[11,  7],
        [ 9,  5]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.3571428656578064, 
eval_precision=0.4166666567325592, 
eval_specificity=0.6111111044883728, 
eval_balance_acc=0.4841269850730896,
 eval_f1_score=0.38461539149284363,
 eval_auc=0.591269850730896


Epoch: 38/200
Training Epoch 38, LR 0.000034:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 38, LR 0.000034:   6%|â–Œ         | 1/18 [00:03<01:04,  3.80s/batch]Training Epoch 38, LR 0.000034:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 38, LR 0.000034:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 38, LR 0.000034:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 38, LR 0.000034:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.39s/batch]Training Epoch 38, LR 0.000034:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 38, LR 0.000034:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.19batch/s]Training Epoch 38, LR 0.000034:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.43batch/s]Training Epoch 38, LR 0.000034:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.19s/batch]Training Epoch 38, LR 0.000034:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.06batch/s]Training Epoch 38, LR 0.000034:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.28batch/s]Training Epoch 38, LR 0.000034:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.50batch/s]Training Epoch 38, LR 0.000034:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.19s/batch]Training Epoch 38, LR 0.000034:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.05batch/s]Training Epoch 38, LR 0.000034:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.27batch/s]Training Epoch 38, LR 0.000034:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.49batch/s]Training Epoch 38, LR 0.000034:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.15s/batch]Training Epoch 38, LR 0.000034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.08batch/s]Training Epoch 38, LR 0.000034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 38:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 38:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.78s/batch]Evaluating Epoch 38:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.75s/batch]Evaluating Epoch 38:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.02s/batch]Evaluating Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.46batch/s]Evaluating Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.12s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [38/200]:, train_loss=0.047, 
train_confusionMatrix:
tensor([[83,  6],
        [15, 40]], device='cuda:0')
train_accuracy=0.8541666865348816, 
train_recall=0.7272727489471436, 
train_precision=0.8695651888847351, 
train_specificity=0.932584285736084, 
train_balance_acc=0.8299285173416138,
 train_f1_score=0.7920792102813721,
 train_auc=0.8821245431900024

Epoch [38/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[16,  5],
        [ 7,  4]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.3636363744735718, 
eval_precision=0.4444444477558136, 
eval_specificity=0.761904776096344, 
eval_balance_acc=0.5627706050872803,
 eval_f1_score=0.4000000059604645,
 eval_auc=0.6796537041664124


Epoch: 39/200
Training Epoch 39, LR 0.000021:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 39, LR 0.000021:   6%|â–Œ         | 1/18 [00:04<01:10,  4.15s/batch]Training Epoch 39, LR 0.000021:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.95s/batch]Training Epoch 39, LR 0.000021:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.25s/batch]Training Epoch 39, LR 0.000021:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.09batch/s]Training Epoch 39, LR 0.000021:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.39s/batch]Training Epoch 39, LR 0.000021:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.10s/batch]Training Epoch 39, LR 0.000021:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.15batch/s]Training Epoch 39, LR 0.000021:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.38batch/s]Training Epoch 39, LR 0.000021:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.15s/batch]Training Epoch 39, LR 0.000021:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:08,  1.02s/batch]Training Epoch 39, LR 0.000021:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.20batch/s]Training Epoch 39, LR 0.000021:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.42batch/s]Training Epoch 39, LR 0.000021:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:06,  1.20s/batch]Training Epoch 39, LR 0.000021:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.04batch/s]Training Epoch 39, LR 0.000021:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.26batch/s]Training Epoch 39, LR 0.000021:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.47batch/s]Training Epoch 39, LR 0.000021:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.12s/batch]Training Epoch 39, LR 0.000021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.11batch/s]Training Epoch 39, LR 0.000021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 39:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 39:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.48s/batch]Evaluating Epoch 39:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 39:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.65batch/s]Evaluating Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [39/200]:, train_loss=0.049, 
train_confusionMatrix:
tensor([[80,  9],
        [18, 37]], device='cuda:0')
train_accuracy=0.8125, 
train_recall=0.6727272868156433, 
train_precision=0.804347813129425, 
train_specificity=0.898876428604126, 
train_balance_acc=0.785801887512207,
 train_f1_score=0.7326732873916626,
 train_auc=0.8641470670700073

Epoch [39/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[14,  6],
        [ 9,  3]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.25, 
eval_precision=0.3333333432674408, 
eval_specificity=0.699999988079071, 
eval_balance_acc=0.4749999940395355,
 eval_f1_score=0.2857142984867096,
 eval_auc=0.5291666388511658


Epoch: 40/200
Training Epoch 40, LR 0.000013:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 40, LR 0.000013:   6%|â–Œ         | 1/18 [00:04<01:12,  4.24s/batch]Training Epoch 40, LR 0.000013:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.98s/batch]Training Epoch 40, LR 0.000013:  17%|â–ˆâ–‹        | 3/18 [00:05<00:18,  1.26s/batch]Training Epoch 40, LR 0.000013:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.08batch/s]Training Epoch 40, LR 0.000013:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.36s/batch]Training Epoch 40, LR 0.000013:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 40, LR 0.000013:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 40, LR 0.000013:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 40, LR 0.000013:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 40, LR 0.000013:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.10batch/s]Training Epoch 40, LR 0.000013:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 40, LR 0.000013:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.54batch/s]Training Epoch 40, LR 0.000013:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.19s/batch]Training Epoch 40, LR 0.000013:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.05batch/s]Training Epoch 40, LR 0.000013:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.27batch/s]Training Epoch 40, LR 0.000013:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.49batch/s]Training Epoch 40, LR 0.000013:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.09s/batch]Training Epoch 40, LR 0.000013: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.13batch/s]Training Epoch 40, LR 0.000013: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 40:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 40:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.00s/batch]Evaluating Epoch 40:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.74s/batch]Evaluating Epoch 40:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.01s/batch]Evaluating Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.48batch/s]Evaluating Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.13s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [40/200]:, train_loss=0.050, 
train_confusionMatrix:
tensor([[77, 12],
        [17, 38]], device='cuda:0')
train_accuracy=0.7986111044883728, 
train_recall=0.6909090876579285, 
train_precision=0.7599999904632568, 
train_specificity=0.8651685118675232, 
train_balance_acc=0.7780387997627258,
 train_f1_score=0.723809540271759,
 train_auc=0.8594484329223633

Epoch [40/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[16,  4],
        [ 7,  5]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.4166666567325592, 
eval_precision=0.5555555820465088, 
eval_specificity=0.800000011920929, 
eval_balance_acc=0.6083333492279053,
 eval_f1_score=0.4761904776096344,
 eval_auc=0.7083333134651184


Epoch: 41/200
Training Epoch 41, LR 0.001000:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 41, LR 0.001000:   6%|â–Œ         | 1/18 [00:03<01:03,  3.76s/batch]Training Epoch 41, LR 0.001000:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 41, LR 0.001000:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 41, LR 0.001000:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.16batch/s]Training Epoch 41, LR 0.001000:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.28s/batch]Training Epoch 41, LR 0.001000:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 41, LR 0.001000:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 41, LR 0.001000:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 41, LR 0.001000:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.16s/batch]Training Epoch 41, LR 0.001000:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.08batch/s]Training Epoch 41, LR 0.001000:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.30batch/s]Training Epoch 41, LR 0.001000:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.51batch/s]Training Epoch 41, LR 0.001000:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.15s/batch]Training Epoch 41, LR 0.001000:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.08batch/s]Training Epoch 41, LR 0.001000:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.30batch/s]Training Epoch 41, LR 0.001000:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.52batch/s]Training Epoch 41, LR 0.001000:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.12s/batch]Training Epoch 41, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.10batch/s]Training Epoch 41, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 41:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 41:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.66s/batch]Evaluating Epoch 41:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.60s/batch]Evaluating Epoch 41:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.06batch/s]Evaluating Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [41/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[73, 17],
        [29, 25]], device='cuda:0')
train_accuracy=0.6805555820465088, 
train_recall=0.46296295523643494, 
train_precision=0.5952380895614624, 
train_specificity=0.8111110925674438, 
train_balance_acc=0.6370370388031006,
 train_f1_score=0.5208333134651184,
 train_auc=0.7063785791397095

Epoch [41/200]:, eval_loss=0.021, 
eval_confusionMatrix:
tensor([[ 0, 20],
        [ 0, 12]], device='cuda:0')
eval_accuracy=0.375, 
eval_recall=1.0, 
eval_precision=0.375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5454545617103577,
 eval_auc=0.5


Epoch: 42/200
Training Epoch 42, LR 0.001000:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 42, LR 0.001000:   6%|â–Œ         | 1/18 [00:04<01:12,  4.28s/batch]Training Epoch 42, LR 0.001000:  11%|â–ˆ         | 2/18 [00:04<00:32,  2.00s/batch]Training Epoch 42, LR 0.001000:  17%|â–ˆâ–‹        | 3/18 [00:05<00:19,  1.27s/batch]Training Epoch 42, LR 0.001000:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:13,  1.07batch/s]Training Epoch 42, LR 0.001000:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:19,  1.51s/batch]Training Epoch 42, LR 0.001000:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.13s/batch]Training Epoch 42, LR 0.001000:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.12batch/s]Training Epoch 42, LR 0.001000:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:09<00:07,  1.35batch/s]Training Epoch 42, LR 0.001000:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.29s/batch]Training Epoch 42, LR 0.001000:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:12<00:08,  1.02s/batch]Training Epoch 42, LR 0.001000:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.21batch/s]Training Epoch 42, LR 0.001000:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.43batch/s]Training Epoch 42, LR 0.001000:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:15<00:05,  1.15s/batch]Training Epoch 42, LR 0.001000:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.08batch/s]Training Epoch 42, LR 0.001000:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.30batch/s]Training Epoch 42, LR 0.001000:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.51batch/s]Training Epoch 42, LR 0.001000:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.17s/batch]Training Epoch 42, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.06batch/s]Training Epoch 42, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:19<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 42:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 42:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.18s/batch]Evaluating Epoch 42:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.81s/batch]Evaluating Epoch 42:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.05s/batch]Evaluating Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.44batch/s]Evaluating Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.17s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [42/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[78, 12],
        [29, 25]], device='cuda:0')
train_accuracy=0.7152777910232544, 
train_recall=0.46296295523643494, 
train_precision=0.6756756901741028, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.664814829826355,
 train_f1_score=0.5494505763053894,
 train_auc=0.7347736954689026

Epoch [42/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[16,  2],
        [12,  2]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.1428571492433548, 
eval_precision=0.5, 
eval_specificity=0.8888888955116272, 
eval_balance_acc=0.5158730149269104,
 eval_f1_score=0.2222222238779068,
 eval_auc=0.5952380895614624


Epoch: 43/200
Training Epoch 43, LR 0.000999:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 43, LR 0.000999:   6%|â–Œ         | 1/18 [00:04<01:11,  4.23s/batch]Training Epoch 43, LR 0.000999:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.98s/batch]Training Epoch 43, LR 0.000999:  17%|â–ˆâ–‹        | 3/18 [00:05<00:18,  1.26s/batch]Training Epoch 43, LR 0.000999:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.08batch/s]Training Epoch 43, LR 0.000999:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.40s/batch]Training Epoch 43, LR 0.000999:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:12,  1.06s/batch]Training Epoch 43, LR 0.000999:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.18batch/s]Training Epoch 43, LR 0.000999:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.42batch/s]Training Epoch 43, LR 0.000999:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.14s/batch]Training Epoch 43, LR 0.000999:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.09batch/s]Training Epoch 43, LR 0.000999:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.31batch/s]Training Epoch 43, LR 0.000999:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.53batch/s]Training Epoch 43, LR 0.000999:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.13s/batch]Training Epoch 43, LR 0.000999:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.09batch/s]Training Epoch 43, LR 0.000999:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.31batch/s]Training Epoch 43, LR 0.000999:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.53batch/s]Training Epoch 43, LR 0.000999:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.05s/batch]Training Epoch 43, LR 0.000999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.17batch/s]Training Epoch 43, LR 0.000999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 43:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 43:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.24s/batch]Evaluating Epoch 43:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.83s/batch]Evaluating Epoch 43:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.07s/batch]Evaluating Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.42batch/s]Evaluating Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.19s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [43/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[76, 13],
        [27, 28]], device='cuda:0')
train_accuracy=0.7222222089767456, 
train_recall=0.5090909004211426, 
train_precision=0.6829268336296082, 
train_specificity=0.8539325594902039, 
train_balance_acc=0.6815117597579956,
 train_f1_score=0.5833333134651184,
 train_auc=0.7131767272949219

Epoch [43/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 8, 14],
        [ 3,  7]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=0.699999988079071, 
eval_precision=0.3333333432674408, 
eval_specificity=0.3636363744735718, 
eval_balance_acc=0.531818151473999,
 eval_f1_score=0.4516128897666931,
 eval_auc=0.5409090518951416


Epoch: 44/200
Training Epoch 44, LR 0.000997:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 44, LR 0.000997:   6%|â–Œ         | 1/18 [00:03<01:06,  3.92s/batch]Training Epoch 44, LR 0.000997:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 44, LR 0.000997:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 44, LR 0.000997:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 44, LR 0.000997:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.28s/batch]Training Epoch 44, LR 0.000997:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 44, LR 0.000997:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 44, LR 0.000997:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 44, LR 0.000997:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.17s/batch]Training Epoch 44, LR 0.000997:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.07batch/s]Training Epoch 44, LR 0.000997:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.28batch/s]Training Epoch 44, LR 0.000997:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:04,  1.50batch/s]Training Epoch 44, LR 0.000997:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:06,  1.24s/batch]Training Epoch 44, LR 0.000997:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.01batch/s]Training Epoch 44, LR 0.000997:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.23batch/s]Training Epoch 44, LR 0.000997:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.45batch/s]Training Epoch 44, LR 0.000997:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.16s/batch]Training Epoch 44, LR 0.000997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.07batch/s]Training Epoch 44, LR 0.000997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 44:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 44:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.00s/batch]Evaluating Epoch 44:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.74s/batch]Evaluating Epoch 44:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.02s/batch]Evaluating Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.48batch/s]Evaluating Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.13s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [44/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[73, 16],
        [34, 21]], device='cuda:0')
train_accuracy=0.6527777910232544, 
train_recall=0.38181817531585693, 
train_precision=0.5675675868988037, 
train_specificity=0.8202247023582458, 
train_balance_acc=0.601021409034729,
 train_f1_score=0.45652174949645996,
 train_auc=0.7362614870071411

Epoch [44/200]:, eval_loss=0.019, 
eval_confusionMatrix:
tensor([[ 0, 18],
        [ 0, 14]], device='cuda:0')
eval_accuracy=0.4375, 
eval_recall=1.0, 
eval_precision=0.4375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.6086956262588501,
 eval_auc=0.5


Epoch: 45/200
Training Epoch 45, LR 0.000995:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 45, LR 0.000995:   6%|â–Œ         | 1/18 [00:04<01:09,  4.08s/batch]Training Epoch 45, LR 0.000995:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.92s/batch]Training Epoch 45, LR 0.000995:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.23s/batch]Training Epoch 45, LR 0.000995:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 45, LR 0.000995:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 45, LR 0.000995:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 45, LR 0.000995:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.22batch/s]Training Epoch 45, LR 0.000995:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 45, LR 0.000995:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.11s/batch]Training Epoch 45, LR 0.000995:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.12batch/s]Training Epoch 45, LR 0.000995:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 45, LR 0.000995:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 45, LR 0.000995:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.13s/batch]Training Epoch 45, LR 0.000995:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.10batch/s]Training Epoch 45, LR 0.000995:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.32batch/s]Training Epoch 45, LR 0.000995:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.54batch/s]Training Epoch 45, LR 0.000995:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.00s/batch]Training Epoch 45, LR 0.000995: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 45, LR 0.000995: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 45:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 45:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.58s/batch]Evaluating Epoch 45:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 45:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [45/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[67, 23],
        [24, 30]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.5555555820465088, 
train_precision=0.5660377144813538, 
train_specificity=0.7444444298744202, 
train_balance_acc=0.6499999761581421,
 train_f1_score=0.5607476830482483,
 train_auc=0.7037037014961243

Epoch [45/200]:, eval_loss=0.021, 
eval_confusionMatrix:
tensor([[ 0, 20],
        [ 0, 12]], device='cuda:0')
eval_accuracy=0.375, 
eval_recall=1.0, 
eval_precision=0.375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5454545617103577,
 eval_auc=0.574999988079071


Epoch: 46/200
Training Epoch 46, LR 0.000992:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 46, LR 0.000992:   6%|â–Œ         | 1/18 [00:03<01:06,  3.93s/batch]Training Epoch 46, LR 0.000992:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.86s/batch]Training Epoch 46, LR 0.000992:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 46, LR 0.000992:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 46, LR 0.000992:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 46, LR 0.000992:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 46, LR 0.000992:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 46, LR 0.000992:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 46, LR 0.000992:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 46, LR 0.000992:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.09batch/s]Training Epoch 46, LR 0.000992:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 46, LR 0.000992:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 46, LR 0.000992:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.01s/batch]Training Epoch 46, LR 0.000992:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 46, LR 0.000992:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.32batch/s]Training Epoch 46, LR 0.000992:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.54batch/s]Training Epoch 46, LR 0.000992:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 46, LR 0.000992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.09batch/s]Training Epoch 46, LR 0.000992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 46:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 46:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.64s/batch]Evaluating Epoch 46:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.64s/batch]Evaluating Epoch 46:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.56batch/s]Evaluating Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [46/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[70, 19],
        [32, 23]], device='cuda:0')
train_accuracy=0.6458333134651184, 
train_recall=0.41818180680274963, 
train_precision=0.5476190447807312, 
train_specificity=0.7865168452262878, 
train_balance_acc=0.6023493409156799,
 train_f1_score=0.47422680258750916,
 train_auc=0.697650671005249

Epoch [46/200]:, eval_loss=0.019, 
eval_confusionMatrix:
tensor([[ 1, 18],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.4375, 
eval_recall=1.0, 
eval_precision=0.4193548262119293, 
eval_specificity=0.05263157933950424, 
eval_balance_acc=0.5263158082962036,
 eval_f1_score=0.5909090638160706,
 eval_auc=0.6032388806343079


Epoch: 47/200
Training Epoch 47, LR 0.000989:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 47, LR 0.000989:   6%|â–Œ         | 1/18 [00:04<01:08,  4.02s/batch]Training Epoch 47, LR 0.000989:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.89s/batch]Training Epoch 47, LR 0.000989:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 47, LR 0.000989:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 47, LR 0.000989:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 47, LR 0.000989:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.00batch/s]Training Epoch 47, LR 0.000989:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.24batch/s]Training Epoch 47, LR 0.000989:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 47, LR 0.000989:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 47, LR 0.000989:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 47, LR 0.000989:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 47, LR 0.000989:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 47, LR 0.000989:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.12s/batch]Training Epoch 47, LR 0.000989:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 47, LR 0.000989:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.33batch/s]Training Epoch 47, LR 0.000989:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.54batch/s]Training Epoch 47, LR 0.000989:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.09s/batch]Training Epoch 47, LR 0.000989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.13batch/s]Training Epoch 47, LR 0.000989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 47:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 47:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 47:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 47:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [47/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[74, 15],
        [26, 29]], device='cuda:0')
train_accuracy=0.7152777910232544, 
train_recall=0.5272727012634277, 
train_precision=0.6590909361839294, 
train_specificity=0.8314606547355652, 
train_balance_acc=0.6793667078018188,
 train_f1_score=0.5858585834503174,
 train_auc=0.7117466926574707

Epoch [47/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[14,  5],
        [ 9,  4]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.3076923191547394, 
eval_precision=0.4444444477558136, 
eval_specificity=0.7368420958518982, 
eval_balance_acc=0.52226722240448,
 eval_f1_score=0.3636363744735718,
 eval_auc=0.5344129204750061


Epoch: 48/200
Training Epoch 48, LR 0.000985:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 48, LR 0.000985:   6%|â–Œ         | 1/18 [00:03<01:02,  3.65s/batch]Training Epoch 48, LR 0.000985:  11%|â–ˆ         | 2/18 [00:04<00:27,  1.74s/batch]Training Epoch 48, LR 0.000985:  17%|â–ˆâ–‹        | 3/18 [00:04<00:16,  1.13s/batch]Training Epoch 48, LR 0.000985:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.18batch/s]Training Epoch 48, LR 0.000985:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.30s/batch]Training Epoch 48, LR 0.000985:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.00batch/s]Training Epoch 48, LR 0.000985:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 48, LR 0.000985:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 48, LR 0.000985:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 48, LR 0.000985:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 48, LR 0.000985:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 48, LR 0.000985:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 48, LR 0.000985:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 48, LR 0.000985:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.12batch/s]Training Epoch 48, LR 0.000985:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.34batch/s]Training Epoch 48, LR 0.000985:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.56batch/s]Training Epoch 48, LR 0.000985:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 48, LR 0.000985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 48, LR 0.000985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 48:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 48:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.48s/batch]Evaluating Epoch 48:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.52s/batch]Evaluating Epoch 48:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.66batch/s]Evaluating Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [48/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[75, 14],
        [31, 24]], device='cuda:0')
train_accuracy=0.6875, 
train_recall=0.4363636374473572, 
train_precision=0.6315789222717285, 
train_specificity=0.8426966071128845, 
train_balance_acc=0.6395301222801208,
 train_f1_score=0.5161290168762207,
 train_auc=0.686618983745575

Epoch [48/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[16,  3],
        [11,  2]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.1538461595773697, 
eval_precision=0.4000000059604645, 
eval_specificity=0.8421052694320679, 
eval_balance_acc=0.4979757070541382,
 eval_f1_score=0.2222222238779068,
 eval_auc=0.6072874665260315


Epoch: 49/200
Training Epoch 49, LR 0.000981:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 49, LR 0.000981:   6%|â–Œ         | 1/18 [00:03<01:04,  3.80s/batch]Training Epoch 49, LR 0.000981:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 49, LR 0.000981:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 49, LR 0.000981:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 49, LR 0.000981:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.26s/batch]Training Epoch 49, LR 0.000981:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 49, LR 0.000981:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 49, LR 0.000981:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.43batch/s]Training Epoch 49, LR 0.000981:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 49, LR 0.000981:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.00batch/s]Training Epoch 49, LR 0.000981:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.23batch/s]Training Epoch 49, LR 0.000981:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:04,  1.45batch/s]Training Epoch 49, LR 0.000981:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.01batch/s]Training Epoch 49, LR 0.000981:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 49, LR 0.000981:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 49, LR 0.000981:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 49, LR 0.000981:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.11batch/s]Training Epoch 49, LR 0.000981: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 49, LR 0.000981: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 49:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 49:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.51s/batch]Evaluating Epoch 49:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.68s/batch]Evaluating Epoch 49:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.02batch/s]Evaluating Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.52batch/s]Evaluating Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [49/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[74, 16],
        [30, 24]], device='cuda:0')
train_accuracy=0.6805555820465088, 
train_recall=0.4444444477558136, 
train_precision=0.6000000238418579, 
train_specificity=0.8222222328186035, 
train_balance_acc=0.6333333253860474,
 train_f1_score=0.5106382966041565,
 train_auc=0.7547324895858765

Epoch [49/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[19,  1],
        [12,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.949999988079071, 
eval_balance_acc=0.4749999940395355,
 eval_f1_score=0.0,
 eval_auc=0.7333333492279053


Epoch: 50/200
Training Epoch 50, LR 0.000976:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 50, LR 0.000976:   6%|â–Œ         | 1/18 [00:03<01:03,  3.76s/batch]Training Epoch 50, LR 0.000976:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 50, LR 0.000976:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 50, LR 0.000976:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 50, LR 0.000976:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.32s/batch]Training Epoch 50, LR 0.000976:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 50, LR 0.000976:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.23batch/s]Training Epoch 50, LR 0.000976:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 50, LR 0.000976:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.14s/batch]Training Epoch 50, LR 0.000976:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 50, LR 0.000976:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 50, LR 0.000976:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 50, LR 0.000976:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 50, LR 0.000976:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 50, LR 0.000976:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 50, LR 0.000976:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 50, LR 0.000976:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 50, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.23batch/s]Training Epoch 50, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 50:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 50:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.66s/batch]Evaluating Epoch 50:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.62s/batch]Evaluating Epoch 50:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.06batch/s]Evaluating Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [50/200]:, train_loss=0.061, 
train_confusionMatrix:
tensor([[68, 21],
        [26, 29]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.5272727012634277, 
train_precision=0.5799999833106995, 
train_specificity=0.7640449404716492, 
train_balance_acc=0.6456588506698608,
 train_f1_score=0.5523809790611267,
 train_auc=0.6988763809204102

Epoch [50/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.6833333373069763


Epoch: 51/200
Training Epoch 51, LR 0.000970:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 51, LR 0.000970:   6%|â–Œ         | 1/18 [00:03<01:07,  3.97s/batch]Training Epoch 51, LR 0.000970:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 51, LR 0.000970:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 51, LR 0.000970:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 51, LR 0.000970:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.32s/batch]Training Epoch 51, LR 0.000970:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 51, LR 0.000970:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.23batch/s]Training Epoch 51, LR 0.000970:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 51, LR 0.000970:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.17s/batch]Training Epoch 51, LR 0.000970:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.07batch/s]Training Epoch 51, LR 0.000970:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.29batch/s]Training Epoch 51, LR 0.000970:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.51batch/s]Training Epoch 51, LR 0.000970:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.14s/batch]Training Epoch 51, LR 0.000970:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.09batch/s]Training Epoch 51, LR 0.000970:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.31batch/s]Training Epoch 51, LR 0.000970:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.53batch/s]Training Epoch 51, LR 0.000970:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.12s/batch]Training Epoch 51, LR 0.000970: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.10batch/s]Training Epoch 51, LR 0.000970: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 51:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 51:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.73s/batch]Evaluating Epoch 51:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.63s/batch]Evaluating Epoch 51:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.57batch/s]Evaluating Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [51/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[78, 12],
        [29, 25]], device='cuda:0')
train_accuracy=0.7152777910232544, 
train_recall=0.46296295523643494, 
train_precision=0.6756756901741028, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.664814829826355,
 train_f1_score=0.5494505763053894,
 train_auc=0.7253085970878601

Epoch [51/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 5, 15],
        [ 1, 11]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.9166666865348816, 
eval_precision=0.42307692766189575, 
eval_specificity=0.25, 
eval_balance_acc=0.5833333730697632,
 eval_f1_score=0.5789473652839661,
 eval_auc=0.6291666626930237


Epoch: 52/200
Training Epoch 52, LR 0.000964:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 52, LR 0.000964:   6%|â–Œ         | 1/18 [00:03<01:07,  3.98s/batch]Training Epoch 52, LR 0.000964:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.88s/batch]Training Epoch 52, LR 0.000964:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 52, LR 0.000964:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 52, LR 0.000964:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.37s/batch]Training Epoch 52, LR 0.000964:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 52, LR 0.000964:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 52, LR 0.000964:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 52, LR 0.000964:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.20s/batch]Training Epoch 52, LR 0.000964:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.05batch/s]Training Epoch 52, LR 0.000964:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.27batch/s]Training Epoch 52, LR 0.000964:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.49batch/s]Training Epoch 52, LR 0.000964:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.12s/batch]Training Epoch 52, LR 0.000964:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 52, LR 0.000964:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.33batch/s]Training Epoch 52, LR 0.000964:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.55batch/s]Training Epoch 52, LR 0.000964:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.05s/batch]Training Epoch 52, LR 0.000964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 52, LR 0.000964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 52:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 52:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.52s/batch]Evaluating Epoch 52:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 52:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [52/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[77, 13],
        [29, 25]], device='cuda:0')
train_accuracy=0.7083333134651184, 
train_recall=0.46296295523643494, 
train_precision=0.6578947305679321, 
train_specificity=0.855555534362793, 
train_balance_acc=0.6592592597007751,
 train_f1_score=0.54347825050354,
 train_auc=0.7584362030029297

Epoch [52/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[16,  5],
        [ 8,  3]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.27272728085517883, 
eval_precision=0.375, 
eval_specificity=0.761904776096344, 
eval_balance_acc=0.5173160433769226,
 eval_f1_score=0.31578946113586426,
 eval_auc=0.6406926512718201


Epoch: 53/200
Training Epoch 53, LR 0.000957:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 53, LR 0.000957:   6%|â–Œ         | 1/18 [00:03<01:05,  3.87s/batch]Training Epoch 53, LR 0.000957:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 53, LR 0.000957:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 53, LR 0.000957:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 53, LR 0.000957:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 53, LR 0.000957:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 53, LR 0.000957:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.22batch/s]Training Epoch 53, LR 0.000957:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 53, LR 0.000957:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.15s/batch]Training Epoch 53, LR 0.000957:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.09batch/s]Training Epoch 53, LR 0.000957:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.31batch/s]Training Epoch 53, LR 0.000957:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 53, LR 0.000957:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 53, LR 0.000957:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 53, LR 0.000957:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 53, LR 0.000957:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.58batch/s]Training Epoch 53, LR 0.000957:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.05s/batch]Training Epoch 53, LR 0.000957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 53, LR 0.000957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 53:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 53:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.55s/batch]Evaluating Epoch 53:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 53:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [53/200]:, train_loss=0.054, 
train_confusionMatrix:
tensor([[77, 12],
        [21, 34]], device='cuda:0')
train_accuracy=0.7708333134651184, 
train_recall=0.6181818246841431, 
train_precision=0.739130437374115, 
train_specificity=0.8651685118675232, 
train_balance_acc=0.7416751384735107,
 train_f1_score=0.6732673048973083,
 train_auc=0.7679264545440674

Epoch [53/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  1],
        [11,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.9523809552192688, 
eval_balance_acc=0.4761904776096344,
 eval_f1_score=0.0,
 eval_auc=0.7186146974563599


Epoch: 54/200
Training Epoch 54, LR 0.000950:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 54, LR 0.000950:   6%|â–Œ         | 1/18 [00:03<01:07,  3.99s/batch]Training Epoch 54, LR 0.000950:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.88s/batch]Training Epoch 54, LR 0.000950:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 54, LR 0.000950:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 54, LR 0.000950:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 54, LR 0.000950:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 54, LR 0.000950:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 54, LR 0.000950:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 54, LR 0.000950:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.20s/batch]Training Epoch 54, LR 0.000950:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.05batch/s]Training Epoch 54, LR 0.000950:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.27batch/s]Training Epoch 54, LR 0.000950:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.50batch/s]Training Epoch 54, LR 0.000950:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.06s/batch]Training Epoch 54, LR 0.000950:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.16batch/s]Training Epoch 54, LR 0.000950:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 54, LR 0.000950:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.60batch/s]Training Epoch 54, LR 0.000950:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.02s/batch]Training Epoch 54, LR 0.000950: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 54, LR 0.000950: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 54:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 54:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.48s/batch]Evaluating Epoch 54:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.52s/batch]Evaluating Epoch 54:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [54/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[74, 15],
        [20, 35]], device='cuda:0')
train_accuracy=0.7569444179534912, 
train_recall=0.6363636255264282, 
train_precision=0.699999988079071, 
train_specificity=0.8314606547355652, 
train_balance_acc=0.7339121103286743,
 train_f1_score=0.6666666865348816,
 train_auc=0.7387129664421082

Epoch [54/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[14,  7],
        [ 8,  3]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.27272728085517883, 
eval_precision=0.30000001192092896, 
eval_specificity=0.6666666865348816, 
eval_balance_acc=0.4696969985961914,
 eval_f1_score=0.2857142984867096,
 eval_auc=0.5670995712280273


Epoch: 55/200
Training Epoch 55, LR 0.000942:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 55, LR 0.000942:   6%|â–Œ         | 1/18 [00:04<01:10,  4.12s/batch]Training Epoch 55, LR 0.000942:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.94s/batch]Training Epoch 55, LR 0.000942:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.24s/batch]Training Epoch 55, LR 0.000942:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 55, LR 0.000942:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 55, LR 0.000942:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 55, LR 0.000942:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.25batch/s]Training Epoch 55, LR 0.000942:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 55, LR 0.000942:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.15s/batch]Training Epoch 55, LR 0.000942:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.09batch/s]Training Epoch 55, LR 0.000942:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.31batch/s]Training Epoch 55, LR 0.000942:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 55, LR 0.000942:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.09s/batch]Training Epoch 55, LR 0.000942:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 55, LR 0.000942:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 55, LR 0.000942:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 55, LR 0.000942:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 55, LR 0.000942: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 55, LR 0.000942: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 55:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 55:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.66s/batch]Evaluating Epoch 55:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.60s/batch]Evaluating Epoch 55:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.59batch/s]Evaluating Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [55/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[79, 10],
        [25, 30]], device='cuda:0')
train_accuracy=0.7569444179534912, 
train_recall=0.5454545617103577, 
train_precision=0.75, 
train_specificity=0.8876404762268066, 
train_balance_acc=0.7165474891662598,
 train_f1_score=0.6315789222717285,
 train_auc=0.7530132532119751

Epoch [55/200]:, eval_loss=0.021, 
eval_confusionMatrix:
tensor([[ 0, 21],
        [ 0, 11]], device='cuda:0')
eval_accuracy=0.34375, 
eval_recall=1.0, 
eval_precision=0.34375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5116279125213623,
 eval_auc=0.6103895902633667


Epoch: 56/200
Training Epoch 56, LR 0.000934:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 56, LR 0.000934:   6%|â–Œ         | 1/18 [00:03<01:05,  3.84s/batch]Training Epoch 56, LR 0.000934:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 56, LR 0.000934:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 56, LR 0.000934:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 56, LR 0.000934:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.26s/batch]Training Epoch 56, LR 0.000934:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 56, LR 0.000934:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 56, LR 0.000934:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 56, LR 0.000934:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.16s/batch]Training Epoch 56, LR 0.000934:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:08,  1.01s/batch]Training Epoch 56, LR 0.000934:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.21batch/s]Training Epoch 56, LR 0.000934:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:04,  1.44batch/s]Training Epoch 56, LR 0.000934:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.14s/batch]Training Epoch 56, LR 0.000934:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.01batch/s]Training Epoch 56, LR 0.000934:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.23batch/s]Training Epoch 56, LR 0.000934:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.44batch/s]Training Epoch 56, LR 0.000934:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.10s/batch]Training Epoch 56, LR 0.000934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.07batch/s]Training Epoch 56, LR 0.000934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 56:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 56:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.77s/batch]Evaluating Epoch 56:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.64s/batch]Evaluating Epoch 56:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [56/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[79, 10],
        [26, 29]], device='cuda:0')
train_accuracy=0.75, 
train_recall=0.5272727012634277, 
train_precision=0.7435897588729858, 
train_specificity=0.8876404762268066, 
train_balance_acc=0.7074565887451172,
 train_f1_score=0.6170212626457214,
 train_auc=0.7634320855140686

Epoch [56/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[14,  7],
        [ 8,  3]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.27272728085517883, 
eval_precision=0.30000001192092896, 
eval_specificity=0.6666666865348816, 
eval_balance_acc=0.4696969985961914,
 eval_f1_score=0.2857142984867096,
 eval_auc=0.5151515007019043


Epoch: 57/200
Training Epoch 57, LR 0.000925:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 57, LR 0.000925:   6%|â–Œ         | 1/18 [00:03<01:06,  3.91s/batch]Training Epoch 57, LR 0.000925:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 57, LR 0.000925:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 57, LR 0.000925:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 57, LR 0.000925:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.27s/batch]Training Epoch 57, LR 0.000925:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 57, LR 0.000925:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 57, LR 0.000925:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 57, LR 0.000925:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.04s/batch]Training Epoch 57, LR 0.000925:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.19batch/s]Training Epoch 57, LR 0.000925:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:04,  1.41batch/s]Training Epoch 57, LR 0.000925:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.63batch/s]Training Epoch 57, LR 0.000925:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 57, LR 0.000925:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.20batch/s]Training Epoch 57, LR 0.000925:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.42batch/s]Training Epoch 57, LR 0.000925:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.63batch/s]Training Epoch 57, LR 0.000925:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 57, LR 0.000925: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.21batch/s]Training Epoch 57, LR 0.000925: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 57:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 57:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.46s/batch]Evaluating Epoch 57:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.51s/batch]Evaluating Epoch 57:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.66batch/s]Evaluating Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [57/200]:, train_loss=0.050, 
train_confusionMatrix:
tensor([[79, 11],
        [17, 37]], device='cuda:0')
train_accuracy=0.8055555820465088, 
train_recall=0.6851851940155029, 
train_precision=0.7708333134651184, 
train_specificity=0.8777777552604675, 
train_balance_acc=0.7814815044403076,
 train_f1_score=0.7254902124404907,
 train_auc=0.817078173160553

Epoch [57/200]:, eval_loss=0.021, 
eval_confusionMatrix:
tensor([[ 0, 21],
        [ 0, 11]], device='cuda:0')
eval_accuracy=0.34375, 
eval_recall=1.0, 
eval_precision=0.34375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5116279125213623,
 eval_auc=0.5


Epoch: 58/200
Training Epoch 58, LR 0.000915:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 58, LR 0.000915:   6%|â–Œ         | 1/18 [00:03<01:06,  3.90s/batch]Training Epoch 58, LR 0.000915:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 58, LR 0.000915:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 58, LR 0.000915:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 58, LR 0.000915:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.36s/batch]Training Epoch 58, LR 0.000915:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 58, LR 0.000915:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 58, LR 0.000915:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 58, LR 0.000915:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.18s/batch]Training Epoch 58, LR 0.000915:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.06batch/s]Training Epoch 58, LR 0.000915:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.29batch/s]Training Epoch 58, LR 0.000915:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.51batch/s]Training Epoch 58, LR 0.000915:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.13s/batch]Training Epoch 58, LR 0.000915:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.09batch/s]Training Epoch 58, LR 0.000915:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.32batch/s]Training Epoch 58, LR 0.000915:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.53batch/s]Training Epoch 58, LR 0.000915:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.11s/batch]Training Epoch 58, LR 0.000915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.11batch/s]Training Epoch 58, LR 0.000915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 58:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 58:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.58s/batch]Evaluating Epoch 58:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 58:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [58/200]:, train_loss=0.052, 
train_confusionMatrix:
tensor([[75, 14],
        [16, 39]], device='cuda:0')
train_accuracy=0.7916666865348816, 
train_recall=0.7090908885002136, 
train_precision=0.7358490824699402, 
train_specificity=0.8426966071128845, 
train_balance_acc=0.7758937478065491,
 train_f1_score=0.7222222089767456,
 train_auc=0.7910112142562866

Epoch [58/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[14,  7],
        [ 9,  2]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.1818181872367859, 
eval_precision=0.2222222238779068, 
eval_specificity=0.6666666865348816, 
eval_balance_acc=0.42424243688583374,
 eval_f1_score=0.20000000298023224,
 eval_auc=0.5887446403503418


Epoch: 59/200
Training Epoch 59, LR 0.000905:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 59, LR 0.000905:   6%|â–Œ         | 1/18 [00:04<01:14,  4.41s/batch]Training Epoch 59, LR 0.000905:  11%|â–ˆ         | 2/18 [00:04<00:32,  2.05s/batch]Training Epoch 59, LR 0.000905:  17%|â–ˆâ–‹        | 3/18 [00:05<00:19,  1.30s/batch]Training Epoch 59, LR 0.000905:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:13,  1.05batch/s]Training Epoch 59, LR 0.000905:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.45s/batch]Training Epoch 59, LR 0.000905:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.10s/batch]Training Epoch 59, LR 0.000905:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.15batch/s]Training Epoch 59, LR 0.000905:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:09<00:07,  1.39batch/s]Training Epoch 59, LR 0.000905:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.13s/batch]Training Epoch 59, LR 0.000905:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.10batch/s]Training Epoch 59, LR 0.000905:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.33batch/s]Training Epoch 59, LR 0.000905:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.54batch/s]Training Epoch 59, LR 0.000905:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:06,  1.22s/batch]Training Epoch 59, LR 0.000905:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:03,  1.03batch/s]Training Epoch 59, LR 0.000905:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.24batch/s]Training Epoch 59, LR 0.000905:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.46batch/s]Training Epoch 59, LR 0.000905:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.10s/batch]Training Epoch 59, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.12batch/s]Training Epoch 59, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 59:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 59:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.06s/batch]Evaluating Epoch 59:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.76s/batch]Evaluating Epoch 59:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.03s/batch]Evaluating Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.47batch/s]Evaluating Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.14s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [59/200]:, train_loss=0.054, 
train_confusionMatrix:
tensor([[75, 15],
        [22, 32]], device='cuda:0')
train_accuracy=0.7430555820465088, 
train_recall=0.5925925970077515, 
train_precision=0.6808510422706604, 
train_specificity=0.8333333134651184, 
train_balance_acc=0.7129629850387573,
 train_f1_score=0.6336633563041687,
 train_auc=0.7693415880203247

Epoch [59/200]:, eval_loss=0.021, 
eval_confusionMatrix:
tensor([[ 0, 21],
        [ 0, 11]], device='cuda:0')
eval_accuracy=0.34375, 
eval_recall=1.0, 
eval_precision=0.34375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5116279125213623,
 eval_auc=0.4545454680919647


Epoch: 60/200
Training Epoch 60, LR 0.000895:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 60, LR 0.000895:   6%|â–Œ         | 1/18 [00:04<01:10,  4.14s/batch]Training Epoch 60, LR 0.000895:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.94s/batch]Training Epoch 60, LR 0.000895:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.24s/batch]Training Epoch 60, LR 0.000895:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 60, LR 0.000895:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 60, LR 0.000895:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 60, LR 0.000895:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 60, LR 0.000895:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 60, LR 0.000895:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.20s/batch]Training Epoch 60, LR 0.000895:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.05batch/s]Training Epoch 60, LR 0.000895:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.27batch/s]Training Epoch 60, LR 0.000895:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.49batch/s]Training Epoch 60, LR 0.000895:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.09s/batch]Training Epoch 60, LR 0.000895:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 60, LR 0.000895:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.35batch/s]Training Epoch 60, LR 0.000895:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.56batch/s]Training Epoch 60, LR 0.000895:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.07s/batch]Training Epoch 60, LR 0.000895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.08batch/s]Training Epoch 60, LR 0.000895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 60:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 60:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 60:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 60:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [60/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[75, 14],
        [24, 31]], device='cuda:0')
train_accuracy=0.7361111044883728, 
train_recall=0.5636363625526428, 
train_precision=0.6888889074325562, 
train_specificity=0.8426966071128845, 
train_balance_acc=0.7031664848327637,
 train_f1_score=0.6200000047683716,
 train_auc=0.765066385269165

Epoch [60/200]:, eval_loss=0.013, 
eval_confusionMatrix:
tensor([[20,  2],
        [ 8,  2]], device='cuda:0')
eval_accuracy=0.6875, 
eval_recall=0.20000000298023224, 
eval_precision=0.5, 
eval_specificity=0.9090909361839294, 
eval_balance_acc=0.5545454621315002,
 eval_f1_score=0.2857142984867096,
 eval_auc=0.6363636255264282


Epoch: 61/200
Training Epoch 61, LR 0.000884:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 61, LR 0.000884:   6%|â–Œ         | 1/18 [00:03<01:03,  3.75s/batch]Training Epoch 61, LR 0.000884:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 61, LR 0.000884:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 61, LR 0.000884:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 61, LR 0.000884:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 61, LR 0.000884:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 61, LR 0.000884:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.22batch/s]Training Epoch 61, LR 0.000884:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 61, LR 0.000884:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.15s/batch]Training Epoch 61, LR 0.000884:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.09batch/s]Training Epoch 61, LR 0.000884:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 61, LR 0.000884:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 61, LR 0.000884:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 61, LR 0.000884:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.19batch/s]Training Epoch 61, LR 0.000884:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 61, LR 0.000884:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 61, LR 0.000884:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 61, LR 0.000884: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 61, LR 0.000884: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 61:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 61:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.49s/batch]Evaluating Epoch 61:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 61:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.65batch/s]Evaluating Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [61/200]:, train_loss=0.054, 
train_confusionMatrix:
tensor([[74, 15],
        [22, 33]], device='cuda:0')
train_accuracy=0.7430555820465088, 
train_recall=0.6000000238418579, 
train_precision=0.6875, 
train_specificity=0.8314606547355652, 
train_balance_acc=0.7157303094863892,
 train_f1_score=0.6407766938209534,
 train_auc=0.7979571223258972

Epoch [61/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 4, 15],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=1.0, 
eval_precision=0.4642857015132904, 
eval_specificity=0.21052631735801697, 
eval_balance_acc=0.6052631735801697,
 eval_f1_score=0.6341463327407837,
 eval_auc=0.7125506401062012


Epoch: 62/200
Training Epoch 62, LR 0.000873:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 62, LR 0.000873:   6%|â–Œ         | 1/18 [00:03<01:05,  3.86s/batch]Training Epoch 62, LR 0.000873:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 62, LR 0.000873:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 62, LR 0.000873:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 62, LR 0.000873:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 62, LR 0.000873:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 62, LR 0.000873:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.22batch/s]Training Epoch 62, LR 0.000873:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 62, LR 0.000873:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 62, LR 0.000873:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 62, LR 0.000873:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.37batch/s]Training Epoch 62, LR 0.000873:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 62, LR 0.000873:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 62, LR 0.000873:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 62, LR 0.000873:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 62, LR 0.000873:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 62, LR 0.000873:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.07s/batch]Training Epoch 62, LR 0.000873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.15batch/s]Training Epoch 62, LR 0.000873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 62:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 62:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.71s/batch]Evaluating Epoch 62:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.62s/batch]Evaluating Epoch 62:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [62/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[70, 19],
        [31, 24]], device='cuda:0')
train_accuracy=0.6527777910232544, 
train_recall=0.4363636374473572, 
train_precision=0.5581395626068115, 
train_specificity=0.7865168452262878, 
train_balance_acc=0.6114402413368225,
 train_f1_score=0.4897959232330322,
 train_auc=0.6273748874664307

Epoch [62/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[22,  0],
        [10,  0]], device='cuda:0')
eval_accuracy=0.6875, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.7681818008422852


Epoch: 63/200
Training Epoch 63, LR 0.000861:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 63, LR 0.000861:   6%|â–Œ         | 1/18 [00:04<01:09,  4.10s/batch]Training Epoch 63, LR 0.000861:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.92s/batch]Training Epoch 63, LR 0.000861:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.23s/batch]Training Epoch 63, LR 0.000861:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 63, LR 0.000861:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 63, LR 0.000861:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 63, LR 0.000861:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.25batch/s]Training Epoch 63, LR 0.000861:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 63, LR 0.000861:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 63, LR 0.000861:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.11batch/s]Training Epoch 63, LR 0.000861:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 63, LR 0.000861:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 63, LR 0.000861:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 63, LR 0.000861:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 63, LR 0.000861:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 63, LR 0.000861:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 63, LR 0.000861:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.03s/batch]Training Epoch 63, LR 0.000861: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 63, LR 0.000861: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 63:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 63:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.79s/batch]Evaluating Epoch 63:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.65s/batch]Evaluating Epoch 63:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.03batch/s]Evaluating Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [63/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[81,  8],
        [31, 24]], device='cuda:0')
train_accuracy=0.7291666865348816, 
train_recall=0.4363636374473572, 
train_precision=0.75, 
train_specificity=0.9101123809814453, 
train_balance_acc=0.6732380390167236,
 train_f1_score=0.5517241358757019,
 train_auc=0.7417773008346558

Epoch [63/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[13,  5],
        [ 5,  9]], device='cuda:0')
eval_accuracy=0.6875, 
eval_recall=0.6428571343421936, 
eval_precision=0.6428571343421936, 
eval_specificity=0.7222222089767456, 
eval_balance_acc=0.682539701461792,
 eval_f1_score=0.6428571343421936,
 eval_auc=0.7857142686843872


Epoch: 64/200
Training Epoch 64, LR 0.000849:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 64, LR 0.000849:   6%|â–Œ         | 1/18 [00:03<01:04,  3.77s/batch]Training Epoch 64, LR 0.000849:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 64, LR 0.000849:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 64, LR 0.000849:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 64, LR 0.000849:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 64, LR 0.000849:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 64, LR 0.000849:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:09,  1.22batch/s]Training Epoch 64, LR 0.000849:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 64, LR 0.000849:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 64, LR 0.000849:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.11batch/s]Training Epoch 64, LR 0.000849:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 64, LR 0.000849:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 64, LR 0.000849:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 64, LR 0.000849:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.12batch/s]Training Epoch 64, LR 0.000849:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.34batch/s]Training Epoch 64, LR 0.000849:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.56batch/s]Training Epoch 64, LR 0.000849:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 64, LR 0.000849: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.14batch/s]Training Epoch 64, LR 0.000849: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 64:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 64:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.67s/batch]Evaluating Epoch 64:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.60s/batch]Evaluating Epoch 64:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.06batch/s]Evaluating Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [64/200]:, train_loss=0.054, 
train_confusionMatrix:
tensor([[76, 13],
        [24, 31]], device='cuda:0')
train_accuracy=0.7430555820465088, 
train_recall=0.5636363625526428, 
train_precision=0.7045454382896423, 
train_specificity=0.8539325594902039, 
train_balance_acc=0.7087844610214233,
 train_f1_score=0.6262626051902771,
 train_auc=0.7760980129241943

Epoch [64/200]:, eval_loss=0.013, 
eval_confusionMatrix:
tensor([[17,  4],
        [ 6,  5]], device='cuda:0')
eval_accuracy=0.6875, 
eval_recall=0.4545454680919647, 
eval_precision=0.5555555820465088, 
eval_specificity=0.8095238208770752, 
eval_balance_acc=0.6320346593856812,
 eval_f1_score=0.5,
 eval_auc=0.7489177584648132


Epoch: 65/200
Training Epoch 65, LR 0.000836:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 65, LR 0.000836:   6%|â–Œ         | 1/18 [00:03<01:06,  3.91s/batch]Training Epoch 65, LR 0.000836:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 65, LR 0.000836:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 65, LR 0.000836:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 65, LR 0.000836:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 65, LR 0.000836:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 65, LR 0.000836:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.22batch/s]Training Epoch 65, LR 0.000836:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 65, LR 0.000836:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 65, LR 0.000836:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.11batch/s]Training Epoch 65, LR 0.000836:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 65, LR 0.000836:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 65, LR 0.000836:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 65, LR 0.000836:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 65, LR 0.000836:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 65, LR 0.000836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.58batch/s]Training Epoch 65, LR 0.000836:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.00batch/s]Training Epoch 65, LR 0.000836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.22batch/s]Training Epoch 65, LR 0.000836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 65:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 65:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.57s/batch]Evaluating Epoch 65:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 65:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [65/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[73, 16],
        [24, 31]], device='cuda:0')
train_accuracy=0.7222222089767456, 
train_recall=0.5636363625526428, 
train_precision=0.6595744490623474, 
train_specificity=0.8202247023582458, 
train_balance_acc=0.6919305324554443,
 train_f1_score=0.6078431606292725,
 train_auc=0.7656792402267456

Epoch [65/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.737500011920929


Epoch: 66/200
Training Epoch 66, LR 0.000823:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 66, LR 0.000823:   6%|â–Œ         | 1/18 [00:03<01:03,  3.72s/batch]Training Epoch 66, LR 0.000823:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.77s/batch]Training Epoch 66, LR 0.000823:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 66, LR 0.000823:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 66, LR 0.000823:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.32s/batch]Training Epoch 66, LR 0.000823:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 66, LR 0.000823:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.23batch/s]Training Epoch 66, LR 0.000823:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 66, LR 0.000823:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 66, LR 0.000823:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 66, LR 0.000823:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 66, LR 0.000823:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 66, LR 0.000823:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 66, LR 0.000823:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 66, LR 0.000823:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 66, LR 0.000823:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.56batch/s]Training Epoch 66, LR 0.000823:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 66, LR 0.000823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 66, LR 0.000823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 66:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 66:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.49s/batch]Evaluating Epoch 66:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 66:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [66/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[76, 14],
        [30, 24]], device='cuda:0')
train_accuracy=0.6944444179534912, 
train_recall=0.4444444477558136, 
train_precision=0.6315789222717285, 
train_specificity=0.8444444537162781, 
train_balance_acc=0.644444465637207,
 train_f1_score=0.52173912525177,
 train_auc=0.7586419582366943

Epoch [66/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [11,  1]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.0833333358168602, 
eval_precision=1.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5416666865348816,
 eval_f1_score=0.1538461595773697,
 eval_auc=0.4541666507720947


Epoch: 67/200
Training Epoch 67, LR 0.000810:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 67, LR 0.000810:   6%|â–Œ         | 1/18 [00:03<01:04,  3.79s/batch]Training Epoch 67, LR 0.000810:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 67, LR 0.000810:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 67, LR 0.000810:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 67, LR 0.000810:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.39s/batch]Training Epoch 67, LR 0.000810:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.06s/batch]Training Epoch 67, LR 0.000810:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.18batch/s]Training Epoch 67, LR 0.000810:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.41batch/s]Training Epoch 67, LR 0.000810:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 67, LR 0.000810:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.16batch/s]Training Epoch 67, LR 0.000810:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.38batch/s]Training Epoch 67, LR 0.000810:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 67, LR 0.000810:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.11s/batch]Training Epoch 67, LR 0.000810:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.12batch/s]Training Epoch 67, LR 0.000810:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.34batch/s]Training Epoch 67, LR 0.000810:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.55batch/s]Training Epoch 67, LR 0.000810:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 67, LR 0.000810: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 67, LR 0.000810: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 67:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 67:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.80s/batch]Evaluating Epoch 67:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.65s/batch]Evaluating Epoch 67:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.03batch/s]Evaluating Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.54batch/s]Evaluating Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [67/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[75, 15],
        [29, 25]], device='cuda:0')
train_accuracy=0.6944444179534912, 
train_recall=0.46296295523643494, 
train_precision=0.625, 
train_specificity=0.8333333134651184, 
train_balance_acc=0.6481481194496155,
 train_f1_score=0.5319148898124695,
 train_auc=0.7259259223937988

Epoch [67/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[16,  4],
        [ 8,  4]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.3333333432674408, 
eval_precision=0.5, 
eval_specificity=0.800000011920929, 
eval_balance_acc=0.5666666626930237,
 eval_f1_score=0.4000000059604645,
 eval_auc=0.6000000238418579


Epoch: 68/200
Training Epoch 68, LR 0.000796:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 68, LR 0.000796:   6%|â–Œ         | 1/18 [00:04<01:09,  4.06s/batch]Training Epoch 68, LR 0.000796:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.91s/batch]Training Epoch 68, LR 0.000796:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.22s/batch]Training Epoch 68, LR 0.000796:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 68, LR 0.000796:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 68, LR 0.000796:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 68, LR 0.000796:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.24batch/s]Training Epoch 68, LR 0.000796:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 68, LR 0.000796:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.11s/batch]Training Epoch 68, LR 0.000796:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 68, LR 0.000796:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 68, LR 0.000796:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 68, LR 0.000796:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.16s/batch]Training Epoch 68, LR 0.000796:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.08batch/s]Training Epoch 68, LR 0.000796:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.30batch/s]Training Epoch 68, LR 0.000796:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.51batch/s]Training Epoch 68, LR 0.000796:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.20s/batch]Training Epoch 68, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.04batch/s]Training Epoch 68, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 68:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 68:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.49s/batch]Evaluating Epoch 68:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 68:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [68/200]:, train_loss=0.051, 
train_confusionMatrix:
tensor([[80,  9],
        [23, 32]], device='cuda:0')
train_accuracy=0.7777777910232544, 
train_recall=0.581818163394928, 
train_precision=0.7804877758026123, 
train_specificity=0.898876428604126, 
train_balance_acc=0.7403472661972046,
 train_f1_score=0.6666666865348816,
 train_auc=0.8288048505783081

Epoch [68/200]:, eval_loss=0.018, 
eval_confusionMatrix:
tensor([[ 4, 17],
        [ 1, 10]], device='cuda:0')
eval_accuracy=0.4375, 
eval_recall=0.9090909361839294, 
eval_precision=0.37037035822868347, 
eval_specificity=0.190476194024086, 
eval_balance_acc=0.5497835874557495,
 eval_f1_score=0.5263158082962036,
 eval_auc=0.6277056336402893


Epoch: 69/200
Training Epoch 69, LR 0.000782:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 69, LR 0.000782:   6%|â–Œ         | 1/18 [00:03<01:05,  3.85s/batch]Training Epoch 69, LR 0.000782:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 69, LR 0.000782:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 69, LR 0.000782:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 69, LR 0.000782:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.42s/batch]Training Epoch 69, LR 0.000782:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.08s/batch]Training Epoch 69, LR 0.000782:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.17batch/s]Training Epoch 69, LR 0.000782:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.39batch/s]Training Epoch 69, LR 0.000782:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.17s/batch]Training Epoch 69, LR 0.000782:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.08batch/s]Training Epoch 69, LR 0.000782:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.30batch/s]Training Epoch 69, LR 0.000782:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.51batch/s]Training Epoch 69, LR 0.000782:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.12s/batch]Training Epoch 69, LR 0.000782:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 69, LR 0.000782:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.33batch/s]Training Epoch 69, LR 0.000782:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.54batch/s]Training Epoch 69, LR 0.000782:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.01s/batch]Training Epoch 69, LR 0.000782: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 69, LR 0.000782: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 69:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 69:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.84s/batch]Evaluating Epoch 69:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.67s/batch]Evaluating Epoch 69:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.02batch/s]Evaluating Epoch 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.54batch/s]Evaluating Epoch 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.09s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [69/200]:, train_loss=0.054, 
train_confusionMatrix:
tensor([[79, 11],
        [27, 27]], device='cuda:0')
train_accuracy=0.7361111044883728, 
train_recall=0.5, 
train_precision=0.7105262875556946, 
train_specificity=0.8777777552604675, 
train_balance_acc=0.6888889074325562,
 train_f1_score=0.5869565010070801,
 train_auc=0.8337448835372925

Epoch [69/200]:, eval_loss=0.019, 
eval_confusionMatrix:
tensor([[ 5, 13],
        [ 8,  6]], device='cuda:0')
eval_accuracy=0.34375, 
eval_recall=0.4285714328289032, 
eval_precision=0.31578946113586426, 
eval_specificity=0.2777777910232544, 
eval_balance_acc=0.35317462682724,
 eval_f1_score=0.3636363744735718,
 eval_auc=0.4325396716594696


Epoch: 70/200
Training Epoch 70, LR 0.000767:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 70, LR 0.000767:   6%|â–Œ         | 1/18 [00:03<01:05,  3.86s/batch]Training Epoch 70, LR 0.000767:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 70, LR 0.000767:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 70, LR 0.000767:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 70, LR 0.000767:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.32s/batch]Training Epoch 70, LR 0.000767:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 70, LR 0.000767:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.23batch/s]Training Epoch 70, LR 0.000767:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 70, LR 0.000767:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 70, LR 0.000767:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 70, LR 0.000767:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 70, LR 0.000767:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 70, LR 0.000767:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 70, LR 0.000767:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.20batch/s]Training Epoch 70, LR 0.000767:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.42batch/s]Training Epoch 70, LR 0.000767:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.63batch/s]Training Epoch 70, LR 0.000767:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.05s/batch]Training Epoch 70, LR 0.000767: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 70, LR 0.000767: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 70:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 70:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.62s/batch]Evaluating Epoch 70:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 70:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 70: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [70/200]:, train_loss=0.051, 
train_confusionMatrix:
tensor([[78, 11],
        [18, 37]], device='cuda:0')
train_accuracy=0.7986111044883728, 
train_recall=0.6727272868156433, 
train_precision=0.7708333134651184, 
train_specificity=0.8764045238494873, 
train_balance_acc=0.7745659351348877,
 train_f1_score=0.7184466123580933,
 train_auc=0.8224719166755676

Epoch [70/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[16,  3],
        [12,  1]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.07692307978868484, 
eval_precision=0.25, 
eval_specificity=0.8421052694320679, 
eval_balance_acc=0.45951417088508606,
 eval_f1_score=0.11764705926179886,
 eval_auc=0.7004048228263855


Epoch: 71/200
Training Epoch 71, LR 0.000753:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 71, LR 0.000753:   6%|â–Œ         | 1/18 [00:03<01:04,  3.82s/batch]Training Epoch 71, LR 0.000753:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 71, LR 0.000753:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 71, LR 0.000753:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 71, LR 0.000753:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.25s/batch]Training Epoch 71, LR 0.000753:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.04batch/s]Training Epoch 71, LR 0.000753:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.28batch/s]Training Epoch 71, LR 0.000753:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.52batch/s]Training Epoch 71, LR 0.000753:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 71, LR 0.000753:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 71, LR 0.000753:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.37batch/s]Training Epoch 71, LR 0.000753:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 71, LR 0.000753:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 71, LR 0.000753:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.14batch/s]Training Epoch 71, LR 0.000753:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 71, LR 0.000753:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 71, LR 0.000753:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.05s/batch]Training Epoch 71, LR 0.000753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 71, LR 0.000753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 71:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 71:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.55s/batch]Evaluating Epoch 71:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 71:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 71: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [71/200]:, train_loss=0.053, 
train_confusionMatrix:
tensor([[75, 15],
        [19, 35]], device='cuda:0')
train_accuracy=0.7638888955116272, 
train_recall=0.6481481194496155, 
train_precision=0.699999988079071, 
train_specificity=0.8333333134651184, 
train_balance_acc=0.7407407164573669,
 train_f1_score=0.6730769276618958,
 train_auc=0.8090535402297974

Epoch [71/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[16,  3],
        [11,  2]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.1538461595773697, 
eval_precision=0.4000000059604645, 
eval_specificity=0.8421052694320679, 
eval_balance_acc=0.4979757070541382,
 eval_f1_score=0.2222222238779068,
 eval_auc=0.6842105388641357


Epoch: 72/200
Training Epoch 72, LR 0.000737:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 72, LR 0.000737:   6%|â–Œ         | 1/18 [00:03<01:04,  3.79s/batch]Training Epoch 72, LR 0.000737:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 72, LR 0.000737:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 72, LR 0.000737:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 72, LR 0.000737:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.26s/batch]Training Epoch 72, LR 0.000737:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 72, LR 0.000737:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 72, LR 0.000737:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 72, LR 0.000737:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.16s/batch]Training Epoch 72, LR 0.000737:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.07batch/s]Training Epoch 72, LR 0.000737:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.30batch/s]Training Epoch 72, LR 0.000737:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.52batch/s]Training Epoch 72, LR 0.000737:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.17s/batch]Training Epoch 72, LR 0.000737:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.06batch/s]Training Epoch 72, LR 0.000737:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.28batch/s]Training Epoch 72, LR 0.000737:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.50batch/s]Training Epoch 72, LR 0.000737:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.12s/batch]Training Epoch 72, LR 0.000737: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.10batch/s]Training Epoch 72, LR 0.000737: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 72:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 72:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.55s/batch]Evaluating Epoch 72:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 72:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 72: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [72/200]:, train_loss=0.052, 
train_confusionMatrix:
tensor([[77, 13],
        [17, 37]], device='cuda:0')
train_accuracy=0.7916666865348816, 
train_recall=0.6851851940155029, 
train_precision=0.7400000095367432, 
train_specificity=0.855555534362793, 
train_balance_acc=0.770370364189148,
 train_f1_score=0.7115384340286255,
 train_auc=0.8209876418113708

Epoch [72/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[14,  4],
        [12,  2]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.1428571492433548, 
eval_precision=0.3333333432674408, 
eval_specificity=0.7777777910232544, 
eval_balance_acc=0.460317462682724,
 eval_f1_score=0.20000000298023224,
 eval_auc=0.658730149269104


Epoch: 73/200
Training Epoch 73, LR 0.000722:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 73, LR 0.000722:   6%|â–Œ         | 1/18 [00:03<01:03,  3.75s/batch]Training Epoch 73, LR 0.000722:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 73, LR 0.000722:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 73, LR 0.000722:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 73, LR 0.000722:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 73, LR 0.000722:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 73, LR 0.000722:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:09,  1.21batch/s]Training Epoch 73, LR 0.000722:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 73, LR 0.000722:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.14s/batch]Training Epoch 73, LR 0.000722:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.09batch/s]Training Epoch 73, LR 0.000722:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 73, LR 0.000722:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 73, LR 0.000722:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 73, LR 0.000722:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 73, LR 0.000722:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 73, LR 0.000722:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 73, LR 0.000722:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 73, LR 0.000722: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 73, LR 0.000722: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 73:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 73:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 73:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 73:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 73: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [73/200]:, train_loss=0.050, 
train_confusionMatrix:
tensor([[77, 13],
        [16, 38]], device='cuda:0')
train_accuracy=0.7986111044883728, 
train_recall=0.7037037014961243, 
train_precision=0.7450980544090271, 
train_specificity=0.855555534362793, 
train_balance_acc=0.7796295881271362,
 train_f1_score=0.723809540271759,
 train_auc=0.8580246567726135

Epoch [73/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[13,  7],
        [ 8,  4]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.3333333432674408, 
eval_precision=0.3636363744735718, 
eval_specificity=0.6499999761581421, 
eval_balance_acc=0.49166667461395264,
 eval_f1_score=0.3478260934352875,
 eval_auc=0.6666666865348816


Epoch: 74/200
Training Epoch 74, LR 0.000706:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 74, LR 0.000706:   6%|â–Œ         | 1/18 [00:03<01:05,  3.88s/batch]Training Epoch 74, LR 0.000706:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 74, LR 0.000706:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 74, LR 0.000706:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 74, LR 0.000706:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:19,  1.49s/batch]Training Epoch 74, LR 0.000706:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.12s/batch]Training Epoch 74, LR 0.000706:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.13batch/s]Training Epoch 74, LR 0.000706:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.36batch/s]Training Epoch 74, LR 0.000706:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.25s/batch]Training Epoch 74, LR 0.000706:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.01batch/s]Training Epoch 74, LR 0.000706:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.23batch/s]Training Epoch 74, LR 0.000706:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.46batch/s]Training Epoch 74, LR 0.000706:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.06s/batch]Training Epoch 74, LR 0.000706:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.16batch/s]Training Epoch 74, LR 0.000706:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.38batch/s]Training Epoch 74, LR 0.000706:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.59batch/s]Training Epoch 74, LR 0.000706:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 74, LR 0.000706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.18batch/s]Training Epoch 74, LR 0.000706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 74:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 74:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.56s/batch]Evaluating Epoch 74:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 74:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 74: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [74/200]:, train_loss=0.050, 
train_confusionMatrix:
tensor([[79, 11],
        [18, 36]], device='cuda:0')
train_accuracy=0.7986111044883728, 
train_recall=0.6666666865348816, 
train_precision=0.7659574747085571, 
train_specificity=0.8777777552604675, 
train_balance_acc=0.7722222208976746,
 train_f1_score=0.7128713130950928,
 train_auc=0.866460919380188

Epoch [74/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[14,  6],
        [ 8,  4]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.3333333432674408, 
eval_precision=0.4000000059604645, 
eval_specificity=0.699999988079071, 
eval_balance_acc=0.5166666507720947,
 eval_f1_score=0.3636363744735718,
 eval_auc=0.6333333253860474


Epoch: 75/200
Training Epoch 75, LR 0.000690:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 75, LR 0.000690:   6%|â–Œ         | 1/18 [00:03<01:06,  3.94s/batch]Training Epoch 75, LR 0.000690:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.86s/batch]Training Epoch 75, LR 0.000690:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.20s/batch]Training Epoch 75, LR 0.000690:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 75, LR 0.000690:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 75, LR 0.000690:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.00batch/s]Training Epoch 75, LR 0.000690:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.24batch/s]Training Epoch 75, LR 0.000690:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 75, LR 0.000690:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 75, LR 0.000690:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 75, LR 0.000690:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 75, LR 0.000690:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 75, LR 0.000690:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.12s/batch]Training Epoch 75, LR 0.000690:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 75, LR 0.000690:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.33batch/s]Training Epoch 75, LR 0.000690:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.55batch/s]Training Epoch 75, LR 0.000690:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 75, LR 0.000690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 75, LR 0.000690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 75:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 75:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.63s/batch]Evaluating Epoch 75:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.66s/batch]Evaluating Epoch 75:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.03batch/s]Evaluating Epoch 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.54batch/s]Evaluating Epoch 75: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [75/200]:, train_loss=0.050, 
train_confusionMatrix:
tensor([[83,  6],
        [21, 34]], device='cuda:0')
train_accuracy=0.8125, 
train_recall=0.6181818246841431, 
train_precision=0.8500000238418579, 
train_specificity=0.932584285736084, 
train_balance_acc=0.7753830552101135,
 train_f1_score=0.7157894968986511,
 train_auc=0.8120530843734741

Epoch [75/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[11,  9],
        [ 6,  6]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.5, 
eval_precision=0.4000000059604645, 
eval_specificity=0.550000011920929, 
eval_balance_acc=0.5249999761581421,
 eval_f1_score=0.4444444477558136,
 eval_auc=0.5291666984558105


Epoch: 76/200
Training Epoch 76, LR 0.000674:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 76, LR 0.000674:   6%|â–Œ         | 1/18 [00:03<01:05,  3.84s/batch]Training Epoch 76, LR 0.000674:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 76, LR 0.000674:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 76, LR 0.000674:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 76, LR 0.000674:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.38s/batch]Training Epoch 76, LR 0.000674:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 76, LR 0.000674:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.19batch/s]Training Epoch 76, LR 0.000674:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.43batch/s]Training Epoch 76, LR 0.000674:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.17s/batch]Training Epoch 76, LR 0.000674:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.07batch/s]Training Epoch 76, LR 0.000674:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.30batch/s]Training Epoch 76, LR 0.000674:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.52batch/s]Training Epoch 76, LR 0.000674:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.09s/batch]Training Epoch 76, LR 0.000674:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 76, LR 0.000674:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 76, LR 0.000674:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 76, LR 0.000674:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.01s/batch]Training Epoch 76, LR 0.000674: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 76, LR 0.000674: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 76:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 76:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.71s/batch]Evaluating Epoch 76:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.61s/batch]Evaluating Epoch 76:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.06batch/s]Evaluating Epoch 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 76: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [76/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[76, 14],
        [26, 28]], device='cuda:0')
train_accuracy=0.7222222089767456, 
train_recall=0.5185185074806213, 
train_precision=0.6666666865348816, 
train_specificity=0.8444444537162781, 
train_balance_acc=0.6814814805984497,
 train_f1_score=0.5833333134651184,
 train_auc=0.7518519163131714

Epoch [76/200]:, eval_loss=0.022, 
eval_confusionMatrix:
tensor([[ 0, 22],
        [ 0, 10]], device='cuda:0')
eval_accuracy=0.3125, 
eval_recall=1.0, 
eval_precision=0.3125, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.4761904776096344,
 eval_auc=0.5477272868156433


Epoch: 77/200
Training Epoch 77, LR 0.000658:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 77, LR 0.000658:   6%|â–Œ         | 1/18 [00:03<01:06,  3.90s/batch]Training Epoch 77, LR 0.000658:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 77, LR 0.000658:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 77, LR 0.000658:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 77, LR 0.000658:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 77, LR 0.000658:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 77, LR 0.000658:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 77, LR 0.000658:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 77, LR 0.000658:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 77, LR 0.000658:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 77, LR 0.000658:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 77, LR 0.000658:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 77, LR 0.000658:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 77, LR 0.000658:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 77, LR 0.000658:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 77, LR 0.000658:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.58batch/s]Training Epoch 77, LR 0.000658:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 77, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 77, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 77:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 77:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.56s/batch]Evaluating Epoch 77:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 77:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 77: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [77/200]:, train_loss=0.053, 
train_confusionMatrix:
tensor([[83,  6],
        [27, 28]], device='cuda:0')
train_accuracy=0.7708333134651184, 
train_recall=0.5090909004211426, 
train_precision=0.8235294222831726, 
train_specificity=0.932584285736084, 
train_balance_acc=0.7208375930786133,
 train_f1_score=0.6292135119438171,
 train_auc=0.8053115010261536

Epoch [77/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 7, 12],
        [ 4,  9]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.692307710647583, 
eval_precision=0.4285714328289032, 
eval_specificity=0.3684210479259491, 
eval_balance_acc=0.5303643941879272,
 eval_f1_score=0.529411792755127,
 eval_auc=0.52226722240448


Epoch: 78/200
Training Epoch 78, LR 0.000641:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 78, LR 0.000641:   6%|â–Œ         | 1/18 [00:03<01:06,  3.90s/batch]Training Epoch 78, LR 0.000641:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 78, LR 0.000641:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 78, LR 0.000641:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 78, LR 0.000641:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.27s/batch]Training Epoch 78, LR 0.000641:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 78, LR 0.000641:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 78, LR 0.000641:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 78, LR 0.000641:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 78, LR 0.000641:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 78, LR 0.000641:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 78, LR 0.000641:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 78, LR 0.000641:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 78, LR 0.000641:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.17batch/s]Training Epoch 78, LR 0.000641:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 78, LR 0.000641:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 78, LR 0.000641:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.05s/batch]Training Epoch 78, LR 0.000641: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 78, LR 0.000641: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 78:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 78:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.63s/batch]Evaluating Epoch 78:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 78:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [78/200]:, train_loss=0.053, 
train_confusionMatrix:
tensor([[77, 13],
        [23, 31]], device='cuda:0')
train_accuracy=0.75, 
train_recall=0.5740740895271301, 
train_precision=0.7045454382896423, 
train_specificity=0.855555534362793, 
train_balance_acc=0.7148147821426392,
 train_f1_score=0.6326530575752258,
 train_auc=0.8004115223884583

Epoch [78/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[17,  4],
        [ 8,  3]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.27272728085517883, 
eval_precision=0.4285714328289032, 
eval_specificity=0.8095238208770752, 
eval_balance_acc=0.5411255359649658,
 eval_f1_score=0.3333333432674408,
 eval_auc=0.7402597665786743


Epoch: 79/200
Training Epoch 79, LR 0.000625:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 79, LR 0.000625:   6%|â–Œ         | 1/18 [00:03<01:06,  3.93s/batch]Training Epoch 79, LR 0.000625:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.94s/batch]Training Epoch 79, LR 0.000625:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.24s/batch]Training Epoch 79, LR 0.000625:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 79, LR 0.000625:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.38s/batch]Training Epoch 79, LR 0.000625:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.08s/batch]Training Epoch 79, LR 0.000625:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.17batch/s]Training Epoch 79, LR 0.000625:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.41batch/s]Training Epoch 79, LR 0.000625:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.16s/batch]Training Epoch 79, LR 0.000625:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:08,  1.01s/batch]Training Epoch 79, LR 0.000625:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.21batch/s]Training Epoch 79, LR 0.000625:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.43batch/s]Training Epoch 79, LR 0.000625:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.13s/batch]Training Epoch 79, LR 0.000625:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:04,  1.03s/batch]Training Epoch 79, LR 0.000625:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.19batch/s]Training Epoch 79, LR 0.000625:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.41batch/s]Training Epoch 79, LR 0.000625:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:00,  1.01batch/s]Training Epoch 79, LR 0.000625: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.07batch/s]Training Epoch 79, LR 0.000625: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 79:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 79:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.79s/batch]Evaluating Epoch 79:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.66s/batch]Evaluating Epoch 79:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.03batch/s]Evaluating Epoch 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.54batch/s]Evaluating Epoch 79: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.08s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [79/200]:, train_loss=0.051, 
train_confusionMatrix:
tensor([[73, 16],
        [16, 39]], device='cuda:0')
train_accuracy=0.7777777910232544, 
train_recall=0.7090908885002136, 
train_precision=0.7090908885002136, 
train_specificity=0.8202247023582458, 
train_balance_acc=0.7646577954292297,
 train_f1_score=0.7090908885002136,
 train_auc=0.832482099533081

Epoch [79/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[14,  6],
        [ 8,  4]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.3333333432674408, 
eval_precision=0.4000000059604645, 
eval_specificity=0.699999988079071, 
eval_balance_acc=0.5166666507720947,
 eval_f1_score=0.3636363744735718,
 eval_auc=0.625


Epoch: 80/200
Training Epoch 80, LR 0.000608:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 80, LR 0.000608:   6%|â–Œ         | 1/18 [00:04<01:08,  4.06s/batch]Training Epoch 80, LR 0.000608:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.91s/batch]Training Epoch 80, LR 0.000608:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.22s/batch]Training Epoch 80, LR 0.000608:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 80, LR 0.000608:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.32s/batch]Training Epoch 80, LR 0.000608:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 80, LR 0.000608:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.24batch/s]Training Epoch 80, LR 0.000608:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 80, LR 0.000608:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.11s/batch]Training Epoch 80, LR 0.000608:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 80, LR 0.000608:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 80, LR 0.000608:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 80, LR 0.000608:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 80, LR 0.000608:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.19batch/s]Training Epoch 80, LR 0.000608:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 80, LR 0.000608:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 80, LR 0.000608:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.09s/batch]Training Epoch 80, LR 0.000608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.13batch/s]Training Epoch 80, LR 0.000608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 80:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 80:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.68s/batch]Evaluating Epoch 80:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.60s/batch]Evaluating Epoch 80:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.06batch/s]Evaluating Epoch 80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 80: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [80/200]:, train_loss=0.052, 
train_confusionMatrix:
tensor([[75, 14],
        [19, 36]], device='cuda:0')
train_accuracy=0.7708333134651184, 
train_recall=0.6545454263687134, 
train_precision=0.7200000286102295, 
train_specificity=0.8426966071128845, 
train_balance_acc=0.7486209869384766,
 train_f1_score=0.6857143044471741,
 train_auc=0.8247190713882446

Epoch [80/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[13,  5],
        [10,  4]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.2857142984867096, 
eval_precision=0.4444444477558136, 
eval_specificity=0.7222222089767456, 
eval_balance_acc=0.5039682388305664,
 eval_f1_score=0.3478260934352875,
 eval_auc=0.7023809552192688


Epoch: 81/200
Training Epoch 81, LR 0.000591:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 81, LR 0.000591:   6%|â–Œ         | 1/18 [00:04<01:09,  4.10s/batch]Training Epoch 81, LR 0.000591:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.93s/batch]Training Epoch 81, LR 0.000591:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.24s/batch]Training Epoch 81, LR 0.000591:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 81, LR 0.000591:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.36s/batch]Training Epoch 81, LR 0.000591:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 81, LR 0.000591:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 81, LR 0.000591:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 81, LR 0.000591:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 81, LR 0.000591:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.13batch/s]Training Epoch 81, LR 0.000591:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 81, LR 0.000591:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 81, LR 0.000591:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 81, LR 0.000591:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 81, LR 0.000591:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 81, LR 0.000591:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 81, LR 0.000591:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.03s/batch]Training Epoch 81, LR 0.000591: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 81, LR 0.000591: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 81:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 81:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.51s/batch]Evaluating Epoch 81:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 81:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 81: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [81/200]:, train_loss=0.050, 
train_confusionMatrix:
tensor([[81,  8],
        [23, 32]], device='cuda:0')
train_accuracy=0.7847222089767456, 
train_recall=0.581818163394928, 
train_precision=0.800000011920929, 
train_specificity=0.9101123809814453, 
train_balance_acc=0.7459652423858643,
 train_f1_score=0.6736842393875122,
 train_auc=0.8616956472396851

Epoch [81/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[19,  2],
        [10,  1]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.09090909361839294, 
eval_precision=0.3333333432674408, 
eval_specificity=0.9047619104385376, 
eval_balance_acc=0.49783551692962646,
 eval_f1_score=0.1428571492433548,
 eval_auc=0.6060606241226196


Epoch: 82/200
Training Epoch 82, LR 0.000574:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 82, LR 0.000574:   6%|â–Œ         | 1/18 [00:03<01:03,  3.75s/batch]Training Epoch 82, LR 0.000574:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 82, LR 0.000574:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 82, LR 0.000574:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 82, LR 0.000574:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.27s/batch]Training Epoch 82, LR 0.000574:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 82, LR 0.000574:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 82, LR 0.000574:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 82, LR 0.000574:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 82, LR 0.000574:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 82, LR 0.000574:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 82, LR 0.000574:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 82, LR 0.000574:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 82, LR 0.000574:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.15batch/s]Training Epoch 82, LR 0.000574:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 82, LR 0.000574:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 82, LR 0.000574:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 82, LR 0.000574: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 82, LR 0.000574: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 82:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 82:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.54s/batch]Evaluating Epoch 82:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 82:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 82: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.63batch/s]Evaluating Epoch 82: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [82/200]:, train_loss=0.048, 
train_confusionMatrix:
tensor([[82,  7],
        [20, 35]], device='cuda:0')
train_accuracy=0.8125, 
train_recall=0.6363636255264282, 
train_precision=0.8333333134651184, 
train_specificity=0.9213483333587646, 
train_balance_acc=0.7788559794425964,
 train_f1_score=0.7216494679450989,
 train_auc=0.8813074827194214

Epoch [82/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[18,  2],
        [11,  1]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0833333358168602, 
eval_precision=0.3333333432674408, 
eval_specificity=0.8999999761581421, 
eval_balance_acc=0.49166664481163025,
 eval_f1_score=0.13333334028720856,
 eval_auc=0.6666666865348816


Epoch: 83/200
Training Epoch 83, LR 0.000557:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 83, LR 0.000557:   6%|â–Œ         | 1/18 [00:03<01:03,  3.76s/batch]Training Epoch 83, LR 0.000557:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 83, LR 0.000557:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 83, LR 0.000557:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 83, LR 0.000557:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.25s/batch]Training Epoch 83, LR 0.000557:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.04batch/s]Training Epoch 83, LR 0.000557:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.28batch/s]Training Epoch 83, LR 0.000557:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 83, LR 0.000557:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 83, LR 0.000557:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.11batch/s]Training Epoch 83, LR 0.000557:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 83, LR 0.000557:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 83, LR 0.000557:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 83, LR 0.000557:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.15batch/s]Training Epoch 83, LR 0.000557:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 83, LR 0.000557:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 83, LR 0.000557:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.06s/batch]Training Epoch 83, LR 0.000557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 83, LR 0.000557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 83:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 83:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.54s/batch]Evaluating Epoch 83:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 83:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 83: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 83: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [83/200]:, train_loss=0.052, 
train_confusionMatrix:
tensor([[78, 12],
        [24, 30]], device='cuda:0')
train_accuracy=0.75, 
train_recall=0.5555555820465088, 
train_precision=0.7142857313156128, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.7111111283302307,
 train_f1_score=0.625,
 train_auc=0.8355967402458191

Epoch [83/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[12,  8],
        [ 8,  4]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.3333333432674408, 
eval_precision=0.3333333432674408, 
eval_specificity=0.6000000238418579, 
eval_balance_acc=0.46666669845581055,
 eval_f1_score=0.3333333432674408,
 eval_auc=0.5666666626930237


Epoch: 84/200
Training Epoch 84, LR 0.000540:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 84, LR 0.000540:   6%|â–Œ         | 1/18 [00:03<01:04,  3.82s/batch]Training Epoch 84, LR 0.000540:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 84, LR 0.000540:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 84, LR 0.000540:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 84, LR 0.000540:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.27s/batch]Training Epoch 84, LR 0.000540:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 84, LR 0.000540:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 84, LR 0.000540:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 84, LR 0.000540:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 84, LR 0.000540:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 84, LR 0.000540:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 84, LR 0.000540:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 84, LR 0.000540:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 84, LR 0.000540:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.16batch/s]Training Epoch 84, LR 0.000540:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 84, LR 0.000540:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 84, LR 0.000540:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.05s/batch]Training Epoch 84, LR 0.000540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 84, LR 0.000540: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 84:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 84:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.70s/batch]Evaluating Epoch 84:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.61s/batch]Evaluating Epoch 84:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 84: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.57batch/s]Evaluating Epoch 84: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [84/200]:, train_loss=0.048, 
train_confusionMatrix:
tensor([[81,  8],
        [16, 39]], device='cuda:0')
train_accuracy=0.8333333134651184, 
train_recall=0.7090908885002136, 
train_precision=0.8297872543334961, 
train_specificity=0.9101123809814453, 
train_balance_acc=0.8096016645431519,
 train_f1_score=0.7647058963775635,
 train_auc=0.8563840389251709

Epoch [84/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 5, 13],
        [ 3, 11]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.7857142686843872, 
eval_precision=0.4583333432674408, 
eval_specificity=0.2777777910232544, 
eval_balance_acc=0.5317460298538208,
 eval_f1_score=0.5789473652839661,
 eval_auc=0.5595238208770752


Epoch: 85/200
Training Epoch 85, LR 0.000522:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 85, LR 0.000522:   6%|â–Œ         | 1/18 [00:03<01:07,  3.96s/batch]Training Epoch 85, LR 0.000522:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 85, LR 0.000522:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 85, LR 0.000522:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 85, LR 0.000522:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 85, LR 0.000522:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 85, LR 0.000522:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.19batch/s]Training Epoch 85, LR 0.000522:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.42batch/s]Training Epoch 85, LR 0.000522:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.15s/batch]Training Epoch 85, LR 0.000522:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.08batch/s]Training Epoch 85, LR 0.000522:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.31batch/s]Training Epoch 85, LR 0.000522:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.52batch/s]Training Epoch 85, LR 0.000522:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 85, LR 0.000522:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 85, LR 0.000522:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 85, LR 0.000522:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.58batch/s]Training Epoch 85, LR 0.000522:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.06s/batch]Training Epoch 85, LR 0.000522: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 85, LR 0.000522: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 85:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 85:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.81s/batch]Evaluating Epoch 85:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.66s/batch]Evaluating Epoch 85:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.03batch/s]Evaluating Epoch 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 85: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.08s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [85/200]:, train_loss=0.049, 
train_confusionMatrix:
tensor([[77, 12],
        [13, 42]], device='cuda:0')
train_accuracy=0.8263888955116272, 
train_recall=0.7636363506317139, 
train_precision=0.7777777910232544, 
train_specificity=0.8651685118675232, 
train_balance_acc=0.8144024610519409,
 train_f1_score=0.7706422209739685,
 train_auc=0.8226762413978577

Epoch [85/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[17,  4],
        [ 7,  4]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.3636363744735718, 
eval_precision=0.5, 
eval_specificity=0.8095238208770752, 
eval_balance_acc=0.5865800976753235,
 eval_f1_score=0.42105263471603394,
 eval_auc=0.6233766078948975


Epoch: 86/200
Training Epoch 86, LR 0.000505:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 86, LR 0.000505:   6%|â–Œ         | 1/18 [00:03<01:07,  3.98s/batch]Training Epoch 86, LR 0.000505:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.88s/batch]Training Epoch 86, LR 0.000505:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 86, LR 0.000505:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 86, LR 0.000505:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.39s/batch]Training Epoch 86, LR 0.000505:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 86, LR 0.000505:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.19batch/s]Training Epoch 86, LR 0.000505:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.42batch/s]Training Epoch 86, LR 0.000505:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 86, LR 0.000505:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.14batch/s]Training Epoch 86, LR 0.000505:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.37batch/s]Training Epoch 86, LR 0.000505:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 86, LR 0.000505:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 86, LR 0.000505:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.18batch/s]Training Epoch 86, LR 0.000505:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 86, LR 0.000505:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.62batch/s]Training Epoch 86, LR 0.000505:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 86, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 86, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 86:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 86:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.64s/batch]Evaluating Epoch 86:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.59s/batch]Evaluating Epoch 86:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 86: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 86: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [86/200]:, train_loss=0.049, 
train_confusionMatrix:
tensor([[77, 12],
        [17, 38]], device='cuda:0')
train_accuracy=0.7986111044883728, 
train_recall=0.6909090876579285, 
train_precision=0.7599999904632568, 
train_specificity=0.8651685118675232, 
train_balance_acc=0.7780387997627258,
 train_f1_score=0.723809540271759,
 train_auc=0.8433095216751099

Epoch [86/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[10, 10],
        [ 7,  5]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=0.4166666567325592, 
eval_precision=0.3333333432674408, 
eval_specificity=0.5, 
eval_balance_acc=0.4583333134651184,
 eval_f1_score=0.37037035822868347,
 eval_auc=0.5916666388511658


Epoch: 87/200
Training Epoch 87, LR 0.000488:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 87, LR 0.000488:   6%|â–Œ         | 1/18 [00:03<01:05,  3.83s/batch]Training Epoch 87, LR 0.000488:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 87, LR 0.000488:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 87, LR 0.000488:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 87, LR 0.000488:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 87, LR 0.000488:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 87, LR 0.000488:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.22batch/s]Training Epoch 87, LR 0.000488:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 87, LR 0.000488:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 87, LR 0.000488:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 87, LR 0.000488:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.38batch/s]Training Epoch 87, LR 0.000488:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 87, LR 0.000488:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 87, LR 0.000488:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 87, LR 0.000488:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 87, LR 0.000488:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.61batch/s]Training Epoch 87, LR 0.000488:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.03batch/s]Training Epoch 87, LR 0.000488: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.25batch/s]Training Epoch 87, LR 0.000488: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 87:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 87:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.53s/batch]Evaluating Epoch 87:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 87:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 87: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [87/200]:, train_loss=0.046, 
train_confusionMatrix:
tensor([[82,  7],
        [13, 42]], device='cuda:0')
train_accuracy=0.8611111044883728, 
train_recall=0.7636363506317139, 
train_precision=0.8571428656578064, 
train_specificity=0.9213483333587646, 
train_balance_acc=0.8424923419952393,
 train_f1_score=0.807692289352417,
 train_auc=0.8876404762268066

Epoch [87/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[18,  3],
        [ 8,  3]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.27272728085517883, 
eval_precision=0.5, 
eval_specificity=0.8571428656578064, 
eval_balance_acc=0.5649350881576538,
 eval_f1_score=0.3529411852359772,
 eval_auc=0.6363636255264282


Epoch: 88/200
Training Epoch 88, LR 0.000470:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 88, LR 0.000470:   6%|â–Œ         | 1/18 [00:03<01:05,  3.87s/batch]Training Epoch 88, LR 0.000470:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 88, LR 0.000470:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 88, LR 0.000470:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 88, LR 0.000470:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.25s/batch]Training Epoch 88, LR 0.000470:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 88, LR 0.000470:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 88, LR 0.000470:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 88, LR 0.000470:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.11s/batch]Training Epoch 88, LR 0.000470:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 88, LR 0.000470:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 88, LR 0.000470:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 88, LR 0.000470:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 88, LR 0.000470:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.17batch/s]Training Epoch 88, LR 0.000470:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 88, LR 0.000470:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 88, LR 0.000470:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 88, LR 0.000470: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 88, LR 0.000470: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 88:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 88:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.50s/batch]Evaluating Epoch 88:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 88:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 88: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 88: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [88/200]:, train_loss=0.050, 
train_confusionMatrix:
tensor([[81,  8],
        [20, 35]], device='cuda:0')
train_accuracy=0.8055555820465088, 
train_recall=0.6363636255264282, 
train_precision=0.8139534592628479, 
train_specificity=0.9101123809814453, 
train_balance_acc=0.7732380032539368,
 train_f1_score=0.7142857313156128,
 train_auc=0.856792688369751

Epoch [88/200]:, eval_loss=0.019, 
eval_confusionMatrix:
tensor([[ 2, 17],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=1.0, 
eval_precision=0.4333333373069763, 
eval_specificity=0.10526315867900848, 
eval_balance_acc=0.5526315569877625,
 eval_f1_score=0.604651153087616,
 eval_auc=0.6052631735801697


Epoch: 89/200
Training Epoch 89, LR 0.000453:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 89, LR 0.000453:   6%|â–Œ         | 1/18 [00:03<01:05,  3.86s/batch]Training Epoch 89, LR 0.000453:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 89, LR 0.000453:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 89, LR 0.000453:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 89, LR 0.000453:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 89, LR 0.000453:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 89, LR 0.000453:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 89, LR 0.000453:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 89, LR 0.000453:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:11,  1.23s/batch]Training Epoch 89, LR 0.000453:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.03batch/s]Training Epoch 89, LR 0.000453:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.25batch/s]Training Epoch 89, LR 0.000453:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:04,  1.48batch/s]Training Epoch 89, LR 0.000453:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 89, LR 0.000453:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.16batch/s]Training Epoch 89, LR 0.000453:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 89, LR 0.000453:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.59batch/s]Training Epoch 89, LR 0.000453:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.09s/batch]Training Epoch 89, LR 0.000453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.13batch/s]Training Epoch 89, LR 0.000453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 89:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 89:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.57s/batch]Evaluating Epoch 89:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 89:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 89: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [89/200]:, train_loss=0.045, 
train_confusionMatrix:
tensor([[83,  6],
        [17, 38]], device='cuda:0')
train_accuracy=0.8402777910232544, 
train_recall=0.6909090876579285, 
train_precision=0.8636363744735718, 
train_specificity=0.932584285736084, 
train_balance_acc=0.8117467164993286,
 train_f1_score=0.7676767706871033,
 train_auc=0.8937690854072571

Epoch [89/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[19,  1],
        [11,  1]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0833333358168602, 
eval_precision=0.5, 
eval_specificity=0.949999988079071, 
eval_balance_acc=0.5166666507720947,
 eval_f1_score=0.1428571492433548,
 eval_auc=0.6499999761581421


Epoch: 90/200
Training Epoch 90, LR 0.000436:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 90, LR 0.000436:   6%|â–Œ         | 1/18 [00:03<01:05,  3.82s/batch]Training Epoch 90, LR 0.000436:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 90, LR 0.000436:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 90, LR 0.000436:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 90, LR 0.000436:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 90, LR 0.000436:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 90, LR 0.000436:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 90, LR 0.000436:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 90, LR 0.000436:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.15s/batch]Training Epoch 90, LR 0.000436:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.09batch/s]Training Epoch 90, LR 0.000436:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.31batch/s]Training Epoch 90, LR 0.000436:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 90, LR 0.000436:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 90, LR 0.000436:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.16batch/s]Training Epoch 90, LR 0.000436:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 90, LR 0.000436:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.58batch/s]Training Epoch 90, LR 0.000436:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.09s/batch]Training Epoch 90, LR 0.000436: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.13batch/s]Training Epoch 90, LR 0.000436: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 90:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 90:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.85s/batch]Evaluating Epoch 90:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.68s/batch]Evaluating Epoch 90:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.02batch/s]Evaluating Epoch 90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.53batch/s]Evaluating Epoch 90: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.09s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [90/200]:, train_loss=0.049, 
train_confusionMatrix:
tensor([[82,  7],
        [18, 37]], device='cuda:0')
train_accuracy=0.8263888955116272, 
train_recall=0.6727272868156433, 
train_precision=0.8409090638160706, 
train_specificity=0.9213483333587646, 
train_balance_acc=0.7970378398895264,
 train_f1_score=0.747474730014801,
 train_auc=0.8545454740524292

Epoch [90/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[17,  2],
        [12,  1]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.07692307978868484, 
eval_precision=0.3333333432674408, 
eval_specificity=0.8947368264198303, 
eval_balance_acc=0.4858299493789673,
 eval_f1_score=0.125,
 eval_auc=0.5587044358253479


Epoch: 91/200
Training Epoch 91, LR 0.000419:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 91, LR 0.000419:   6%|â–Œ         | 1/18 [00:03<01:07,  3.94s/batch]Training Epoch 91, LR 0.000419:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.86s/batch]Training Epoch 91, LR 0.000419:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.20s/batch]Training Epoch 91, LR 0.000419:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 91, LR 0.000419:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 91, LR 0.000419:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 91, LR 0.000419:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.23batch/s]Training Epoch 91, LR 0.000419:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 91, LR 0.000419:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.18s/batch]Training Epoch 91, LR 0.000419:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.06batch/s]Training Epoch 91, LR 0.000419:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.29batch/s]Training Epoch 91, LR 0.000419:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.51batch/s]Training Epoch 91, LR 0.000419:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.10s/batch]Training Epoch 91, LR 0.000419:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.12batch/s]Training Epoch 91, LR 0.000419:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.34batch/s]Training Epoch 91, LR 0.000419:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.55batch/s]Training Epoch 91, LR 0.000419:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.05s/batch]Training Epoch 91, LR 0.000419: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 91, LR 0.000419: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 91:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 91:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.60s/batch]Evaluating Epoch 91:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 91:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 91: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 91: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [91/200]:, train_loss=0.048, 
train_confusionMatrix:
tensor([[82,  7],
        [14, 41]], device='cuda:0')
train_accuracy=0.8541666865348816, 
train_recall=0.7454545497894287, 
train_precision=0.8541666865348816, 
train_specificity=0.9213483333587646, 
train_balance_acc=0.8334014415740967,
 train_f1_score=0.7961165308952332,
 train_auc=0.8504596948623657

Epoch [91/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[ 9, 11],
        [ 4,  8]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.6666666865348816, 
eval_precision=0.42105263471603394, 
eval_specificity=0.44999998807907104, 
eval_balance_acc=0.5583333373069763,
 eval_f1_score=0.5161290168762207,
 eval_auc=0.637499988079071


Epoch: 92/200
Training Epoch 92, LR 0.000402:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 92, LR 0.000402:   6%|â–Œ         | 1/18 [00:03<01:07,  3.99s/batch]Training Epoch 92, LR 0.000402:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.88s/batch]Training Epoch 92, LR 0.000402:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 92, LR 0.000402:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 92, LR 0.000402:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.32s/batch]Training Epoch 92, LR 0.000402:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 92, LR 0.000402:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.23batch/s]Training Epoch 92, LR 0.000402:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 92, LR 0.000402:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 92, LR 0.000402:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 92, LR 0.000402:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.38batch/s]Training Epoch 92, LR 0.000402:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 92, LR 0.000402:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 92, LR 0.000402:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.19batch/s]Training Epoch 92, LR 0.000402:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 92, LR 0.000402:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 92, LR 0.000402:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 92, LR 0.000402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.23batch/s]Training Epoch 92, LR 0.000402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 92:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 92:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.53s/batch]Evaluating Epoch 92:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 92:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 92: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [92/200]:, train_loss=0.045, 
train_confusionMatrix:
tensor([[79, 10],
        [13, 42]], device='cuda:0')
train_accuracy=0.8402777910232544, 
train_recall=0.7636363506317139, 
train_precision=0.807692289352417, 
train_specificity=0.8876404762268066, 
train_balance_acc=0.8256384134292603,
 train_f1_score=0.7850467562675476,
 train_auc=0.8921347856521606

Epoch [92/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[11,  8],
        [ 3, 10]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.7692307829856873, 
eval_precision=0.5555555820465088, 
eval_specificity=0.5789473652839661, 
eval_balance_acc=0.6740890741348267,
 eval_f1_score=0.6451612710952759,
 eval_auc=0.6842105388641357


Epoch: 93/200
Training Epoch 93, LR 0.000385:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 93, LR 0.000385:   6%|â–Œ         | 1/18 [00:03<01:06,  3.90s/batch]Training Epoch 93, LR 0.000385:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 93, LR 0.000385:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 93, LR 0.000385:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 93, LR 0.000385:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 93, LR 0.000385:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 93, LR 0.000385:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.22batch/s]Training Epoch 93, LR 0.000385:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 93, LR 0.000385:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 93, LR 0.000385:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 93, LR 0.000385:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 93, LR 0.000385:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 93, LR 0.000385:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.17s/batch]Training Epoch 93, LR 0.000385:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.07batch/s]Training Epoch 93, LR 0.000385:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.29batch/s]Training Epoch 93, LR 0.000385:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.50batch/s]Training Epoch 93, LR 0.000385:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.12s/batch]Training Epoch 93, LR 0.000385: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.10batch/s]Training Epoch 93, LR 0.000385: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 93:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 93:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.63s/batch]Evaluating Epoch 93:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.71s/batch]Evaluating Epoch 93:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.00batch/s]Evaluating Epoch 93: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.50batch/s]Evaluating Epoch 93: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.09s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [93/200]:, train_loss=0.051, 
train_confusionMatrix:
tensor([[78, 12],
        [20, 34]], device='cuda:0')
train_accuracy=0.7777777910232544, 
train_recall=0.6296296119689941, 
train_precision=0.739130437374115, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.7481481432914734,
 train_f1_score=0.6800000071525574,
 train_auc=0.8572016358375549

Epoch [93/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[13,  7],
        [ 8,  4]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.3333333432674408, 
eval_precision=0.3636363744735718, 
eval_specificity=0.6499999761581421, 
eval_balance_acc=0.49166667461395264,
 eval_f1_score=0.3478260934352875,
 eval_auc=0.6583333611488342


Epoch: 94/200
Training Epoch 94, LR 0.000369:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 94, LR 0.000369:   6%|â–Œ         | 1/18 [00:03<01:05,  3.88s/batch]Training Epoch 94, LR 0.000369:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 94, LR 0.000369:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 94, LR 0.000369:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 94, LR 0.000369:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 94, LR 0.000369:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 94, LR 0.000369:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 94, LR 0.000369:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 94, LR 0.000369:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 94, LR 0.000369:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 94, LR 0.000369:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 94, LR 0.000369:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 94, LR 0.000369:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 94, LR 0.000369:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 94, LR 0.000369:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 94, LR 0.000369:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 94, LR 0.000369:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 94, LR 0.000369: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 94, LR 0.000369: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 94:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 94:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.56s/batch]Evaluating Epoch 94:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 94:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 94: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.64batch/s]Evaluating Epoch 94: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [94/200]:, train_loss=0.047, 
train_confusionMatrix:
tensor([[81,  8],
        [15, 40]], device='cuda:0')
train_accuracy=0.8402777910232544, 
train_recall=0.7272727489471436, 
train_precision=0.8333333134651184, 
train_specificity=0.9101123809814453, 
train_balance_acc=0.8186925649642944,
 train_f1_score=0.7766990065574646,
 train_auc=0.8802860379219055

Epoch [94/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[13,  8],
        [ 6,  5]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.4545454680919647, 
eval_precision=0.38461539149284363, 
eval_specificity=0.6190476417541504, 
eval_balance_acc=0.5367965698242188,
 eval_f1_score=0.4166666567325592,
 eval_auc=0.6839826107025146


Epoch: 95/200
Training Epoch 95, LR 0.000352:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 95, LR 0.000352:   6%|â–Œ         | 1/18 [00:04<01:08,  4.05s/batch]Training Epoch 95, LR 0.000352:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.91s/batch]Training Epoch 95, LR 0.000352:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.22s/batch]Training Epoch 95, LR 0.000352:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 95, LR 0.000352:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.38s/batch]Training Epoch 95, LR 0.000352:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.08s/batch]Training Epoch 95, LR 0.000352:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.16batch/s]Training Epoch 95, LR 0.000352:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.39batch/s]Training Epoch 95, LR 0.000352:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.18s/batch]Training Epoch 95, LR 0.000352:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.01batch/s]Training Epoch 95, LR 0.000352:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.24batch/s]Training Epoch 95, LR 0.000352:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.46batch/s]Training Epoch 95, LR 0.000352:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.08s/batch]Training Epoch 95, LR 0.000352:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.08batch/s]Training Epoch 95, LR 0.000352:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.30batch/s]Training Epoch 95, LR 0.000352:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.51batch/s]Training Epoch 95, LR 0.000352:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.00s/batch]Training Epoch 95, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.15batch/s]Training Epoch 95, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 95:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 95:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.60s/batch]Evaluating Epoch 95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [95/200]:, train_loss=0.052, 
train_confusionMatrix:
tensor([[78, 12],
        [19, 35]], device='cuda:0')
train_accuracy=0.7847222089767456, 
train_recall=0.6481481194496155, 
train_precision=0.7446808218955994, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.7574074268341064,
 train_f1_score=0.6930692791938782,
 train_auc=0.8337448835372925

Epoch [95/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[17,  2],
        [12,  1]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.07692307978868484, 
eval_precision=0.3333333432674408, 
eval_specificity=0.8947368264198303, 
eval_balance_acc=0.4858299493789673,
 eval_f1_score=0.125,
 eval_auc=0.3927125334739685


Epoch: 96/200
Training Epoch 96, LR 0.000336:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 96, LR 0.000336:   6%|â–Œ         | 1/18 [00:03<01:07,  3.96s/batch]Training Epoch 96, LR 0.000336:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 96, LR 0.000336:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 96, LR 0.000336:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 96, LR 0.000336:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.45s/batch]Training Epoch 96, LR 0.000336:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.10s/batch]Training Epoch 96, LR 0.000336:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.15batch/s]Training Epoch 96, LR 0.000336:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.39batch/s]Training Epoch 96, LR 0.000336:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:10,  1.19s/batch]Training Epoch 96, LR 0.000336:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.06batch/s]Training Epoch 96, LR 0.000336:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.28batch/s]Training Epoch 96, LR 0.000336:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.50batch/s]Training Epoch 96, LR 0.000336:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.15s/batch]Training Epoch 96, LR 0.000336:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.08batch/s]Training Epoch 96, LR 0.000336:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.30batch/s]Training Epoch 96, LR 0.000336:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.52batch/s]Training Epoch 96, LR 0.000336:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.11s/batch]Training Epoch 96, LR 0.000336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.12batch/s]Training Epoch 96, LR 0.000336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 96:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 96:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:12,  4.03s/batch]Evaluating Epoch 96:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.75s/batch]Evaluating Epoch 96:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.02s/batch]Evaluating Epoch 96: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.48batch/s]Evaluating Epoch 96: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.13s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [96/200]:, train_loss=0.049, 
train_confusionMatrix:
tensor([[78, 11],
        [16, 39]], device='cuda:0')
train_accuracy=0.8125, 
train_recall=0.7090908885002136, 
train_precision=0.7799999713897705, 
train_specificity=0.8764045238494873, 
train_balance_acc=0.7927477359771729,
 train_f1_score=0.7428571581840515,
 train_auc=0.8516854047775269

Epoch [96/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[15,  6],
        [ 8,  3]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.27272728085517883, 
eval_precision=0.3333333432674408, 
eval_specificity=0.7142857313156128, 
eval_balance_acc=0.4935064911842346,
 eval_f1_score=0.30000001192092896,
 eval_auc=0.5454545617103577


Epoch: 97/200
Training Epoch 97, LR 0.000320:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 97, LR 0.000320:   6%|â–Œ         | 1/18 [00:04<01:08,  4.02s/batch]Training Epoch 97, LR 0.000320:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.90s/batch]Training Epoch 97, LR 0.000320:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.22s/batch]Training Epoch 97, LR 0.000320:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 97, LR 0.000320:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 97, LR 0.000320:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 97, LR 0.000320:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.22batch/s]Training Epoch 97, LR 0.000320:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 97, LR 0.000320:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.11s/batch]Training Epoch 97, LR 0.000320:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.12batch/s]Training Epoch 97, LR 0.000320:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 97, LR 0.000320:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 97, LR 0.000320:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.14s/batch]Training Epoch 97, LR 0.000320:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.09batch/s]Training Epoch 97, LR 0.000320:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.31batch/s]Training Epoch 97, LR 0.000320:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.53batch/s]Training Epoch 97, LR 0.000320:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.05s/batch]Training Epoch 97, LR 0.000320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 97, LR 0.000320: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 97:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 97:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.54s/batch]Evaluating Epoch 97:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 97:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 97: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 97: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [97/200]:, train_loss=0.050, 
train_confusionMatrix:
tensor([[73, 16],
        [16, 39]], device='cuda:0')
train_accuracy=0.7777777910232544, 
train_recall=0.7090908885002136, 
train_precision=0.7090908885002136, 
train_specificity=0.8202247023582458, 
train_balance_acc=0.7646577954292297,
 train_f1_score=0.7090908885002136,
 train_auc=0.8449438214302063

Epoch [97/200]:, eval_loss=0.020, 
eval_confusionMatrix:
tensor([[ 0, 19],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=1.0, 
eval_precision=0.40625, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5777778029441833,
 eval_auc=0.5465587377548218


Epoch: 98/200
Training Epoch 98, LR 0.000304:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 98, LR 0.000304:   6%|â–Œ         | 1/18 [00:03<01:04,  3.79s/batch]Training Epoch 98, LR 0.000304:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 98, LR 0.000304:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 98, LR 0.000304:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.16batch/s]Training Epoch 98, LR 0.000304:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.32s/batch]Training Epoch 98, LR 0.000304:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 98, LR 0.000304:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.23batch/s]Training Epoch 98, LR 0.000304:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 98, LR 0.000304:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 98, LR 0.000304:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 98, LR 0.000304:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 98, LR 0.000304:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 98, LR 0.000304:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 98, LR 0.000304:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 98, LR 0.000304:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 98, LR 0.000304:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 98, LR 0.000304:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.05s/batch]Training Epoch 98, LR 0.000304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.13batch/s]Training Epoch 98, LR 0.000304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 98:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 98:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.66s/batch]Evaluating Epoch 98:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.61s/batch]Evaluating Epoch 98:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.06batch/s]Evaluating Epoch 98: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 98: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [98/200]:, train_loss=0.044, 
train_confusionMatrix:
tensor([[86,  4],
        [14, 40]], device='cuda:0')
train_accuracy=0.875, 
train_recall=0.7407407164573669, 
train_precision=0.9090909361839294, 
train_specificity=0.9555555582046509, 
train_balance_acc=0.8481481075286865,
 train_f1_score=0.8163265585899353,
 train_auc=0.9030864238739014

Epoch [98/200]:, eval_loss=0.018, 
eval_confusionMatrix:
tensor([[ 2, 17],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=1.0, 
eval_precision=0.4333333373069763, 
eval_specificity=0.10526315867900848, 
eval_balance_acc=0.5526315569877625,
 eval_f1_score=0.604651153087616,
 eval_auc=0.7894736528396606


Epoch: 99/200
Training Epoch 99, LR 0.000288:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 99, LR 0.000288:   6%|â–Œ         | 1/18 [00:04<01:08,  4.05s/batch]Training Epoch 99, LR 0.000288:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.90s/batch]Training Epoch 99, LR 0.000288:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.22s/batch]Training Epoch 99, LR 0.000288:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 99, LR 0.000288:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 99, LR 0.000288:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 99, LR 0.000288:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.24batch/s]Training Epoch 99, LR 0.000288:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 99, LR 0.000288:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 99, LR 0.000288:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.11batch/s]Training Epoch 99, LR 0.000288:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 99, LR 0.000288:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 99, LR 0.000288:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 99, LR 0.000288:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 99, LR 0.000288:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 99, LR 0.000288:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 99, LR 0.000288:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.06s/batch]Training Epoch 99, LR 0.000288: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 99, LR 0.000288: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 99:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 99:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.74s/batch]Evaluating Epoch 99:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.63s/batch]Evaluating Epoch 99:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.56batch/s]Evaluating Epoch 99: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [99/200]:, train_loss=0.048, 
train_confusionMatrix:
tensor([[78, 11],
        [13, 42]], device='cuda:0')
train_accuracy=0.8333333134651184, 
train_recall=0.7636363506317139, 
train_precision=0.7924528121948242, 
train_specificity=0.8764045238494873, 
train_balance_acc=0.8200204372406006,
 train_f1_score=0.7777777910232544,
 train_auc=0.8862103819847107

Epoch [99/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[15,  4],
        [10,  3]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.23076923191547394, 
eval_precision=0.4285714328289032, 
eval_specificity=0.7894737124443054, 
eval_balance_acc=0.5101214647293091,
 eval_f1_score=0.30000001192092896,
 eval_auc=0.7570849657058716


Epoch: 100/200
Training Epoch 100, LR 0.000273:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 100, LR 0.000273:   6%|â–Œ         | 1/18 [00:04<01:08,  4.05s/batch]Training Epoch 100, LR 0.000273:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.90s/batch]Training Epoch 100, LR 0.000273:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.22s/batch]Training Epoch 100, LR 0.000273:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 100, LR 0.000273:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.40s/batch]Training Epoch 100, LR 0.000273:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.06s/batch]Training Epoch 100, LR 0.000273:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.18batch/s]Training Epoch 100, LR 0.000273:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.41batch/s]Training Epoch 100, LR 0.000273:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.15s/batch]Training Epoch 100, LR 0.000273:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.09batch/s]Training Epoch 100, LR 0.000273:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.31batch/s]Training Epoch 100, LR 0.000273:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.53batch/s]Training Epoch 100, LR 0.000273:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.16s/batch]Training Epoch 100, LR 0.000273:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.07batch/s]Training Epoch 100, LR 0.000273:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.29batch/s]Training Epoch 100, LR 0.000273:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.51batch/s]Training Epoch 100, LR 0.000273:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.14s/batch]Training Epoch 100, LR 0.000273: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.09batch/s]Training Epoch 100, LR 0.000273: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 100:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 100:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.71s/batch]Evaluating Epoch 100:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.62s/batch]Evaluating Epoch 100:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.06batch/s]Evaluating Epoch 100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 100: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [100/200]:, train_loss=0.046, 
train_confusionMatrix:
tensor([[80, 10],
        [13, 41]], device='cuda:0')
train_accuracy=0.8402777910232544, 
train_recall=0.7592592835426331, 
train_precision=0.8039215803146362, 
train_specificity=0.8888888955116272, 
train_balance_acc=0.8240740895271301,
 train_f1_score=0.7809523940086365,
 train_auc=0.885185182094574

Epoch [100/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[12,  8],
        [ 5,  7]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.5833333134651184, 
eval_precision=0.46666666865348816, 
eval_specificity=0.6000000238418579, 
eval_balance_acc=0.5916666984558105,
 eval_f1_score=0.5185185074806213,
 eval_auc=0.6833332777023315


Epoch: 101/200
Training Epoch 101, LR 0.000258:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 101, LR 0.000258:   6%|â–Œ         | 1/18 [00:03<01:05,  3.87s/batch]Training Epoch 101, LR 0.000258:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 101, LR 0.000258:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 101, LR 0.000258:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 101, LR 0.000258:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.27s/batch]Training Epoch 101, LR 0.000258:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 101, LR 0.000258:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 101, LR 0.000258:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 101, LR 0.000258:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 101, LR 0.000258:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 101, LR 0.000258:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 101, LR 0.000258:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 101, LR 0.000258:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.13s/batch]Training Epoch 101, LR 0.000258:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.10batch/s]Training Epoch 101, LR 0.000258:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.32batch/s]Training Epoch 101, LR 0.000258:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.53batch/s]Training Epoch 101, LR 0.000258:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.12s/batch]Training Epoch 101, LR 0.000258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.10batch/s]Training Epoch 101, LR 0.000258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 101:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 101:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.51s/batch]Evaluating Epoch 101:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 101:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 101: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 101: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [101/200]:, train_loss=0.044, 
train_confusionMatrix:
tensor([[80,  9],
        [ 9, 46]], device='cuda:0')
train_accuracy=0.875, 
train_recall=0.8363636136054993, 
train_precision=0.8363636136054993, 
train_specificity=0.898876428604126, 
train_balance_acc=0.8676199913024902,
 train_f1_score=0.8363636136054993,
 train_auc=0.907252311706543

Epoch [101/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[12,  7],
        [ 9,  4]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.3076923191547394, 
eval_precision=0.3636363744735718, 
eval_specificity=0.6315789222717285, 
eval_balance_acc=0.46963560581207275,
 eval_f1_score=0.3333333432674408,
 eval_auc=0.6072874665260315


Epoch: 102/200
Training Epoch 102, LR 0.000243:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 102, LR 0.000243:   6%|â–Œ         | 1/18 [00:03<01:05,  3.84s/batch]Training Epoch 102, LR 0.000243:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 102, LR 0.000243:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 102, LR 0.000243:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 102, LR 0.000243:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.39s/batch]Training Epoch 102, LR 0.000243:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 102, LR 0.000243:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.19batch/s]Training Epoch 102, LR 0.000243:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.43batch/s]Training Epoch 102, LR 0.000243:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.24s/batch]Training Epoch 102, LR 0.000243:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.02batch/s]Training Epoch 102, LR 0.000243:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.24batch/s]Training Epoch 102, LR 0.000243:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.46batch/s]Training Epoch 102, LR 0.000243:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.16s/batch]Training Epoch 102, LR 0.000243:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.07batch/s]Training Epoch 102, LR 0.000243:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.29batch/s]Training Epoch 102, LR 0.000243:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.51batch/s]Training Epoch 102, LR 0.000243:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.05s/batch]Training Epoch 102, LR 0.000243: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.17batch/s]Training Epoch 102, LR 0.000243: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 102:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 102:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.65s/batch]Evaluating Epoch 102:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.59s/batch]Evaluating Epoch 102:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.59batch/s]Evaluating Epoch 102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [102/200]:, train_loss=0.046, 
train_confusionMatrix:
tensor([[82,  7],
        [18, 37]], device='cuda:0')
train_accuracy=0.8263888955116272, 
train_recall=0.6727272868156433, 
train_precision=0.8409090638160706, 
train_specificity=0.9213483333587646, 
train_balance_acc=0.7970378398895264,
 train_f1_score=0.747474730014801,
 train_auc=0.9074565768241882

Epoch [102/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[12,  8],
        [ 3,  9]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.75, 
eval_precision=0.529411792755127, 
eval_specificity=0.6000000238418579, 
eval_balance_acc=0.675000011920929,
 eval_f1_score=0.6206896305084229,
 eval_auc=0.7749999761581421


Epoch: 103/200
Training Epoch 103, LR 0.000228:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 103, LR 0.000228:   6%|â–Œ         | 1/18 [00:03<01:07,  3.97s/batch]Training Epoch 103, LR 0.000228:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 103, LR 0.000228:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 103, LR 0.000228:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 103, LR 0.000228:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 103, LR 0.000228:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 103, LR 0.000228:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 103, LR 0.000228:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 103, LR 0.000228:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.21s/batch]Training Epoch 103, LR 0.000228:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.04batch/s]Training Epoch 103, LR 0.000228:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.27batch/s]Training Epoch 103, LR 0.000228:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.48batch/s]Training Epoch 103, LR 0.000228:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.18s/batch]Training Epoch 103, LR 0.000228:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.06batch/s]Training Epoch 103, LR 0.000228:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.28batch/s]Training Epoch 103, LR 0.000228:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.50batch/s]Training Epoch 103, LR 0.000228:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.08s/batch]Training Epoch 103, LR 0.000228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.14batch/s]Training Epoch 103, LR 0.000228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 103:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 103:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.72s/batch]Evaluating Epoch 103:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.63s/batch]Evaluating Epoch 103:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.56batch/s]Evaluating Epoch 103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [103/200]:, train_loss=0.043, 
train_confusionMatrix:
tensor([[84,  5],
        [13, 42]], device='cuda:0')
train_accuracy=0.875, 
train_recall=0.7636363506317139, 
train_precision=0.8936170339584351, 
train_specificity=0.9438202381134033, 
train_balance_acc=0.8537282943725586,
 train_f1_score=0.8235294222831726,
 train_auc=0.9082737565040588

Epoch [103/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[13,  6],
        [ 8,  5]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.38461539149284363, 
eval_precision=0.4545454680919647, 
eval_specificity=0.6842105388641357, 
eval_balance_acc=0.5344129800796509,
 eval_f1_score=0.4166666567325592,
 eval_auc=0.659919023513794


Epoch: 104/200
Training Epoch 104, LR 0.000214:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 104, LR 0.000214:   6%|â–Œ         | 1/18 [00:03<01:05,  3.86s/batch]Training Epoch 104, LR 0.000214:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 104, LR 0.000214:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 104, LR 0.000214:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 104, LR 0.000214:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.25s/batch]Training Epoch 104, LR 0.000214:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.04batch/s]Training Epoch 104, LR 0.000214:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.28batch/s]Training Epoch 104, LR 0.000214:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 104, LR 0.000214:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.04s/batch]Training Epoch 104, LR 0.000214:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 104, LR 0.000214:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.40batch/s]Training Epoch 104, LR 0.000214:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 104, LR 0.000214:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 104, LR 0.000214:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.19batch/s]Training Epoch 104, LR 0.000214:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 104, LR 0.000214:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 104, LR 0.000214:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 104, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.20batch/s]Training Epoch 104, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 104:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 104:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.55s/batch]Evaluating Epoch 104:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 104:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 104: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 104: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [104/200]:, train_loss=0.043, 
train_confusionMatrix:
tensor([[85,  5],
        [10, 44]], device='cuda:0')
train_accuracy=0.8958333134651184, 
train_recall=0.8148148059844971, 
train_precision=0.8979591727256775, 
train_specificity=0.9444444179534912, 
train_balance_acc=0.8796296119689941,
 train_f1_score=0.8543689250946045,
 train_auc=0.9160494208335876

Epoch [104/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[15,  5],
        [ 8,  4]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.3333333432674408, 
eval_precision=0.4444444477558136, 
eval_specificity=0.75, 
eval_balance_acc=0.5416666865348816,
 eval_f1_score=0.380952388048172,
 eval_auc=0.7083333134651184


Epoch: 105/200
Training Epoch 105, LR 0.000200:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 105, LR 0.000200:   6%|â–Œ         | 1/18 [00:03<01:03,  3.73s/batch]Training Epoch 105, LR 0.000200:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 105, LR 0.000200:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 105, LR 0.000200:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.17batch/s]Training Epoch 105, LR 0.000200:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.37s/batch]Training Epoch 105, LR 0.000200:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 105, LR 0.000200:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 105, LR 0.000200:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.43batch/s]Training Epoch 105, LR 0.000200:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.18s/batch]Training Epoch 105, LR 0.000200:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.06batch/s]Training Epoch 105, LR 0.000200:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.28batch/s]Training Epoch 105, LR 0.000200:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.50batch/s]Training Epoch 105, LR 0.000200:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 105, LR 0.000200:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 105, LR 0.000200:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 105, LR 0.000200:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 105, LR 0.000200:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.03s/batch]Training Epoch 105, LR 0.000200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 105, LR 0.000200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 105:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 105:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.49s/batch]Evaluating Epoch 105:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.62s/batch]Evaluating Epoch 105:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.05batch/s]Evaluating Epoch 105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [105/200]:, train_loss=0.045, 
train_confusionMatrix:
tensor([[81,  8],
        [15, 40]], device='cuda:0')
train_accuracy=0.8402777910232544, 
train_recall=0.7272727489471436, 
train_precision=0.8333333134651184, 
train_specificity=0.9101123809814453, 
train_balance_acc=0.8186925649642944,
 train_f1_score=0.7766990065574646,
 train_auc=0.9088866114616394

Epoch [105/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[16,  5],
        [ 7,  4]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.3636363744735718, 
eval_precision=0.4444444477558136, 
eval_specificity=0.761904776096344, 
eval_balance_acc=0.5627706050872803,
 eval_f1_score=0.4000000059604645,
 eval_auc=0.7142857313156128


Epoch: 106/200
Training Epoch 106, LR 0.000187:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 106, LR 0.000187:   6%|â–Œ         | 1/18 [00:03<01:07,  3.98s/batch]Training Epoch 106, LR 0.000187:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.88s/batch]Training Epoch 106, LR 0.000187:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 106, LR 0.000187:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 106, LR 0.000187:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.38s/batch]Training Epoch 106, LR 0.000187:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 106, LR 0.000187:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 106, LR 0.000187:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.43batch/s]Training Epoch 106, LR 0.000187:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:11<00:11,  1.33s/batch]Training Epoch 106, LR 0.000187:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:08,  1.04s/batch]Training Epoch 106, LR 0.000187:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:12<00:05,  1.18batch/s]Training Epoch 106, LR 0.000187:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.40batch/s]Training Epoch 106, LR 0.000187:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:15<00:06,  1.27s/batch]Training Epoch 106, LR 0.000187:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:15<00:04,  1.00s/batch]Training Epoch 106, LR 0.000187:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.21batch/s]Training Epoch 106, LR 0.000187:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:16<00:01,  1.44batch/s]Training Epoch 106, LR 0.000187:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:18<00:01,  1.10s/batch]Training Epoch 106, LR 0.000187: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.12batch/s]Training Epoch 106, LR 0.000187: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 106:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 106:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.88s/batch]Evaluating Epoch 106:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.69s/batch]Evaluating Epoch 106:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.01batch/s]Evaluating Epoch 106: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.52batch/s]Evaluating Epoch 106: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.10s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [106/200]:, train_loss=0.043, 
train_confusionMatrix:
tensor([[85,  5],
        [13, 41]], device='cuda:0')
train_accuracy=0.875, 
train_recall=0.7592592835426331, 
train_precision=0.8913043737411499, 
train_specificity=0.9444444179534912, 
train_balance_acc=0.8518518209457397,
 train_f1_score=0.8199999928474426,
 train_auc=0.9228394627571106

Epoch [106/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[17,  2],
        [11,  2]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.1538461595773697, 
eval_precision=0.5, 
eval_specificity=0.8947368264198303, 
eval_balance_acc=0.5242915153503418,
 eval_f1_score=0.23529411852359772,
 eval_auc=0.6680161952972412


Epoch: 107/200
Training Epoch 107, LR 0.000174:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 107, LR 0.000174:   6%|â–Œ         | 1/18 [00:03<01:06,  3.89s/batch]Training Epoch 107, LR 0.000174:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 107, LR 0.000174:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 107, LR 0.000174:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 107, LR 0.000174:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 107, LR 0.000174:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 107, LR 0.000174:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.23batch/s]Training Epoch 107, LR 0.000174:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 107, LR 0.000174:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.21s/batch]Training Epoch 107, LR 0.000174:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.04batch/s]Training Epoch 107, LR 0.000174:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.27batch/s]Training Epoch 107, LR 0.000174:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.48batch/s]Training Epoch 107, LR 0.000174:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.14s/batch]Training Epoch 107, LR 0.000174:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.09batch/s]Training Epoch 107, LR 0.000174:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.31batch/s]Training Epoch 107, LR 0.000174:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.53batch/s]Training Epoch 107, LR 0.000174:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.15s/batch]Training Epoch 107, LR 0.000174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.08batch/s]Training Epoch 107, LR 0.000174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:18<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 107:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 107:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.77s/batch]Evaluating Epoch 107:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.64s/batch]Evaluating Epoch 107:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.56batch/s]Evaluating Epoch 107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [107/200]:, train_loss=0.043, 
train_confusionMatrix:
tensor([[83,  6],
        [11, 44]], device='cuda:0')
train_accuracy=0.8819444179534912, 
train_recall=0.800000011920929, 
train_precision=0.8799999952316284, 
train_specificity=0.932584285736084, 
train_balance_acc=0.8662921190261841,
 train_f1_score=0.8380952477455139,
 train_auc=0.9233912229537964

Epoch [107/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[10,  9],
        [ 4,  9]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.692307710647583, 
eval_precision=0.5, 
eval_specificity=0.5263158082962036, 
eval_balance_acc=0.6093117594718933,
 eval_f1_score=0.5806451439857483,
 eval_auc=0.7287449836730957


Epoch: 108/200
Training Epoch 108, LR 0.000161:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 108, LR 0.000161:   6%|â–Œ         | 1/18 [00:03<01:03,  3.76s/batch]Training Epoch 108, LR 0.000161:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 108, LR 0.000161:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 108, LR 0.000161:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 108, LR 0.000161:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.27s/batch]Training Epoch 108, LR 0.000161:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 108, LR 0.000161:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 108, LR 0.000161:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 108, LR 0.000161:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 108, LR 0.000161:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 108, LR 0.000161:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 108, LR 0.000161:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 108, LR 0.000161:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 108, LR 0.000161:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.13batch/s]Training Epoch 108, LR 0.000161:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 108, LR 0.000161:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 108, LR 0.000161:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 108, LR 0.000161: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 108, LR 0.000161: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 108:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 108:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.45s/batch]Evaluating Epoch 108:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 108:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.65batch/s]Evaluating Epoch 108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [108/200]:, train_loss=0.042, 
train_confusionMatrix:
tensor([[84,  5],
        [10, 45]], device='cuda:0')
train_accuracy=0.8958333134651184, 
train_recall=0.8181818127632141, 
train_precision=0.8999999761581421, 
train_specificity=0.9438202381134033, 
train_balance_acc=0.8810009956359863,
 train_f1_score=0.8571428656578064,
 train_auc=0.9338099956512451

Epoch [108/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[11,  9],
        [ 4,  8]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.6666666865348816, 
eval_precision=0.47058823704719543, 
eval_specificity=0.550000011920929, 
eval_balance_acc=0.6083333492279053,
 eval_f1_score=0.5517241358757019,
 eval_auc=0.6916666626930237


Epoch: 109/200
Training Epoch 109, LR 0.000149:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 109, LR 0.000149:   6%|â–Œ         | 1/18 [00:03<01:06,  3.89s/batch]Training Epoch 109, LR 0.000149:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 109, LR 0.000149:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 109, LR 0.000149:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 109, LR 0.000149:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 109, LR 0.000149:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.00batch/s]Training Epoch 109, LR 0.000149:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 109, LR 0.000149:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 109, LR 0.000149:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 109, LR 0.000149:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 109, LR 0.000149:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.37batch/s]Training Epoch 109, LR 0.000149:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 109, LR 0.000149:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 109, LR 0.000149:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.17batch/s]Training Epoch 109, LR 0.000149:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 109, LR 0.000149:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 109, LR 0.000149:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 109, LR 0.000149: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 109, LR 0.000149: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 109:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 109:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.79s/batch]Evaluating Epoch 109:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.65s/batch]Evaluating Epoch 109:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.03batch/s]Evaluating Epoch 109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.08s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [109/200]:, train_loss=0.041, 
train_confusionMatrix:
tensor([[83,  7],
        [ 8, 46]], device='cuda:0')
train_accuracy=0.8958333134651184, 
train_recall=0.8518518805503845, 
train_precision=0.8679245114326477, 
train_specificity=0.9222221970558167, 
train_balance_acc=0.8870370388031006,
 train_f1_score=0.8598130941390991,
 train_auc=0.9378600716590881

Epoch [109/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[10, 11],
        [ 2,  9]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.8181818127632141, 
eval_precision=0.44999998807907104, 
eval_specificity=0.4761904776096344, 
eval_balance_acc=0.6471861600875854,
 eval_f1_score=0.5806451439857483,
 eval_auc=0.5800865888595581


Epoch: 110/200
Training Epoch 110, LR 0.000137:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 110, LR 0.000137:   6%|â–Œ         | 1/18 [00:03<01:02,  3.66s/batch]Training Epoch 110, LR 0.000137:  11%|â–ˆ         | 2/18 [00:04<00:27,  1.75s/batch]Training Epoch 110, LR 0.000137:  17%|â–ˆâ–‹        | 3/18 [00:04<00:16,  1.13s/batch]Training Epoch 110, LR 0.000137:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.18batch/s]Training Epoch 110, LR 0.000137:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.27s/batch]Training Epoch 110, LR 0.000137:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 110, LR 0.000137:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 110, LR 0.000137:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 110, LR 0.000137:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.14s/batch]Training Epoch 110, LR 0.000137:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 110, LR 0.000137:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 110, LR 0.000137:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 110, LR 0.000137:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 110, LR 0.000137:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 110, LR 0.000137:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 110, LR 0.000137:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.56batch/s]Training Epoch 110, LR 0.000137:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.03s/batch]Training Epoch 110, LR 0.000137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 110, LR 0.000137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 110:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 110:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.53s/batch]Evaluating Epoch 110:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 110:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 110: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [110/200]:, train_loss=0.042, 
train_confusionMatrix:
tensor([[84,  6],
        [10, 44]], device='cuda:0')
train_accuracy=0.8888888955116272, 
train_recall=0.8148148059844971, 
train_precision=0.8799999952316284, 
train_specificity=0.9333333373069763, 
train_balance_acc=0.8740741014480591,
 train_f1_score=0.8461538553237915,
 train_auc=0.924074113368988

Epoch [110/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[11,  9],
        [ 7,  5]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.4166666567325592, 
eval_precision=0.3571428656578064, 
eval_specificity=0.550000011920929, 
eval_balance_acc=0.4833333492279053,
 eval_f1_score=0.38461539149284363,
 eval_auc=0.6708333492279053


Epoch: 111/200
Training Epoch 111, LR 0.000126:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 111, LR 0.000126:   6%|â–Œ         | 1/18 [00:03<01:01,  3.60s/batch]Training Epoch 111, LR 0.000126:  11%|â–ˆ         | 2/18 [00:04<00:27,  1.73s/batch]Training Epoch 111, LR 0.000126:  17%|â–ˆâ–‹        | 3/18 [00:04<00:16,  1.12s/batch]Training Epoch 111, LR 0.000126:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.19batch/s]Training Epoch 111, LR 0.000126:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.27s/batch]Training Epoch 111, LR 0.000126:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 111, LR 0.000126:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 111, LR 0.000126:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 111, LR 0.000126:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 111, LR 0.000126:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 111, LR 0.000126:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.38batch/s]Training Epoch 111, LR 0.000126:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 111, LR 0.000126:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 111, LR 0.000126:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.17batch/s]Training Epoch 111, LR 0.000126:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 111, LR 0.000126:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 111, LR 0.000126:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.03s/batch]Training Epoch 111, LR 0.000126: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.19batch/s]Training Epoch 111, LR 0.000126: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 111:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 111:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.65s/batch]Evaluating Epoch 111:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.59s/batch]Evaluating Epoch 111:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 111: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 111: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [111/200]:, train_loss=0.042, 
train_confusionMatrix:
tensor([[80,  9],
        [ 8, 47]], device='cuda:0')
train_accuracy=0.8819444179534912, 
train_recall=0.8545454740524292, 
train_precision=0.8392857313156128, 
train_specificity=0.898876428604126, 
train_balance_acc=0.8767109513282776,
 train_f1_score=0.8468468189239502,
 train_auc=0.9219611883163452

Epoch [111/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[16,  3],
        [ 9,  4]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.3076923191547394, 
eval_precision=0.5714285969734192, 
eval_specificity=0.8421052694320679, 
eval_balance_acc=0.5748987793922424,
 eval_f1_score=0.4000000059604645,
 eval_auc=0.7530364394187927


Epoch: 112/200
Training Epoch 112, LR 0.000115:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 112, LR 0.000115:   6%|â–Œ         | 1/18 [00:03<01:05,  3.87s/batch]Training Epoch 112, LR 0.000115:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 112, LR 0.000115:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 112, LR 0.000115:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 112, LR 0.000115:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.25s/batch]Training Epoch 112, LR 0.000115:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.04batch/s]Training Epoch 112, LR 0.000115:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.28batch/s]Training Epoch 112, LR 0.000115:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 112, LR 0.000115:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.05s/batch]Training Epoch 112, LR 0.000115:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 112, LR 0.000115:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.40batch/s]Training Epoch 112, LR 0.000115:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.61batch/s]Training Epoch 112, LR 0.000115:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 112, LR 0.000115:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.19batch/s]Training Epoch 112, LR 0.000115:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 112, LR 0.000115:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 112, LR 0.000115:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 112, LR 0.000115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.21batch/s]Training Epoch 112, LR 0.000115: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.07batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 112:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 112:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.56s/batch]Evaluating Epoch 112:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 112:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [112/200]:, train_loss=0.044, 
train_confusionMatrix:
tensor([[84,  5],
        [13, 42]], device='cuda:0')
train_accuracy=0.875, 
train_recall=0.7636363506317139, 
train_precision=0.8936170339584351, 
train_specificity=0.9438202381134033, 
train_balance_acc=0.8537282943725586,
 train_f1_score=0.8235294222831726,
 train_auc=0.9109295606613159

Epoch [112/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[16,  2],
        [10,  4]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.2857142984867096, 
eval_precision=0.6666666865348816, 
eval_specificity=0.8888888955116272, 
eval_balance_acc=0.5873016119003296,
 eval_f1_score=0.4000000059604645,
 eval_auc=0.8015872836112976


Epoch: 113/200
Training Epoch 113, LR 0.000105:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 113, LR 0.000105:   6%|â–Œ         | 1/18 [00:03<01:07,  3.99s/batch]Training Epoch 113, LR 0.000105:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.88s/batch]Training Epoch 113, LR 0.000105:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 113, LR 0.000105:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 113, LR 0.000105:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 113, LR 0.000105:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 113, LR 0.000105:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.23batch/s]Training Epoch 113, LR 0.000105:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 113, LR 0.000105:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.11s/batch]Training Epoch 113, LR 0.000105:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 113, LR 0.000105:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 113, LR 0.000105:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 113, LR 0.000105:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 113, LR 0.000105:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 113, LR 0.000105:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 113, LR 0.000105:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.58batch/s]Training Epoch 113, LR 0.000105:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 113, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 113, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 113:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 113:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.56s/batch]Evaluating Epoch 113:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 113:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 113: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 113: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [113/200]:, train_loss=0.041, 
train_confusionMatrix:
tensor([[85,  4],
        [10, 45]], device='cuda:0')
train_accuracy=0.9027777910232544, 
train_recall=0.8181818127632141, 
train_precision=0.918367326259613, 
train_specificity=0.9550561904907227, 
train_balance_acc=0.886618971824646,
 train_f1_score=0.8653846383094788,
 train_auc=0.9299284219741821

Epoch [113/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[11,  9],
        [ 8,  4]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=0.3333333432674408, 
eval_precision=0.3076923191547394, 
eval_specificity=0.550000011920929, 
eval_balance_acc=0.4416666626930237,
 eval_f1_score=0.3199999928474426,
 eval_auc=0.5416666865348816


Epoch: 114/200
Training Epoch 114, LR 0.000095:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 114, LR 0.000095:   6%|â–Œ         | 1/18 [00:04<01:09,  4.07s/batch]Training Epoch 114, LR 0.000095:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.92s/batch]Training Epoch 114, LR 0.000095:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.23s/batch]Training Epoch 114, LR 0.000095:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 114, LR 0.000095:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.38s/batch]Training Epoch 114, LR 0.000095:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 114, LR 0.000095:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.19batch/s]Training Epoch 114, LR 0.000095:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.43batch/s]Training Epoch 114, LR 0.000095:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.18s/batch]Training Epoch 114, LR 0.000095:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.07batch/s]Training Epoch 114, LR 0.000095:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.29batch/s]Training Epoch 114, LR 0.000095:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:04,  1.50batch/s]Training Epoch 114, LR 0.000095:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.01batch/s]Training Epoch 114, LR 0.000095:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.24batch/s]Training Epoch 114, LR 0.000095:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.45batch/s]Training Epoch 114, LR 0.000095:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.66batch/s]Training Epoch 114, LR 0.000095:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:00,  1.01batch/s]Training Epoch 114, LR 0.000095: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.23batch/s]Training Epoch 114, LR 0.000095: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 114:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 114:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.52s/batch]Evaluating Epoch 114:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 114:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [114/200]:, train_loss=0.043, 
train_confusionMatrix:
tensor([[85,  4],
        [13, 42]], device='cuda:0')
train_accuracy=0.8819444179534912, 
train_recall=0.7636363506317139, 
train_precision=0.9130434989929199, 
train_specificity=0.9550561904907227, 
train_balance_acc=0.8593462705612183,
 train_f1_score=0.8316831588745117,
 train_auc=0.9146068096160889

Epoch [114/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[15,  4],
        [ 9,  4]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.3076923191547394, 
eval_precision=0.5, 
eval_specificity=0.7894737124443054, 
eval_balance_acc=0.5485830307006836,
 eval_f1_score=0.380952388048172,
 eval_auc=0.6437246799468994


Early stopping
Fold 1 Best Epoch: 7
Best confusionMatrix : tensor([[21,  0],
        [10,  1]], device='cuda:0')
Best accuracy : 0.6875, 
Best recall : 0.09090909361839294, 
Best precision : 1.0, 
Best specificity : 1.0, 
Best balance_acc : 0.5454545617103577,
 Best f1_score : 0.1666666716337204,
 Best AUC : 0.6437246799468994


exp:AweSomeNet  seed -> 42
Fold 2/5
[DEBUG] Observer init successfully, program start @2025-04-07_21-44

The name of model will run <class 'Net.AweNet.AweSomeNet'>
Use model : {'Name': 'AweSomeNet', 'Model': <class 'Net.AweNet.AweSomeNet'>, 'dataset': <class 'Dataset.MriPetCliDataset'>, 'shape': (96, 128, 96), 'Loss': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Lr': 0.001, 'Run': <function run_main_for_awesome_net at 0x7f274773b790>, 'Scheduler': <function get_scheduler at 0x7f274c7ad670>}


===============================================

model parameters: 17357958

===============================================

Prepare completed for fold 2! Launch training!ðŸš€
start training
Epoch: 1/200
Training Epoch 1, LR 0.001000:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 1, LR 0.001000:   6%|â–Œ         | 1/18 [00:03<01:04,  3.78s/batch]Training Epoch 1, LR 0.001000:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 1, LR 0.001000:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 1, LR 0.001000:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.16batch/s]Training Epoch 1, LR 0.001000:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 1, LR 0.001000:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 1, LR 0.001000:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.22batch/s]Training Epoch 1, LR 0.001000:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 1, LR 0.001000:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.11s/batch]Training Epoch 1, LR 0.001000:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 1, LR 0.001000:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 1, LR 0.001000:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 1, LR 0.001000:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 1, LR 0.001000:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 1, LR 0.001000:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 1, LR 0.001000:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 1, LR 0.001000:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 1, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 1, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 1:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.41s/batch]Evaluating Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:02,  1.50s/batch]Evaluating Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.69batch/s]Evaluating Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [1/200]:, train_loss=0.068, 
train_confusionMatrix:
tensor([[90,  0],
        [54,  0]], device='cuda:0')
train_accuracy=0.625, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=1.0, 
train_balance_acc=0.5,
 train_f1_score=0.0,
 train_auc=0.5121399164199829

Epoch [1/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.5958333015441895


Best model saved to ././checkpoints_2025-04-07_21-44/AweSomeNet_best_model_fold2.pth


Epoch: 2/200
Training Epoch 2, LR 0.000976:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 2, LR 0.000976:   6%|â–Œ         | 1/18 [00:03<01:04,  3.77s/batch]Training Epoch 2, LR 0.000976:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 2, LR 0.000976:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 2, LR 0.000976:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 2, LR 0.000976:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.27s/batch]Training Epoch 2, LR 0.000976:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 2, LR 0.000976:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 2, LR 0.000976:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 2, LR 0.000976:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 2, LR 0.000976:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 2, LR 0.000976:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 2, LR 0.000976:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 2, LR 0.000976:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 2, LR 0.000976:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.16batch/s]Training Epoch 2, LR 0.000976:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 2, LR 0.000976:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 2, LR 0.000976:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 2, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 2, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 2:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 2:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.58s/batch]Evaluating Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [2/200]:, train_loss=0.066, 
train_confusionMatrix:
tensor([[89,  0],
        [55,  0]], device='cuda:0')
train_accuracy=0.6180555820465088, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=1.0, 
train_balance_acc=0.5,
 train_f1_score=0.0,
 train_auc=0.570990800857544

Epoch [2/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[ 0, 19],
        [ 1, 12]], device='cuda:0')
eval_accuracy=0.375, 
eval_recall=0.9230769276618958, 
eval_precision=0.3870967626571655, 
eval_specificity=0.0, 
eval_balance_acc=0.4615384638309479,
 eval_f1_score=0.5454545617103577,
 eval_auc=0.5182186365127563


Epoch: 3/200
Training Epoch 3, LR 0.000905:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 3, LR 0.000905:   6%|â–Œ         | 1/18 [00:03<01:06,  3.90s/batch]Training Epoch 3, LR 0.000905:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 3, LR 0.000905:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 3, LR 0.000905:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 3, LR 0.000905:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 3, LR 0.000905:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.00batch/s]Training Epoch 3, LR 0.000905:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 3, LR 0.000905:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 3, LR 0.000905:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.06s/batch]Training Epoch 3, LR 0.000905:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.16batch/s]Training Epoch 3, LR 0.000905:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.38batch/s]Training Epoch 3, LR 0.000905:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 3, LR 0.000905:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 3, LR 0.000905:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.20batch/s]Training Epoch 3, LR 0.000905:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.42batch/s]Training Epoch 3, LR 0.000905:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.63batch/s]Training Epoch 3, LR 0.000905:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.03s/batch]Training Epoch 3, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 3, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 3:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 3:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.44s/batch]Evaluating Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.51s/batch]Evaluating Epoch 3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.67batch/s]Evaluating Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [3/200]:, train_loss=0.064, 
train_confusionMatrix:
tensor([[84,  5],
        [50,  5]], device='cuda:0')
train_accuracy=0.6180555820465088, 
train_recall=0.09090909361839294, 
train_precision=0.5, 
train_specificity=0.9438202381134033, 
train_balance_acc=0.5173646807670593,
 train_f1_score=0.1538461595773697,
 train_auc=0.6181818246841431

Epoch [3/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 4, 15],
        [ 1, 12]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.9230769276618958, 
eval_precision=0.4444444477558136, 
eval_specificity=0.21052631735801697, 
eval_balance_acc=0.5668016076087952,
 eval_f1_score=0.6000000238418579,
 eval_auc=0.5546558499336243


Epoch: 4/200
Training Epoch 4, LR 0.000796:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 4, LR 0.000796:   6%|â–Œ         | 1/18 [00:03<01:04,  3.81s/batch]Training Epoch 4, LR 0.000796:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 4, LR 0.000796:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 4, LR 0.000796:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 4, LR 0.000796:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.26s/batch]Training Epoch 4, LR 0.000796:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 4, LR 0.000796:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 4, LR 0.000796:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 4, LR 0.000796:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 4, LR 0.000796:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.16batch/s]Training Epoch 4, LR 0.000796:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.38batch/s]Training Epoch 4, LR 0.000796:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 4, LR 0.000796:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 4, LR 0.000796:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.17batch/s]Training Epoch 4, LR 0.000796:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 4, LR 0.000796:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 4, LR 0.000796:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 4, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.19batch/s]Training Epoch 4, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 4:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 4:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.61s/batch]Evaluating Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 4:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [4/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[81,  8],
        [49,  6]], device='cuda:0')
train_accuracy=0.6041666865348816, 
train_recall=0.1090909093618393, 
train_precision=0.4285714328289032, 
train_specificity=0.9101123809814453, 
train_balance_acc=0.5096016526222229,
 train_f1_score=0.17391304671764374,
 train_auc=0.6093973517417908

Epoch [4/200]:, eval_loss=0.020, 
eval_confusionMatrix:
tensor([[ 0, 19],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=1.0, 
eval_precision=0.40625, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5777778029441833,
 eval_auc=0.554655909538269


Epoch: 5/200
Training Epoch 5, LR 0.000658:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 5, LR 0.000658:   6%|â–Œ         | 1/18 [00:03<01:05,  3.85s/batch]Training Epoch 5, LR 0.000658:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 5, LR 0.000658:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 5, LR 0.000658:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 5, LR 0.000658:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.25s/batch]Training Epoch 5, LR 0.000658:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 5, LR 0.000658:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.28batch/s]Training Epoch 5, LR 0.000658:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 5, LR 0.000658:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 5, LR 0.000658:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 5, LR 0.000658:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 5, LR 0.000658:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 5, LR 0.000658:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 5, LR 0.000658:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.14batch/s]Training Epoch 5, LR 0.000658:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 5, LR 0.000658:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 5, LR 0.000658:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.03s/batch]Training Epoch 5, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 5, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 5:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 5:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.70s/batch]Evaluating Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.61s/batch]Evaluating Epoch 5:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.06batch/s]Evaluating Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [5/200]:, train_loss=0.064, 
train_confusionMatrix:
tensor([[84,  5],
        [49,  6]], device='cuda:0')
train_accuracy=0.625, 
train_recall=0.1090909093618393, 
train_precision=0.5454545617103577, 
train_specificity=0.9438202381134033, 
train_balance_acc=0.5264555811882019,
 train_f1_score=0.1818181872367859,
 train_auc=0.5953013300895691

Epoch [5/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[15,  4],
        [ 8,  5]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.38461539149284363, 
eval_precision=0.5555555820465088, 
eval_specificity=0.7894737124443054, 
eval_balance_acc=0.5870445370674133,
 eval_f1_score=0.4545454680919647,
 eval_auc=0.52226722240448


Epoch: 6/200
Training Epoch 6, LR 0.000505:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 6, LR 0.000505:   6%|â–Œ         | 1/18 [00:03<01:03,  3.76s/batch]Training Epoch 6, LR 0.000505:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 6, LR 0.000505:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 6, LR 0.000505:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 6, LR 0.000505:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.25s/batch]Training Epoch 6, LR 0.000505:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 6, LR 0.000505:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 6, LR 0.000505:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 6, LR 0.000505:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 6, LR 0.000505:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 6, LR 0.000505:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 6, LR 0.000505:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 6, LR 0.000505:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 6, LR 0.000505:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.17batch/s]Training Epoch 6, LR 0.000505:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 6, LR 0.000505:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 6, LR 0.000505:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 6, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.21batch/s]Training Epoch 6, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 6:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 6:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 6:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [6/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[82,  7],
        [44, 11]], device='cuda:0')
train_accuracy=0.6458333134651184, 
train_recall=0.20000000298023224, 
train_precision=0.6111111044883728, 
train_specificity=0.9213483333587646, 
train_balance_acc=0.5606741905212402,
 train_f1_score=0.30136987566947937,
 train_auc=0.663942813873291

Epoch [6/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[ 6, 14],
        [ 2, 10]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.8333333134651184, 
eval_precision=0.4166666567325592, 
eval_specificity=0.30000001192092896, 
eval_balance_acc=0.5666666626930237,
 eval_f1_score=0.5555555820465088,
 eval_auc=0.6291666626930237


Epoch: 7/200
Training Epoch 7, LR 0.000352:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 7, LR 0.000352:   6%|â–Œ         | 1/18 [00:03<01:06,  3.93s/batch]Training Epoch 7, LR 0.000352:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.86s/batch]Training Epoch 7, LR 0.000352:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 7, LR 0.000352:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 7, LR 0.000352:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 7, LR 0.000352:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 7, LR 0.000352:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.24batch/s]Training Epoch 7, LR 0.000352:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 7, LR 0.000352:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 7, LR 0.000352:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 7, LR 0.000352:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.37batch/s]Training Epoch 7, LR 0.000352:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 7, LR 0.000352:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 7, LR 0.000352:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 7, LR 0.000352:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 7, LR 0.000352:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 7, LR 0.000352:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 7, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 7, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 7:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 7:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.65s/batch]Evaluating Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.64s/batch]Evaluating Epoch 7:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [7/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[80,  9],
        [39, 16]], device='cuda:0')
train_accuracy=0.6666666865348816, 
train_recall=0.290909081697464, 
train_precision=0.6399999856948853, 
train_specificity=0.898876428604126, 
train_balance_acc=0.5948927402496338,
 train_f1_score=0.4000000059604645,
 train_auc=0.6606742143630981

Epoch [7/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[16,  4],
        [ 7,  5]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.4166666567325592, 
eval_precision=0.5555555820465088, 
eval_specificity=0.800000011920929, 
eval_balance_acc=0.6083333492279053,
 eval_f1_score=0.4761904776096344,
 eval_auc=0.5583332777023315


Best model saved to ././checkpoints_2025-04-07_21-44/AweSomeNet_best_model_fold2.pth


Epoch: 8/200
Training Epoch 8, LR 0.000214:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 8, LR 0.000214:   6%|â–Œ         | 1/18 [00:03<01:01,  3.61s/batch]Training Epoch 8, LR 0.000214:  11%|â–ˆ         | 2/18 [00:04<00:27,  1.73s/batch]Training Epoch 8, LR 0.000214:  17%|â–ˆâ–‹        | 3/18 [00:04<00:16,  1.13s/batch]Training Epoch 8, LR 0.000214:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.19batch/s]Training Epoch 8, LR 0.000214:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:15,  1.21s/batch]Training Epoch 8, LR 0.000214:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.06batch/s]Training Epoch 8, LR 0.000214:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.31batch/s]Training Epoch 8, LR 0.000214:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:07<00:06,  1.54batch/s]Training Epoch 8, LR 0.000214:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:09<00:09,  1.03s/batch]Training Epoch 8, LR 0.000214:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.20batch/s]Training Epoch 8, LR 0.000214:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:04,  1.42batch/s]Training Epoch 8, LR 0.000214:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.63batch/s]Training Epoch 8, LR 0.000214:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:12<00:05,  1.00s/batch]Training Epoch 8, LR 0.000214:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.21batch/s]Training Epoch 8, LR 0.000214:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:13<00:02,  1.43batch/s]Training Epoch 8, LR 0.000214:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.64batch/s]Training Epoch 8, LR 0.000214:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:15<00:00,  1.03batch/s]Training Epoch 8, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.24batch/s]Training Epoch 8, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.10batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 8:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 8:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.52s/batch]Evaluating Epoch 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 8:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [8/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[78, 12],
        [40, 14]], device='cuda:0')
train_accuracy=0.6388888955116272, 
train_recall=0.25925925374031067, 
train_precision=0.5384615659713745, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.5629629492759705,
 train_f1_score=0.3499999940395355,
 train_auc=0.634156346321106

Epoch [8/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[15,  4],
        [11,  2]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.1538461595773697, 
eval_precision=0.3333333432674408, 
eval_specificity=0.7894737124443054, 
eval_balance_acc=0.47165992856025696,
 eval_f1_score=0.21052631735801697,
 eval_auc=0.5708502531051636


Epoch: 9/200
Training Epoch 9, LR 0.000105:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 9, LR 0.000105:   6%|â–Œ         | 1/18 [00:03<01:02,  3.68s/batch]Training Epoch 9, LR 0.000105:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.76s/batch]Training Epoch 9, LR 0.000105:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.14s/batch]Training Epoch 9, LR 0.000105:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.18batch/s]Training Epoch 9, LR 0.000105:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.28s/batch]Training Epoch 9, LR 0.000105:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 9, LR 0.000105:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 9, LR 0.000105:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 9, LR 0.000105:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 9, LR 0.000105:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 9, LR 0.000105:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.37batch/s]Training Epoch 9, LR 0.000105:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 9, LR 0.000105:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.10s/batch]Training Epoch 9, LR 0.000105:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.13batch/s]Training Epoch 9, LR 0.000105:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 9, LR 0.000105:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.56batch/s]Training Epoch 9, LR 0.000105:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 9, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 9, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 9:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 9:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.51s/batch]Evaluating Epoch 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 9:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.65batch/s]Evaluating Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [9/200]:, train_loss=0.061, 
train_confusionMatrix:
tensor([[83,  7],
        [36, 18]], device='cuda:0')
train_accuracy=0.7013888955116272, 
train_recall=0.3333333432674408, 
train_precision=0.7200000286102295, 
train_specificity=0.9222221970558167, 
train_balance_acc=0.6277777552604675,
 train_f1_score=0.4556961953639984,
 train_auc=0.6790123581886292

Epoch [9/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[17,  3],
        [10,  2]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.1666666716337204, 
eval_precision=0.4000000059604645, 
eval_specificity=0.8500000238418579, 
eval_balance_acc=0.5083333253860474,
 eval_f1_score=0.23529411852359772,
 eval_auc=0.5291666984558105


Epoch: 10/200
Training Epoch 10, LR 0.000034:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 10, LR 0.000034:   6%|â–Œ         | 1/18 [00:04<01:10,  4.14s/batch]Training Epoch 10, LR 0.000034:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.94s/batch]Training Epoch 10, LR 0.000034:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.24s/batch]Training Epoch 10, LR 0.000034:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 10, LR 0.000034:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.25s/batch]Training Epoch 10, LR 0.000034:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.04batch/s]Training Epoch 10, LR 0.000034:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.28batch/s]Training Epoch 10, LR 0.000034:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 10, LR 0.000034:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.02s/batch]Training Epoch 10, LR 0.000034:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.20batch/s]Training Epoch 10, LR 0.000034:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:04,  1.43batch/s]Training Epoch 10, LR 0.000034:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.63batch/s]Training Epoch 10, LR 0.000034:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.02batch/s]Training Epoch 10, LR 0.000034:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.24batch/s]Training Epoch 10, LR 0.000034:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.46batch/s]Training Epoch 10, LR 0.000034:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.66batch/s]Training Epoch 10, LR 0.000034:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 10, LR 0.000034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.23batch/s]Training Epoch 10, LR 0.000034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.07batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 10:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 10:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.53s/batch]Evaluating Epoch 10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [10/200]:, train_loss=0.061, 
train_confusionMatrix:
tensor([[78, 11],
        [36, 19]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.34545454382896423, 
train_precision=0.6333333253860474, 
train_specificity=0.8764045238494873, 
train_balance_acc=0.610929548740387,
 train_f1_score=0.4470588266849518,
 train_auc=0.7084780335426331

Epoch [10/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[16,  3],
        [11,  2]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.1538461595773697, 
eval_precision=0.4000000059604645, 
eval_specificity=0.8421052694320679, 
eval_balance_acc=0.4979757070541382,
 eval_f1_score=0.2222222238779068,
 eval_auc=0.5506073236465454


Epoch: 11/200
Training Epoch 11, LR 0.001000:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 11, LR 0.001000:   6%|â–Œ         | 1/18 [00:03<01:06,  3.89s/batch]Training Epoch 11, LR 0.001000:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 11, LR 0.001000:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 11, LR 0.001000:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 11, LR 0.001000:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.27s/batch]Training Epoch 11, LR 0.001000:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 11, LR 0.001000:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 11, LR 0.001000:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 11, LR 0.001000:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.06s/batch]Training Epoch 11, LR 0.001000:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.16batch/s]Training Epoch 11, LR 0.001000:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.38batch/s]Training Epoch 11, LR 0.001000:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 11, LR 0.001000:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.01batch/s]Training Epoch 11, LR 0.001000:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.22batch/s]Training Epoch 11, LR 0.001000:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.44batch/s]Training Epoch 11, LR 0.001000:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.65batch/s]Training Epoch 11, LR 0.001000:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.09batch/s]Training Epoch 11, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.31batch/s]Training Epoch 11, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.08batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 11:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 11:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.44s/batch]Evaluating Epoch 11:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.50s/batch]Evaluating Epoch 11:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.67batch/s]Evaluating Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [11/200]:, train_loss=0.064, 
train_confusionMatrix:
tensor([[75, 15],
        [43, 11]], device='cuda:0')
train_accuracy=0.5972222089767456, 
train_recall=0.20370370149612427, 
train_precision=0.42307692766189575, 
train_specificity=0.8333333134651184, 
train_balance_acc=0.5185185074806213,
 train_f1_score=0.2750000059604645,
 train_auc=0.5899176597595215

Epoch [11/200]:, eval_loss=0.019, 
eval_confusionMatrix:
tensor([[ 0, 18],
        [ 0, 14]], device='cuda:0')
eval_accuracy=0.4375, 
eval_recall=1.0, 
eval_precision=0.4375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.6086956262588501,
 eval_auc=0.5019841194152832


Epoch: 12/200
Training Epoch 12, LR 0.000997:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 12, LR 0.000997:   6%|â–Œ         | 1/18 [00:03<01:03,  3.75s/batch]Training Epoch 12, LR 0.000997:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 12, LR 0.000997:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 12, LR 0.000997:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 12, LR 0.000997:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.28s/batch]Training Epoch 12, LR 0.000997:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 12, LR 0.000997:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 12, LR 0.000997:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 12, LR 0.000997:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.11s/batch]Training Epoch 12, LR 0.000997:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 12, LR 0.000997:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 12, LR 0.000997:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 12, LR 0.000997:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 12, LR 0.000997:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.20batch/s]Training Epoch 12, LR 0.000997:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.42batch/s]Training Epoch 12, LR 0.000997:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.63batch/s]Training Epoch 12, LR 0.000997:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 12, LR 0.000997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.21batch/s]Training Epoch 12, LR 0.000997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 12:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 12:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.65s/batch]Evaluating Epoch 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.59s/batch]Evaluating Epoch 12:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [12/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[80, 10],
        [41, 13]], device='cuda:0')
train_accuracy=0.6458333134651184, 
train_recall=0.24074074625968933, 
train_precision=0.5652173757553101, 
train_specificity=0.8888888955116272, 
train_balance_acc=0.5648148059844971,
 train_f1_score=0.33766233921051025,
 train_auc=0.6043209433555603

Epoch [12/200]:, eval_loss=0.021, 
eval_confusionMatrix:
tensor([[ 0, 21],
        [ 0, 11]], device='cuda:0')
eval_accuracy=0.34375, 
eval_recall=1.0, 
eval_precision=0.34375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5116279125213623,
 eval_auc=0.5324675440788269


Epoch: 13/200
Training Epoch 13, LR 0.000989:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 13, LR 0.000989:   6%|â–Œ         | 1/18 [00:03<01:07,  3.97s/batch]Training Epoch 13, LR 0.000989:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 13, LR 0.000989:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 13, LR 0.000989:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 13, LR 0.000989:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.25s/batch]Training Epoch 13, LR 0.000989:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.04batch/s]Training Epoch 13, LR 0.000989:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.28batch/s]Training Epoch 13, LR 0.000989:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 13, LR 0.000989:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.04s/batch]Training Epoch 13, LR 0.000989:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 13, LR 0.000989:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:04,  1.40batch/s]Training Epoch 13, LR 0.000989:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.61batch/s]Training Epoch 13, LR 0.000989:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 13, LR 0.000989:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.20batch/s]Training Epoch 13, LR 0.000989:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 13, LR 0.000989:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 13, LR 0.000989:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 13, LR 0.000989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.22batch/s]Training Epoch 13, LR 0.000989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 13:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 13:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.65s/batch]Evaluating Epoch 13:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.59s/batch]Evaluating Epoch 13:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [13/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[78, 12],
        [43, 11]], device='cuda:0')
train_accuracy=0.6180555820465088, 
train_recall=0.20370370149612427, 
train_precision=0.47826087474823, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.5351852178573608,
 train_f1_score=0.2857142984867096,
 train_auc=0.5820987820625305

Epoch [13/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.5666666626930237


Epoch: 14/200
Training Epoch 14, LR 0.000976:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 14, LR 0.000976:   6%|â–Œ         | 1/18 [00:03<01:03,  3.76s/batch]Training Epoch 14, LR 0.000976:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 14, LR 0.000976:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 14, LR 0.000976:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 14, LR 0.000976:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.27s/batch]Training Epoch 14, LR 0.000976:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 14, LR 0.000976:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 14, LR 0.000976:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 14, LR 0.000976:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.06s/batch]Training Epoch 14, LR 0.000976:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.16batch/s]Training Epoch 14, LR 0.000976:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.38batch/s]Training Epoch 14, LR 0.000976:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 14, LR 0.000976:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 14, LR 0.000976:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.19batch/s]Training Epoch 14, LR 0.000976:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 14, LR 0.000976:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 14, LR 0.000976:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.00s/batch]Training Epoch 14, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.22batch/s]Training Epoch 14, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 14:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 14:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.67s/batch]Evaluating Epoch 14:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.60s/batch]Evaluating Epoch 14:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.59batch/s]Evaluating Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [14/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[78, 12],
        [41, 13]], device='cuda:0')
train_accuracy=0.6319444179534912, 
train_recall=0.24074074625968933, 
train_precision=0.5199999809265137, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.5537037253379822,
 train_f1_score=0.3291139304637909,
 train_auc=0.6699588298797607

Epoch [14/200]:, eval_loss=0.020, 
eval_confusionMatrix:
tensor([[ 0, 20],
        [ 0, 12]], device='cuda:0')
eval_accuracy=0.375, 
eval_recall=1.0, 
eval_precision=0.375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5454545617103577,
 eval_auc=0.5625


Epoch: 15/200
Training Epoch 15, LR 0.000957:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 15, LR 0.000957:   6%|â–Œ         | 1/18 [00:03<01:03,  3.75s/batch]Training Epoch 15, LR 0.000957:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 15, LR 0.000957:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 15, LR 0.000957:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.17batch/s]Training Epoch 15, LR 0.000957:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.24s/batch]Training Epoch 15, LR 0.000957:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.05batch/s]Training Epoch 15, LR 0.000957:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.29batch/s]Training Epoch 15, LR 0.000957:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.52batch/s]Training Epoch 15, LR 0.000957:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 15, LR 0.000957:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 15, LR 0.000957:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.37batch/s]Training Epoch 15, LR 0.000957:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 15, LR 0.000957:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 15, LR 0.000957:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.15batch/s]Training Epoch 15, LR 0.000957:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 15, LR 0.000957:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 15, LR 0.000957:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 15, LR 0.000957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.23batch/s]Training Epoch 15, LR 0.000957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.07batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 15:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 15:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.57s/batch]Evaluating Epoch 15:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 15:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [15/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[73, 16],
        [35, 20]], device='cuda:0')
train_accuracy=0.6458333134651184, 
train_recall=0.3636363744735718, 
train_precision=0.5555555820465088, 
train_specificity=0.8202247023582458, 
train_balance_acc=0.5919305086135864,
 train_f1_score=0.4395604431629181,
 train_auc=0.6496424674987793

Epoch [15/200]:, eval_loss=0.020, 
eval_confusionMatrix:
tensor([[ 0, 20],
        [ 0, 12]], device='cuda:0')
eval_accuracy=0.375, 
eval_recall=1.0, 
eval_precision=0.375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5454545617103577,
 eval_auc=0.5583333969116211


Epoch: 16/200
Training Epoch 16, LR 0.000934:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 16, LR 0.000934:   6%|â–Œ         | 1/18 [00:03<01:05,  3.85s/batch]Training Epoch 16, LR 0.000934:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 16, LR 0.000934:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 16, LR 0.000934:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 16, LR 0.000934:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.28s/batch]Training Epoch 16, LR 0.000934:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 16, LR 0.000934:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 16, LR 0.000934:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 16, LR 0.000934:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 16, LR 0.000934:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 16, LR 0.000934:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.38batch/s]Training Epoch 16, LR 0.000934:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 16, LR 0.000934:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 16, LR 0.000934:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.17batch/s]Training Epoch 16, LR 0.000934:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 16, LR 0.000934:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 16, LR 0.000934:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.00s/batch]Training Epoch 16, LR 0.000934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 16, LR 0.000934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 16:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 16:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.65s/batch]Evaluating Epoch 16:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.60s/batch]Evaluating Epoch 16:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.59batch/s]Evaluating Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [16/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[79, 11],
        [38, 16]], device='cuda:0')
train_accuracy=0.6597222089767456, 
train_recall=0.29629629850387573, 
train_precision=0.5925925970077515, 
train_specificity=0.8777777552604675, 
train_balance_acc=0.5870370268821716,
 train_f1_score=0.395061731338501,
 train_auc=0.650617241859436

Epoch [16/200]:, eval_loss=0.013, 
eval_confusionMatrix:
tensor([[19,  1],
        [ 8,  4]], device='cuda:0')
eval_accuracy=0.71875, 
eval_recall=0.3333333432674408, 
eval_precision=0.800000011920929, 
eval_specificity=0.949999988079071, 
eval_balance_acc=0.6416666507720947,
 eval_f1_score=0.47058823704719543,
 eval_auc=0.6166666746139526


Best model saved to ././checkpoints_2025-04-07_21-44/AweSomeNet_best_model_fold2.pth


Epoch: 17/200
Training Epoch 17, LR 0.000905:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 17, LR 0.000905:   6%|â–Œ         | 1/18 [00:04<01:10,  4.13s/batch]Training Epoch 17, LR 0.000905:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.94s/batch]Training Epoch 17, LR 0.000905:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.24s/batch]Training Epoch 17, LR 0.000905:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 17, LR 0.000905:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.31s/batch]Training Epoch 17, LR 0.000905:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 17, LR 0.000905:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.24batch/s]Training Epoch 17, LR 0.000905:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 17, LR 0.000905:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.04s/batch]Training Epoch 17, LR 0.000905:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 17, LR 0.000905:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:04,  1.41batch/s]Training Epoch 17, LR 0.000905:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.62batch/s]Training Epoch 17, LR 0.000905:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 17, LR 0.000905:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 17, LR 0.000905:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 17, LR 0.000905:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 17, LR 0.000905:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 17, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 17, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 17:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 17:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.44s/batch]Evaluating Epoch 17:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.51s/batch]Evaluating Epoch 17:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.67batch/s]Evaluating Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [17/200]:, train_loss=0.064, 
train_confusionMatrix:
tensor([[77, 13],
        [38, 16]], device='cuda:0')
train_accuracy=0.6458333134651184, 
train_recall=0.29629629850387573, 
train_precision=0.5517241358757019, 
train_specificity=0.855555534362793, 
train_balance_acc=0.5759259462356567,
 train_f1_score=0.3855421543121338,
 train_auc=0.6051440238952637

Epoch [17/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[21,  0],
        [11,  0]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.6103895902633667


Epoch: 18/200
Training Epoch 18, LR 0.000873:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 18, LR 0.000873:   6%|â–Œ         | 1/18 [00:03<01:02,  3.69s/batch]Training Epoch 18, LR 0.000873:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.76s/batch]Training Epoch 18, LR 0.000873:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.14s/batch]Training Epoch 18, LR 0.000873:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.17batch/s]Training Epoch 18, LR 0.000873:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.23s/batch]Training Epoch 18, LR 0.000873:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.05batch/s]Training Epoch 18, LR 0.000873:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.29batch/s]Training Epoch 18, LR 0.000873:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.52batch/s]Training Epoch 18, LR 0.000873:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.06s/batch]Training Epoch 18, LR 0.000873:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.16batch/s]Training Epoch 18, LR 0.000873:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.38batch/s]Training Epoch 18, LR 0.000873:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 18, LR 0.000873:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 18, LR 0.000873:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 18, LR 0.000873:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 18, LR 0.000873:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.61batch/s]Training Epoch 18, LR 0.000873:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 18, LR 0.000873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.24batch/s]Training Epoch 18, LR 0.000873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.08batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 18:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 18:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.57s/batch]Evaluating Epoch 18:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 18:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [18/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[75, 15],
        [36, 18]], device='cuda:0')
train_accuracy=0.6458333134651184, 
train_recall=0.3333333432674408, 
train_precision=0.5454545617103577, 
train_specificity=0.8333333134651184, 
train_balance_acc=0.5833333134651184,
 train_f1_score=0.4137931168079376,
 train_auc=0.6576131582260132

Epoch [18/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[21,  0],
        [11,  0]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.5800865888595581


Epoch: 19/200
Training Epoch 19, LR 0.000836:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 19, LR 0.000836:   6%|â–Œ         | 1/18 [00:03<01:02,  3.70s/batch]Training Epoch 19, LR 0.000836:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.76s/batch]Training Epoch 19, LR 0.000836:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.14s/batch]Training Epoch 19, LR 0.000836:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.17batch/s]Training Epoch 19, LR 0.000836:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.38s/batch]Training Epoch 19, LR 0.000836:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 19, LR 0.000836:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.19batch/s]Training Epoch 19, LR 0.000836:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.42batch/s]Training Epoch 19, LR 0.000836:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 19, LR 0.000836:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 19, LR 0.000836:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 19, LR 0.000836:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 19, LR 0.000836:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.01batch/s]Training Epoch 19, LR 0.000836:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.23batch/s]Training Epoch 19, LR 0.000836:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.45batch/s]Training Epoch 19, LR 0.000836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.65batch/s]Training Epoch 19, LR 0.000836:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.07batch/s]Training Epoch 19, LR 0.000836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.28batch/s]Training Epoch 19, LR 0.000836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.07batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 19:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 19:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.61s/batch]Evaluating Epoch 19:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 19:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [19/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[72, 17],
        [39, 16]], device='cuda:0')
train_accuracy=0.6111111044883728, 
train_recall=0.290909081697464, 
train_precision=0.4848484992980957, 
train_specificity=0.8089887499809265, 
train_balance_acc=0.5499489307403564,
 train_f1_score=0.3636363744735718,
 train_auc=0.6024514436721802

Epoch [19/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.6791666746139526


Epoch: 20/200
Training Epoch 20, LR 0.000796:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 20, LR 0.000796:   6%|â–Œ         | 1/18 [00:04<01:11,  4.19s/batch]Training Epoch 20, LR 0.000796:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.97s/batch]Training Epoch 20, LR 0.000796:  17%|â–ˆâ–‹        | 3/18 [00:05<00:18,  1.25s/batch]Training Epoch 20, LR 0.000796:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.09batch/s]Training Epoch 20, LR 0.000796:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 20, LR 0.000796:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 20, LR 0.000796:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 20, LR 0.000796:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 20, LR 0.000796:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 20, LR 0.000796:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.14batch/s]Training Epoch 20, LR 0.000796:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 20, LR 0.000796:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 20, LR 0.000796:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 20, LR 0.000796:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.18batch/s]Training Epoch 20, LR 0.000796:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 20, LR 0.000796:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.61batch/s]Training Epoch 20, LR 0.000796:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.03s/batch]Training Epoch 20, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 20, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 20:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 20:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 20:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 20:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [20/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[76, 14],
        [37, 17]], device='cuda:0')
train_accuracy=0.6458333134651184, 
train_recall=0.31481480598449707, 
train_precision=0.5483871102333069, 
train_specificity=0.8444444537162781, 
train_balance_acc=0.57962965965271,
 train_f1_score=0.4000000059604645,
 train_auc=0.6641975045204163

Epoch [20/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.6666666269302368


Epoch: 21/200
Training Epoch 21, LR 0.000753:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 21, LR 0.000753:   6%|â–Œ         | 1/18 [00:03<01:04,  3.82s/batch]Training Epoch 21, LR 0.000753:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.81s/batch]Training Epoch 21, LR 0.000753:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 21, LR 0.000753:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 21, LR 0.000753:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.27s/batch]Training Epoch 21, LR 0.000753:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 21, LR 0.000753:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 21, LR 0.000753:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 21, LR 0.000753:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 21, LR 0.000753:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.11batch/s]Training Epoch 21, LR 0.000753:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 21, LR 0.000753:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 21, LR 0.000753:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 21, LR 0.000753:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.16batch/s]Training Epoch 21, LR 0.000753:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 21, LR 0.000753:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 21, LR 0.000753:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 21, LR 0.000753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 21, LR 0.000753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 21:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 21:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.58s/batch]Evaluating Epoch 21:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 21:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [21/200]:, train_loss=0.061, 
train_confusionMatrix:
tensor([[73, 16],
        [36, 19]], device='cuda:0')
train_accuracy=0.6388888955116272, 
train_recall=0.34545454382896423, 
train_precision=0.5428571701049805, 
train_specificity=0.8202247023582458, 
train_balance_acc=0.5828396081924438,
 train_f1_score=0.42222222685813904,
 train_auc=0.6710929870605469

Epoch [21/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.637499988079071


Epoch: 22/200
Training Epoch 22, LR 0.000706:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 22, LR 0.000706:   6%|â–Œ         | 1/18 [00:03<01:05,  3.84s/batch]Training Epoch 22, LR 0.000706:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 22, LR 0.000706:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 22, LR 0.000706:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 22, LR 0.000706:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:15,  1.22s/batch]Training Epoch 22, LR 0.000706:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.06batch/s]Training Epoch 22, LR 0.000706:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.30batch/s]Training Epoch 22, LR 0.000706:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.53batch/s]Training Epoch 22, LR 0.000706:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 22, LR 0.000706:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 22, LR 0.000706:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.36batch/s]Training Epoch 22, LR 0.000706:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 22, LR 0.000706:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 22, LR 0.000706:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.19batch/s]Training Epoch 22, LR 0.000706:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 22, LR 0.000706:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 22, LR 0.000706:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.00s/batch]Training Epoch 22, LR 0.000706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.21batch/s]Training Epoch 22, LR 0.000706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 22:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 22:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.52s/batch]Evaluating Epoch 22:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 22:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.63batch/s]Evaluating Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [22/200]:, train_loss=0.061, 
train_confusionMatrix:
tensor([[72, 18],
        [33, 21]], device='cuda:0')
train_accuracy=0.6458333134651184, 
train_recall=0.3888888955116272, 
train_precision=0.5384615659713745, 
train_specificity=0.800000011920929, 
train_balance_acc=0.5944444537162781,
 train_f1_score=0.4516128897666931,
 train_auc=0.6711934208869934

Epoch [22/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[13,  7],
        [ 7,  5]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.4166666567325592, 
eval_precision=0.4166666567325592, 
eval_specificity=0.6499999761581421, 
eval_balance_acc=0.5333333015441895,
 eval_f1_score=0.4166666567325592,
 eval_auc=0.5333333611488342


Epoch: 23/200
Training Epoch 23, LR 0.000658:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 23, LR 0.000658:   6%|â–Œ         | 1/18 [00:03<01:02,  3.68s/batch]Training Epoch 23, LR 0.000658:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.76s/batch]Training Epoch 23, LR 0.000658:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.14s/batch]Training Epoch 23, LR 0.000658:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.17batch/s]Training Epoch 23, LR 0.000658:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:15,  1.20s/batch]Training Epoch 23, LR 0.000658:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.07batch/s]Training Epoch 23, LR 0.000658:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.31batch/s]Training Epoch 23, LR 0.000658:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:07<00:06,  1.54batch/s]Training Epoch 23, LR 0.000658:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.11s/batch]Training Epoch 23, LR 0.000658:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 23, LR 0.000658:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.35batch/s]Training Epoch 23, LR 0.000658:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 23, LR 0.000658:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 23, LR 0.000658:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.17batch/s]Training Epoch 23, LR 0.000658:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 23, LR 0.000658:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 23, LR 0.000658:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 23, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.18batch/s]Training Epoch 23, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 23:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 23:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.65s/batch]Evaluating Epoch 23:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.59s/batch]Evaluating Epoch 23:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [23/200]:, train_loss=0.064, 
train_confusionMatrix:
tensor([[74, 15],
        [39, 16]], device='cuda:0')
train_accuracy=0.625, 
train_recall=0.290909081697464, 
train_precision=0.5161290168762207, 
train_specificity=0.8314606547355652, 
train_balance_acc=0.5611848831176758,
 train_f1_score=0.3720930218696594,
 train_auc=0.6312563419342041

Epoch [23/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[18,  3],
        [11,  0]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.8571428656578064, 
eval_balance_acc=0.4285714328289032,
 eval_f1_score=0.0,
 eval_auc=0.523809552192688


Epoch: 24/200
Training Epoch 24, LR 0.000608:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 24, LR 0.000608:   6%|â–Œ         | 1/18 [00:03<01:05,  3.84s/batch]Training Epoch 24, LR 0.000608:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 24, LR 0.000608:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 24, LR 0.000608:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 24, LR 0.000608:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 24, LR 0.000608:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.00batch/s]Training Epoch 24, LR 0.000608:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 24, LR 0.000608:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 24, LR 0.000608:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 24, LR 0.000608:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.11batch/s]Training Epoch 24, LR 0.000608:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 24, LR 0.000608:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 24, LR 0.000608:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.10s/batch]Training Epoch 24, LR 0.000608:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.12batch/s]Training Epoch 24, LR 0.000608:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.34batch/s]Training Epoch 24, LR 0.000608:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.55batch/s]Training Epoch 24, LR 0.000608:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.05s/batch]Training Epoch 24, LR 0.000608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 24, LR 0.000608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 24:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 24:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 24:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 24:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [24/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[78, 11],
        [34, 21]], device='cuda:0')
train_accuracy=0.6875, 
train_recall=0.38181817531585693, 
train_precision=0.65625, 
train_specificity=0.8764045238494873, 
train_balance_acc=0.6291113495826721,
 train_f1_score=0.48275861144065857,
 train_auc=0.6984677910804749

Epoch [24/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[19,  2],
        [11,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.9047619104385376, 
eval_balance_acc=0.4523809552192688,
 eval_f1_score=0.0,
 eval_auc=0.5541125535964966


Epoch: 25/200
Training Epoch 25, LR 0.000557:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 25, LR 0.000557:   6%|â–Œ         | 1/18 [00:03<01:04,  3.79s/batch]Training Epoch 25, LR 0.000557:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 25, LR 0.000557:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 25, LR 0.000557:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.16batch/s]Training Epoch 25, LR 0.000557:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.25s/batch]Training Epoch 25, LR 0.000557:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 25, LR 0.000557:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 25, LR 0.000557:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 25, LR 0.000557:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 25, LR 0.000557:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.16batch/s]Training Epoch 25, LR 0.000557:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.38batch/s]Training Epoch 25, LR 0.000557:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 25, LR 0.000557:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 25, LR 0.000557:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.15batch/s]Training Epoch 25, LR 0.000557:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 25, LR 0.000557:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 25, LR 0.000557:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 25, LR 0.000557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 25, LR 0.000557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 25:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 25:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.56s/batch]Evaluating Epoch 25:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 25:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [25/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[81,  8],
        [35, 20]], device='cuda:0')
train_accuracy=0.7013888955116272, 
train_recall=0.3636363744735718, 
train_precision=0.7142857313156128, 
train_specificity=0.9101123809814453, 
train_balance_acc=0.6368743777275085,
 train_f1_score=0.4819277226924896,
 train_auc=0.7491317987442017

Epoch [25/200]:, eval_loss=0.020, 
eval_confusionMatrix:
tensor([[ 0, 19],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=1.0, 
eval_precision=0.40625, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5777778029441833,
 eval_auc=0.5748987793922424


Epoch: 26/200
Training Epoch 26, LR 0.000505:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 26, LR 0.000505:   6%|â–Œ         | 1/18 [00:03<01:05,  3.85s/batch]Training Epoch 26, LR 0.000505:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 26, LR 0.000505:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 26, LR 0.000505:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 26, LR 0.000505:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.25s/batch]Training Epoch 26, LR 0.000505:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 26, LR 0.000505:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.28batch/s]Training Epoch 26, LR 0.000505:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 26, LR 0.000505:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 26, LR 0.000505:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 26, LR 0.000505:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.37batch/s]Training Epoch 26, LR 0.000505:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 26, LR 0.000505:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 26, LR 0.000505:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 26, LR 0.000505:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 26, LR 0.000505:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 26, LR 0.000505:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.04batch/s]Training Epoch 26, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.26batch/s]Training Epoch 26, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.07batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 26:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 26:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.47s/batch]Evaluating Epoch 26:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.52s/batch]Evaluating Epoch 26:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.66batch/s]Evaluating Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [26/200]:, train_loss=0.061, 
train_confusionMatrix:
tensor([[76, 13],
        [32, 23]], device='cuda:0')
train_accuracy=0.6875, 
train_recall=0.41818180680274963, 
train_precision=0.6388888955116272, 
train_specificity=0.8539325594902039, 
train_balance_acc=0.6360571980476379,
 train_f1_score=0.5054945349693298,
 train_auc=0.7005107402801514

Epoch [26/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 6, 13],
        [ 3, 10]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.7692307829856873, 
eval_precision=0.43478259444236755, 
eval_specificity=0.31578946113586426, 
eval_balance_acc=0.5425101518630981,
 eval_f1_score=0.5555555820465088,
 eval_auc=0.5263158082962036


Epoch: 27/200
Training Epoch 27, LR 0.000453:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 27, LR 0.000453:   6%|â–Œ         | 1/18 [00:03<01:04,  3.80s/batch]Training Epoch 27, LR 0.000453:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 27, LR 0.000453:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 27, LR 0.000453:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.16batch/s]Training Epoch 27, LR 0.000453:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:15,  1.23s/batch]Training Epoch 27, LR 0.000453:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.05batch/s]Training Epoch 27, LR 0.000453:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.29batch/s]Training Epoch 27, LR 0.000453:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.52batch/s]Training Epoch 27, LR 0.000453:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:09<00:09,  1.04s/batch]Training Epoch 27, LR 0.000453:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 27, LR 0.000453:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:04,  1.41batch/s]Training Epoch 27, LR 0.000453:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.62batch/s]Training Epoch 27, LR 0.000453:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.00s/batch]Training Epoch 27, LR 0.000453:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.21batch/s]Training Epoch 27, LR 0.000453:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:13<00:02,  1.44batch/s]Training Epoch 27, LR 0.000453:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.64batch/s]Training Epoch 27, LR 0.000453:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 27, LR 0.000453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.23batch/s]Training Epoch 27, LR 0.000453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.08batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 27:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 27:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.49s/batch]Evaluating Epoch 27:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 27:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.65batch/s]Evaluating Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [27/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[73, 16],
        [34, 21]], device='cuda:0')
train_accuracy=0.6527777910232544, 
train_recall=0.38181817531585693, 
train_precision=0.5675675868988037, 
train_specificity=0.8202247023582458, 
train_balance_acc=0.601021409034729,
 train_f1_score=0.45652174949645996,
 train_auc=0.680898904800415

Epoch [27/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[17,  2],
        [13,  0]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.8947368264198303, 
eval_balance_acc=0.44736841320991516,
 eval_f1_score=0.0,
 eval_auc=0.49392715096473694


Epoch: 28/200
Training Epoch 28, LR 0.000402:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 28, LR 0.000402:   6%|â–Œ         | 1/18 [00:03<01:05,  3.83s/batch]Training Epoch 28, LR 0.000402:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 28, LR 0.000402:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 28, LR 0.000402:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 28, LR 0.000402:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 28, LR 0.000402:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 28, LR 0.000402:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 28, LR 0.000402:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 28, LR 0.000402:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 28, LR 0.000402:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 28, LR 0.000402:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 28, LR 0.000402:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 28, LR 0.000402:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 28, LR 0.000402:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.17batch/s]Training Epoch 28, LR 0.000402:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 28, LR 0.000402:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 28, LR 0.000402:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 28, LR 0.000402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 28, LR 0.000402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 28:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 28:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.49s/batch]Evaluating Epoch 28:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 28:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.65batch/s]Evaluating Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [28/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[74, 15],
        [32, 23]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.41818180680274963, 
train_precision=0.6052631735801697, 
train_specificity=0.8314606547355652, 
train_balance_acc=0.6248212456703186,
 train_f1_score=0.49462366104125977,
 train_auc=0.7158324718475342

Epoch [28/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[18,  1],
        [13,  0]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.9473684430122375, 
eval_balance_acc=0.4736842215061188,
 eval_f1_score=0.0,
 eval_auc=0.52226722240448


Epoch: 29/200
Training Epoch 29, LR 0.000352:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 29, LR 0.000352:   6%|â–Œ         | 1/18 [00:03<01:07,  3.95s/batch]Training Epoch 29, LR 0.000352:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 29, LR 0.000352:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.20s/batch]Training Epoch 29, LR 0.000352:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 29, LR 0.000352:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.26s/batch]Training Epoch 29, LR 0.000352:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 29, LR 0.000352:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 29, LR 0.000352:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 29, LR 0.000352:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.04s/batch]Training Epoch 29, LR 0.000352:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 29, LR 0.000352:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:04,  1.40batch/s]Training Epoch 29, LR 0.000352:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.62batch/s]Training Epoch 29, LR 0.000352:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 29, LR 0.000352:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.19batch/s]Training Epoch 29, LR 0.000352:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 29, LR 0.000352:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.61batch/s]Training Epoch 29, LR 0.000352:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.05batch/s]Training Epoch 29, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.27batch/s]Training Epoch 29, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.07batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 29:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 29:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.41s/batch]Evaluating Epoch 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:02,  1.50s/batch]Evaluating Epoch 29:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.68batch/s]Evaluating Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [29/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[72, 17],
        [30, 25]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.4545454680919647, 
train_precision=0.5952380895614624, 
train_specificity=0.8089887499809265, 
train_balance_acc=0.6317670941352844,
 train_f1_score=0.5154638886451721,
 train_auc=0.7515832781791687

Epoch [29/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[18,  1],
        [13,  0]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.9473684430122375, 
eval_balance_acc=0.4736842215061188,
 eval_f1_score=0.0,
 eval_auc=0.46963563561439514


Epoch: 30/200
Training Epoch 30, LR 0.000304:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 30, LR 0.000304:   6%|â–Œ         | 1/18 [00:03<01:01,  3.64s/batch]Training Epoch 30, LR 0.000304:  11%|â–ˆ         | 2/18 [00:04<00:27,  1.75s/batch]Training Epoch 30, LR 0.000304:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.14s/batch]Training Epoch 30, LR 0.000304:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.18batch/s]Training Epoch 30, LR 0.000304:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:15,  1.19s/batch]Training Epoch 30, LR 0.000304:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.08batch/s]Training Epoch 30, LR 0.000304:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.33batch/s]Training Epoch 30, LR 0.000304:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:07<00:06,  1.55batch/s]Training Epoch 30, LR 0.000304:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:09<00:09,  1.07s/batch]Training Epoch 30, LR 0.000304:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 30, LR 0.000304:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.37batch/s]Training Epoch 30, LR 0.000304:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 30, LR 0.000304:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 30, LR 0.000304:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.19batch/s]Training Epoch 30, LR 0.000304:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:13<00:02,  1.41batch/s]Training Epoch 30, LR 0.000304:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 30, LR 0.000304:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 30, LR 0.000304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.24batch/s]Training Epoch 30, LR 0.000304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.09batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 30:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 30:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.51s/batch]Evaluating Epoch 30:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 30:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [30/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[70, 19],
        [24, 31]], device='cuda:0')
train_accuracy=0.7013888955116272, 
train_recall=0.5636363625526428, 
train_precision=0.6200000047683716, 
train_specificity=0.7865168452262878, 
train_balance_acc=0.6750766038894653,
 train_f1_score=0.5904762148857117,
 train_auc=0.6990807056427002

Epoch [30/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[17,  4],
        [ 6,  5]], device='cuda:0')
eval_accuracy=0.6875, 
eval_recall=0.4545454680919647, 
eval_precision=0.5555555820465088, 
eval_specificity=0.8095238208770752, 
eval_balance_acc=0.6320346593856812,
 eval_f1_score=0.5,
 eval_auc=0.5714285969734192


Epoch: 31/200
Training Epoch 31, LR 0.000258:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 31, LR 0.000258:   6%|â–Œ         | 1/18 [00:03<01:07,  3.96s/batch]Training Epoch 31, LR 0.000258:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 31, LR 0.000258:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.20s/batch]Training Epoch 31, LR 0.000258:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 31, LR 0.000258:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.31s/batch]Training Epoch 31, LR 0.000258:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 31, LR 0.000258:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.23batch/s]Training Epoch 31, LR 0.000258:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 31, LR 0.000258:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 31, LR 0.000258:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 31, LR 0.000258:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 31, LR 0.000258:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 31, LR 0.000258:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 31, LR 0.000258:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 31, LR 0.000258:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 31, LR 0.000258:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 31, LR 0.000258:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 31, LR 0.000258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 31, LR 0.000258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 31:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 31:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.46s/batch]Evaluating Epoch 31:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.51s/batch]Evaluating Epoch 31:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.66batch/s]Evaluating Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [31/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[73, 17],
        [28, 26]], device='cuda:0')
train_accuracy=0.6875, 
train_recall=0.48148149251937866, 
train_precision=0.604651153087616, 
train_specificity=0.8111110925674438, 
train_balance_acc=0.6462962627410889,
 train_f1_score=0.5360824465751648,
 train_auc=0.7255144119262695

Epoch [31/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[12,  7],
        [ 6,  7]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.5384615659713745, 
eval_precision=0.5, 
eval_specificity=0.6315789222717285, 
eval_balance_acc=0.5850202441215515,
 eval_f1_score=0.5185185074806213,
 eval_auc=0.5789474248886108


Epoch: 32/200
Training Epoch 32, LR 0.000214:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 32, LR 0.000214:   6%|â–Œ         | 1/18 [00:03<01:03,  3.71s/batch]Training Epoch 32, LR 0.000214:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.77s/batch]Training Epoch 32, LR 0.000214:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 32, LR 0.000214:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.17batch/s]Training Epoch 32, LR 0.000214:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.28s/batch]Training Epoch 32, LR 0.000214:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 32, LR 0.000214:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 32, LR 0.000214:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 32, LR 0.000214:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 32, LR 0.000214:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.11batch/s]Training Epoch 32, LR 0.000214:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 32, LR 0.000214:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 32, LR 0.000214:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 32, LR 0.000214:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.15batch/s]Training Epoch 32, LR 0.000214:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 32, LR 0.000214:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 32, LR 0.000214:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 32, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 32, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 32:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 32:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.40s/batch]Evaluating Epoch 32:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.50s/batch]Evaluating Epoch 32:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.68batch/s]Evaluating Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [32/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[71, 18],
        [27, 28]], device='cuda:0')
train_accuracy=0.6875, 
train_recall=0.5090909004211426, 
train_precision=0.6086956262588501, 
train_specificity=0.7977527976036072, 
train_balance_acc=0.6534218788146973,
 train_f1_score=0.5544554591178894,
 train_auc=0.7213482856750488

Epoch [32/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[19,  0],
        [12,  1]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.07692307978868484, 
eval_precision=1.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5384615659713745,
 eval_f1_score=0.1428571492433548,
 eval_auc=0.6518218517303467


Epoch: 33/200
Training Epoch 33, LR 0.000174:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 33, LR 0.000174:   6%|â–Œ         | 1/18 [00:03<01:03,  3.74s/batch]Training Epoch 33, LR 0.000174:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 33, LR 0.000174:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 33, LR 0.000174:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 33, LR 0.000174:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.25s/batch]Training Epoch 33, LR 0.000174:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 33, LR 0.000174:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 33, LR 0.000174:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 33, LR 0.000174:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 33, LR 0.000174:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 33, LR 0.000174:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 33, LR 0.000174:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 33, LR 0.000174:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 33, LR 0.000174:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.16batch/s]Training Epoch 33, LR 0.000174:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 33, LR 0.000174:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 33, LR 0.000174:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 33, LR 0.000174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.23batch/s]Training Epoch 33, LR 0.000174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 33:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 33:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.57s/batch]Evaluating Epoch 33:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 33:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [33/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[75, 15],
        [23, 31]], device='cuda:0')
train_accuracy=0.7361111044883728, 
train_recall=0.5740740895271301, 
train_precision=0.6739130616188049, 
train_specificity=0.8333333134651184, 
train_balance_acc=0.7037037014961243,
 train_f1_score=0.6200000047683716,
 train_auc=0.7518517971038818

Epoch [33/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[15,  4],
        [ 8,  5]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.38461539149284363, 
eval_precision=0.5555555820465088, 
eval_specificity=0.7894737124443054, 
eval_balance_acc=0.5870445370674133,
 eval_f1_score=0.4545454680919647,
 eval_auc=0.6315789222717285


Epoch: 34/200
Training Epoch 34, LR 0.000137:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 34, LR 0.000137:   6%|â–Œ         | 1/18 [00:03<01:02,  3.66s/batch]Training Epoch 34, LR 0.000137:  11%|â–ˆ         | 2/18 [00:04<00:27,  1.75s/batch]Training Epoch 34, LR 0.000137:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.13s/batch]Training Epoch 34, LR 0.000137:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.18batch/s]Training Epoch 34, LR 0.000137:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.27s/batch]Training Epoch 34, LR 0.000137:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 34, LR 0.000137:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 34, LR 0.000137:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 34, LR 0.000137:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 34, LR 0.000137:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 34, LR 0.000137:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.37batch/s]Training Epoch 34, LR 0.000137:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 34, LR 0.000137:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 34, LR 0.000137:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 34, LR 0.000137:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 34, LR 0.000137:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.61batch/s]Training Epoch 34, LR 0.000137:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 34, LR 0.000137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.18batch/s]Training Epoch 34, LR 0.000137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 34:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 34:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.41s/batch]Evaluating Epoch 34:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:02,  1.50s/batch]Evaluating Epoch 34:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.68batch/s]Evaluating Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [34/200]:, train_loss=0.054, 
train_confusionMatrix:
tensor([[78, 12],
        [20, 34]], device='cuda:0')
train_accuracy=0.7777777910232544, 
train_recall=0.6296296119689941, 
train_precision=0.739130437374115, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.7481481432914734,
 train_f1_score=0.6800000071525574,
 train_auc=0.7814815044403076

Epoch [34/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[19,  1],
        [11,  1]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0833333358168602, 
eval_precision=0.5, 
eval_specificity=0.949999988079071, 
eval_balance_acc=0.5166666507720947,
 eval_f1_score=0.1428571492433548,
 eval_auc=0.6541666984558105


Epoch: 35/200
Training Epoch 35, LR 0.000105:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 35, LR 0.000105:   6%|â–Œ         | 1/18 [00:03<01:02,  3.65s/batch]Training Epoch 35, LR 0.000105:  11%|â–ˆ         | 2/18 [00:04<00:27,  1.75s/batch]Training Epoch 35, LR 0.000105:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.14s/batch]Training Epoch 35, LR 0.000105:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.18batch/s]Training Epoch 35, LR 0.000105:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.26s/batch]Training Epoch 35, LR 0.000105:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 35, LR 0.000105:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 35, LR 0.000105:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 35, LR 0.000105:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 35, LR 0.000105:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 35, LR 0.000105:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.35batch/s]Training Epoch 35, LR 0.000105:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 35, LR 0.000105:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 35, LR 0.000105:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.17batch/s]Training Epoch 35, LR 0.000105:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 35, LR 0.000105:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 35, LR 0.000105:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.00batch/s]Training Epoch 35, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.17batch/s]Training Epoch 35, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 35:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 35:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.63s/batch]Evaluating Epoch 35:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 35:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [35/200]:, train_loss=0.054, 
train_confusionMatrix:
tensor([[81,  8],
        [24, 31]], device='cuda:0')
train_accuracy=0.7777777910232544, 
train_recall=0.5636363625526428, 
train_precision=0.7948718070983887, 
train_specificity=0.9101123809814453, 
train_balance_acc=0.7368743419647217,
 train_f1_score=0.6595744490623474,
 train_auc=0.7867211699485779

Epoch [35/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[17,  3],
        [12,  0]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.8500000238418579, 
eval_balance_acc=0.42500001192092896,
 eval_f1_score=0.0,
 eval_auc=0.5625


Epoch: 36/200
Training Epoch 36, LR 0.000076:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 36, LR 0.000076:   6%|â–Œ         | 1/18 [00:03<01:03,  3.74s/batch]Training Epoch 36, LR 0.000076:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 36, LR 0.000076:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 36, LR 0.000076:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.17batch/s]Training Epoch 36, LR 0.000076:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 36, LR 0.000076:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 36, LR 0.000076:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 36, LR 0.000076:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 36, LR 0.000076:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.06s/batch]Training Epoch 36, LR 0.000076:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.17batch/s]Training Epoch 36, LR 0.000076:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.39batch/s]Training Epoch 36, LR 0.000076:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 36, LR 0.000076:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 36, LR 0.000076:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 36, LR 0.000076:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 36, LR 0.000076:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.61batch/s]Training Epoch 36, LR 0.000076:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 36, LR 0.000076: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 36, LR 0.000076: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 36:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 36:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.61s/batch]Evaluating Epoch 36:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 36:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [36/200]:, train_loss=0.054, 
train_confusionMatrix:
tensor([[80, 10],
        [23, 31]], device='cuda:0')
train_accuracy=0.7708333134651184, 
train_recall=0.5740740895271301, 
train_precision=0.7560975551605225, 
train_specificity=0.8888888955116272, 
train_balance_acc=0.7314814925193787,
 train_f1_score=0.6526315808296204,
 train_auc=0.7950617671012878

Epoch [36/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[13,  7],
        [ 6,  6]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.5, 
eval_precision=0.4615384638309479, 
eval_specificity=0.6499999761581421, 
eval_balance_acc=0.574999988079071,
 eval_f1_score=0.47999998927116394,
 eval_auc=0.550000011920929


Epoch: 37/200
Training Epoch 37, LR 0.000053:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 37, LR 0.000053:   6%|â–Œ         | 1/18 [00:03<01:06,  3.93s/batch]Training Epoch 37, LR 0.000053:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.86s/batch]Training Epoch 37, LR 0.000053:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.20s/batch]Training Epoch 37, LR 0.000053:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 37, LR 0.000053:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.26s/batch]Training Epoch 37, LR 0.000053:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 37, LR 0.000053:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 37, LR 0.000053:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 37, LR 0.000053:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.06s/batch]Training Epoch 37, LR 0.000053:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.16batch/s]Training Epoch 37, LR 0.000053:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.38batch/s]Training Epoch 37, LR 0.000053:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 37, LR 0.000053:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.01s/batch]Training Epoch 37, LR 0.000053:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.19batch/s]Training Epoch 37, LR 0.000053:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 37, LR 0.000053:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 37, LR 0.000053:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.03batch/s]Training Epoch 37, LR 0.000053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 37, LR 0.000053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 37:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 37:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.58s/batch]Evaluating Epoch 37:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 37:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [37/200]:, train_loss=0.051, 
train_confusionMatrix:
tensor([[82,  7],
        [23, 32]], device='cuda:0')
train_accuracy=0.7916666865348816, 
train_recall=0.581818163394928, 
train_precision=0.8205128312110901, 
train_specificity=0.9213483333587646, 
train_balance_acc=0.7515832185745239,
 train_f1_score=0.6808510422706604,
 train_auc=0.8422880172729492

Epoch [37/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[14,  7],
        [ 7,  4]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.3636363744735718, 
eval_precision=0.3636363744735718, 
eval_specificity=0.6666666865348816, 
eval_balance_acc=0.5151515007019043,
 eval_f1_score=0.3636363744735718,
 eval_auc=0.5714285969734192


Epoch: 38/200
Training Epoch 38, LR 0.000034:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 38, LR 0.000034:   6%|â–Œ         | 1/18 [00:04<01:08,  4.04s/batch]Training Epoch 38, LR 0.000034:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.90s/batch]Training Epoch 38, LR 0.000034:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.22s/batch]Training Epoch 38, LR 0.000034:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 38, LR 0.000034:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 38, LR 0.000034:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 38, LR 0.000034:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.23batch/s]Training Epoch 38, LR 0.000034:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 38, LR 0.000034:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 38, LR 0.000034:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.10batch/s]Training Epoch 38, LR 0.000034:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 38, LR 0.000034:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 38, LR 0.000034:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 38, LR 0.000034:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.19batch/s]Training Epoch 38, LR 0.000034:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 38, LR 0.000034:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.60batch/s]Training Epoch 38, LR 0.000034:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 38, LR 0.000034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 38, LR 0.000034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 38:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 38:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.45s/batch]Evaluating Epoch 38:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.51s/batch]Evaluating Epoch 38:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.67batch/s]Evaluating Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [38/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[77, 12],
        [29, 26]], device='cuda:0')
train_accuracy=0.7152777910232544, 
train_recall=0.4727272689342499, 
train_precision=0.6842105388641357, 
train_specificity=0.8651685118675232, 
train_balance_acc=0.6689478754997253,
 train_f1_score=0.5591397881507874,
 train_auc=0.7640449404716492

Epoch [38/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[17,  4],
        [ 8,  3]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.27272728085517883, 
eval_precision=0.4285714328289032, 
eval_specificity=0.8095238208770752, 
eval_balance_acc=0.5411255359649658,
 eval_f1_score=0.3333333432674408,
 eval_auc=0.5194805264472961


Epoch: 39/200
Training Epoch 39, LR 0.000021:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 39, LR 0.000021:   6%|â–Œ         | 1/18 [00:03<01:04,  3.80s/batch]Training Epoch 39, LR 0.000021:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 39, LR 0.000021:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 39, LR 0.000021:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 39, LR 0.000021:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 39, LR 0.000021:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 39, LR 0.000021:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 39, LR 0.000021:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 39, LR 0.000021:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 39, LR 0.000021:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 39, LR 0.000021:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 39, LR 0.000021:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 39, LR 0.000021:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.11s/batch]Training Epoch 39, LR 0.000021:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 39, LR 0.000021:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.34batch/s]Training Epoch 39, LR 0.000021:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.55batch/s]Training Epoch 39, LR 0.000021:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 39, LR 0.000021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.23batch/s]Training Epoch 39, LR 0.000021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 39:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 39:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.56s/batch]Evaluating Epoch 39:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 39:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [39/200]:, train_loss=0.054, 
train_confusionMatrix:
tensor([[78, 11],
        [22, 33]], device='cuda:0')
train_accuracy=0.7708333134651184, 
train_recall=0.6000000238418579, 
train_precision=0.75, 
train_specificity=0.8764045238494873, 
train_balance_acc=0.7382022738456726,
 train_f1_score=0.6666666865348816,
 train_auc=0.8010214567184448

Epoch [39/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[14,  5],
        [ 9,  4]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.3076923191547394, 
eval_precision=0.4444444477558136, 
eval_specificity=0.7368420958518982, 
eval_balance_acc=0.52226722240448,
 eval_f1_score=0.3636363744735718,
 eval_auc=0.5263158082962036


Epoch: 40/200
Training Epoch 40, LR 0.000013:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 40, LR 0.000013:   6%|â–Œ         | 1/18 [00:03<01:05,  3.88s/batch]Training Epoch 40, LR 0.000013:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 40, LR 0.000013:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 40, LR 0.000013:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 40, LR 0.000013:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 40, LR 0.000013:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 40, LR 0.000013:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.23batch/s]Training Epoch 40, LR 0.000013:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 40, LR 0.000013:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 40, LR 0.000013:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.11batch/s]Training Epoch 40, LR 0.000013:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 40, LR 0.000013:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 40, LR 0.000013:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 40, LR 0.000013:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 40, LR 0.000013:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 40, LR 0.000013:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 40, LR 0.000013:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.03s/batch]Training Epoch 40, LR 0.000013: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 40, LR 0.000013: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 40:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 40:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.36s/batch]Evaluating Epoch 40:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:02,  1.47s/batch]Evaluating Epoch 40:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.15batch/s]Evaluating Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.71batch/s]Evaluating Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [40/200]:, train_loss=0.050, 
train_confusionMatrix:
tensor([[81,  9],
        [18, 36]], device='cuda:0')
train_accuracy=0.8125, 
train_recall=0.6666666865348816, 
train_precision=0.800000011920929, 
train_specificity=0.8999999761581421, 
train_balance_acc=0.7833333015441895,
 train_f1_score=0.7272727489471436,
 train_auc=0.8469135761260986

Epoch [40/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[16,  4],
        [ 9,  3]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.25, 
eval_precision=0.4285714328289032, 
eval_specificity=0.800000011920929, 
eval_balance_acc=0.5249999761581421,
 eval_f1_score=0.31578946113586426,
 eval_auc=0.5791666507720947


Epoch: 41/200
Training Epoch 41, LR 0.001000:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 41, LR 0.001000:   6%|â–Œ         | 1/18 [00:03<01:01,  3.63s/batch]Training Epoch 41, LR 0.001000:  11%|â–ˆ         | 2/18 [00:04<00:27,  1.74s/batch]Training Epoch 41, LR 0.001000:  17%|â–ˆâ–‹        | 3/18 [00:04<00:16,  1.13s/batch]Training Epoch 41, LR 0.001000:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.19batch/s]Training Epoch 41, LR 0.001000:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:15,  1.21s/batch]Training Epoch 41, LR 0.001000:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.07batch/s]Training Epoch 41, LR 0.001000:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.31batch/s]Training Epoch 41, LR 0.001000:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:07<00:06,  1.54batch/s]Training Epoch 41, LR 0.001000:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:09<00:09,  1.00s/batch]Training Epoch 41, LR 0.001000:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.22batch/s]Training Epoch 41, LR 0.001000:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:04,  1.44batch/s]Training Epoch 41, LR 0.001000:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:10<00:03,  1.65batch/s]Training Epoch 41, LR 0.001000:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:12<00:05,  1.02s/batch]Training Epoch 41, LR 0.001000:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.20batch/s]Training Epoch 41, LR 0.001000:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:13<00:02,  1.42batch/s]Training Epoch 41, LR 0.001000:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 41, LR 0.001000:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.00batch/s]Training Epoch 41, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.22batch/s]Training Epoch 41, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.09batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 41:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 41:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.55s/batch]Evaluating Epoch 41:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 41:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [41/200]:, train_loss=0.064, 
train_confusionMatrix:
tensor([[65, 24],
        [29, 26]], device='cuda:0')
train_accuracy=0.6319444179534912, 
train_recall=0.4727272689342499, 
train_precision=0.5199999809265137, 
train_specificity=0.7303370833396912, 
train_balance_acc=0.6015321612358093,
 train_f1_score=0.4952380955219269,
 train_auc=0.6375893950462341

Epoch [41/200]:, eval_loss=0.021, 
eval_confusionMatrix:
tensor([[ 0, 21],
        [ 0, 11]], device='cuda:0')
eval_accuracy=0.34375, 
eval_recall=1.0, 
eval_precision=0.34375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5116279125213623,
 eval_auc=0.5411255359649658


Epoch: 42/200
Training Epoch 42, LR 0.001000:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 42, LR 0.001000:   6%|â–Œ         | 1/18 [00:04<01:08,  4.04s/batch]Training Epoch 42, LR 0.001000:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.90s/batch]Training Epoch 42, LR 0.001000:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.22s/batch]Training Epoch 42, LR 0.001000:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 42, LR 0.001000:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.37s/batch]Training Epoch 42, LR 0.001000:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 42, LR 0.001000:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 42, LR 0.001000:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.43batch/s]Training Epoch 42, LR 0.001000:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 42, LR 0.001000:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.11batch/s]Training Epoch 42, LR 0.001000:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 42, LR 0.001000:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 42, LR 0.001000:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.11s/batch]Training Epoch 42, LR 0.001000:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.12batch/s]Training Epoch 42, LR 0.001000:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.34batch/s]Training Epoch 42, LR 0.001000:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.55batch/s]Training Epoch 42, LR 0.001000:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.06s/batch]Training Epoch 42, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 42, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 42:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 42:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.96s/batch]Evaluating Epoch 42:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:04<00:03,  1.72s/batch]Evaluating Epoch 42:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.00s/batch]Evaluating Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.50batch/s]Evaluating Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.12s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [42/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[83,  7],
        [40, 14]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.25925925374031067, 
train_precision=0.6666666865348816, 
train_specificity=0.9222221970558167, 
train_balance_acc=0.5907407402992249,
 train_f1_score=0.3733333349227905,
 train_auc=0.6039094924926758

Epoch [42/200]:, eval_loss=0.018, 
eval_confusionMatrix:
tensor([[12,  9],
        [ 8,  3]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=0.27272728085517883, 
eval_precision=0.25, 
eval_specificity=0.5714285969734192, 
eval_balance_acc=0.4220779538154602,
 eval_f1_score=0.260869562625885,
 eval_auc=0.4199134111404419


Epoch: 43/200
Training Epoch 43, LR 0.000999:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 43, LR 0.000999:   6%|â–Œ         | 1/18 [00:04<01:11,  4.22s/batch]Training Epoch 43, LR 0.000999:  11%|â–ˆ         | 2/18 [00:04<00:31,  1.98s/batch]Training Epoch 43, LR 0.000999:  17%|â–ˆâ–‹        | 3/18 [00:05<00:19,  1.27s/batch]Training Epoch 43, LR 0.000999:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:13,  1.07batch/s]Training Epoch 43, LR 0.000999:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.36s/batch]Training Epoch 43, LR 0.000999:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 43, LR 0.000999:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 43, LR 0.000999:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 43, LR 0.000999:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.06s/batch]Training Epoch 43, LR 0.000999:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:06,  1.16batch/s]Training Epoch 43, LR 0.000999:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.38batch/s]Training Epoch 43, LR 0.000999:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 43, LR 0.000999:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.01batch/s]Training Epoch 43, LR 0.000999:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.23batch/s]Training Epoch 43, LR 0.000999:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.45batch/s]Training Epoch 43, LR 0.000999:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.65batch/s]Training Epoch 43, LR 0.000999:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.03batch/s]Training Epoch 43, LR 0.000999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.25batch/s]Training Epoch 43, LR 0.000999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 43:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 43:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.57s/batch]Evaluating Epoch 43:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 43:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [43/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[82,  7],
        [42, 13]], device='cuda:0')
train_accuracy=0.6597222089767456, 
train_recall=0.23636363446712494, 
train_precision=0.6499999761581421, 
train_specificity=0.9213483333587646, 
train_balance_acc=0.5788559913635254,
 train_f1_score=0.3466666638851166,
 train_auc=0.6706843972206116

Epoch [43/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[11,  8],
        [ 5,  8]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.6153846383094788, 
eval_precision=0.5, 
eval_specificity=0.5789473652839661, 
eval_balance_acc=0.5971660017967224,
 eval_f1_score=0.5517241358757019,
 eval_auc=0.5668016672134399


Epoch: 44/200
Training Epoch 44, LR 0.000997:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 44, LR 0.000997:   6%|â–Œ         | 1/18 [00:03<01:05,  3.84s/batch]Training Epoch 44, LR 0.000997:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 44, LR 0.000997:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 44, LR 0.000997:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 44, LR 0.000997:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 44, LR 0.000997:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 44, LR 0.000997:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 44, LR 0.000997:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 44, LR 0.000997:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.20s/batch]Training Epoch 44, LR 0.000997:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.05batch/s]Training Epoch 44, LR 0.000997:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.27batch/s]Training Epoch 44, LR 0.000997:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:04,  1.49batch/s]Training Epoch 44, LR 0.000997:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.10s/batch]Training Epoch 44, LR 0.000997:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.12batch/s]Training Epoch 44, LR 0.000997:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.34batch/s]Training Epoch 44, LR 0.000997:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.55batch/s]Training Epoch 44, LR 0.000997:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.06s/batch]Training Epoch 44, LR 0.000997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 44, LR 0.000997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 44:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 44:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.74s/batch]Evaluating Epoch 44:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.63s/batch]Evaluating Epoch 44:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [44/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[78, 11],
        [34, 21]], device='cuda:0')
train_accuracy=0.6875, 
train_recall=0.38181817531585693, 
train_precision=0.65625, 
train_specificity=0.8764045238494873, 
train_balance_acc=0.6291113495826721,
 train_f1_score=0.48275861144065857,
 train_auc=0.6514810919761658

Epoch [44/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 8, 12],
        [ 3,  9]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.75, 
eval_precision=0.4285714328289032, 
eval_specificity=0.4000000059604645, 
eval_balance_acc=0.574999988079071,
 eval_f1_score=0.5454545617103577,
 eval_auc=0.4791666567325592


Epoch: 45/200
Training Epoch 45, LR 0.000995:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 45, LR 0.000995:   6%|â–Œ         | 1/18 [00:03<01:04,  3.80s/batch]Training Epoch 45, LR 0.000995:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 45, LR 0.000995:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 45, LR 0.000995:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 45, LR 0.000995:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 45, LR 0.000995:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 45, LR 0.000995:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 45, LR 0.000995:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 45, LR 0.000995:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 45, LR 0.000995:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.14batch/s]Training Epoch 45, LR 0.000995:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 45, LR 0.000995:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 45, LR 0.000995:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 45, LR 0.000995:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 45, LR 0.000995:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 45, LR 0.000995:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.56batch/s]Training Epoch 45, LR 0.000995:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 45, LR 0.000995: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 45, LR 0.000995: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 45:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 45:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.42s/batch]Evaluating Epoch 45:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.50s/batch]Evaluating Epoch 45:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.68batch/s]Evaluating Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [45/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[71, 19],
        [33, 21]], device='cuda:0')
train_accuracy=0.6388888955116272, 
train_recall=0.3888888955116272, 
train_precision=0.5249999761581421, 
train_specificity=0.7888888716697693, 
train_balance_acc=0.5888888835906982,
 train_f1_score=0.44680851697921753,
 train_auc=0.6625514626502991

Epoch [45/200]:, eval_loss=0.018, 
eval_confusionMatrix:
tensor([[ 4, 15],
        [ 4,  9]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=0.692307710647583, 
eval_precision=0.375, 
eval_specificity=0.21052631735801697, 
eval_balance_acc=0.4514170289039612,
 eval_f1_score=0.4864864945411682,
 eval_auc=0.5020242929458618


Epoch: 46/200
Training Epoch 46, LR 0.000992:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 46, LR 0.000992:   6%|â–Œ         | 1/18 [00:03<01:04,  3.81s/batch]Training Epoch 46, LR 0.000992:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 46, LR 0.000992:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 46, LR 0.000992:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 46, LR 0.000992:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.24s/batch]Training Epoch 46, LR 0.000992:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.04batch/s]Training Epoch 46, LR 0.000992:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.28batch/s]Training Epoch 46, LR 0.000992:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.52batch/s]Training Epoch 46, LR 0.000992:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.04s/batch]Training Epoch 46, LR 0.000992:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 46, LR 0.000992:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:04,  1.40batch/s]Training Epoch 46, LR 0.000992:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.61batch/s]Training Epoch 46, LR 0.000992:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 46, LR 0.000992:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 46, LR 0.000992:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 46, LR 0.000992:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 46, LR 0.000992:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.03s/batch]Training Epoch 46, LR 0.000992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.19batch/s]Training Epoch 46, LR 0.000992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 46:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 46:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.45s/batch]Evaluating Epoch 46:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.51s/batch]Evaluating Epoch 46:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.67batch/s]Evaluating Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [46/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[76, 14],
        [33, 21]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.3888888955116272, 
train_precision=0.6000000238418579, 
train_specificity=0.8444444537162781, 
train_balance_acc=0.6166666746139526,
 train_f1_score=0.47191011905670166,
 train_auc=0.6823045015335083

Epoch [46/200]:, eval_loss=0.020, 
eval_confusionMatrix:
tensor([[ 0, 20],
        [ 0, 12]], device='cuda:0')
eval_accuracy=0.375, 
eval_recall=1.0, 
eval_precision=0.375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5454545617103577,
 eval_auc=0.4750000238418579


Epoch: 47/200
Training Epoch 47, LR 0.000989:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 47, LR 0.000989:   6%|â–Œ         | 1/18 [00:03<01:06,  3.92s/batch]Training Epoch 47, LR 0.000989:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.86s/batch]Training Epoch 47, LR 0.000989:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.20s/batch]Training Epoch 47, LR 0.000989:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 47, LR 0.000989:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 47, LR 0.000989:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 47, LR 0.000989:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 47, LR 0.000989:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 47, LR 0.000989:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 47, LR 0.000989:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.11batch/s]Training Epoch 47, LR 0.000989:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 47, LR 0.000989:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 47, LR 0.000989:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 47, LR 0.000989:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.16batch/s]Training Epoch 47, LR 0.000989:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 47, LR 0.000989:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.59batch/s]Training Epoch 47, LR 0.000989:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.05s/batch]Training Epoch 47, LR 0.000989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 47, LR 0.000989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 47:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 47:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.65s/batch]Evaluating Epoch 47:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.59s/batch]Evaluating Epoch 47:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [47/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[79, 11],
        [29, 25]], device='cuda:0')
train_accuracy=0.7222222089767456, 
train_recall=0.46296295523643494, 
train_precision=0.6944444179534912, 
train_specificity=0.8777777552604675, 
train_balance_acc=0.67037034034729,
 train_f1_score=0.5555555820465088,
 train_auc=0.7201645970344543

Epoch [47/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[19,  0],
        [13,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.5991902947425842


Epoch: 48/200
Training Epoch 48, LR 0.000985:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 48, LR 0.000985:   6%|â–Œ         | 1/18 [00:03<01:05,  3.87s/batch]Training Epoch 48, LR 0.000985:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 48, LR 0.000985:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 48, LR 0.000985:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 48, LR 0.000985:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 48, LR 0.000985:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 48, LR 0.000985:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 48, LR 0.000985:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 48, LR 0.000985:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.14s/batch]Training Epoch 48, LR 0.000985:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.09batch/s]Training Epoch 48, LR 0.000985:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 48, LR 0.000985:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 48, LR 0.000985:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.10s/batch]Training Epoch 48, LR 0.000985:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.12batch/s]Training Epoch 48, LR 0.000985:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.34batch/s]Training Epoch 48, LR 0.000985:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.55batch/s]Training Epoch 48, LR 0.000985:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.06s/batch]Training Epoch 48, LR 0.000985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 48, LR 0.000985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 48:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 48:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.39s/batch]Evaluating Epoch 48:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:02,  1.48s/batch]Evaluating Epoch 48:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.14batch/s]Evaluating Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.69batch/s]Evaluating Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [48/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[81,  8],
        [27, 28]], device='cuda:0')
train_accuracy=0.7569444179534912, 
train_recall=0.5090909004211426, 
train_precision=0.7777777910232544, 
train_specificity=0.9101123809814453, 
train_balance_acc=0.709601640701294,
 train_f1_score=0.6153846383094788,
 train_auc=0.7638406157493591

Epoch [48/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  1],
        [11,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.9523809552192688, 
eval_balance_acc=0.4761904776096344,
 eval_f1_score=0.0,
 eval_auc=0.6709957122802734


Epoch: 49/200
Training Epoch 49, LR 0.000981:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 49, LR 0.000981:   6%|â–Œ         | 1/18 [00:03<01:03,  3.71s/batch]Training Epoch 49, LR 0.000981:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.77s/batch]Training Epoch 49, LR 0.000981:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 49, LR 0.000981:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.17batch/s]Training Epoch 49, LR 0.000981:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.26s/batch]Training Epoch 49, LR 0.000981:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 49, LR 0.000981:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 49, LR 0.000981:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 49, LR 0.000981:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 49, LR 0.000981:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.09batch/s]Training Epoch 49, LR 0.000981:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.31batch/s]Training Epoch 49, LR 0.000981:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 49, LR 0.000981:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 49, LR 0.000981:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.10batch/s]Training Epoch 49, LR 0.000981:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.32batch/s]Training Epoch 49, LR 0.000981:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.53batch/s]Training Epoch 49, LR 0.000981:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.04batch/s]Training Epoch 49, LR 0.000981: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 49, LR 0.000981: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 49:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 49:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.61s/batch]Evaluating Epoch 49:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 49:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [49/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[76, 13],
        [35, 20]], device='cuda:0')
train_accuracy=0.6666666865348816, 
train_recall=0.3636363744735718, 
train_precision=0.6060606241226196, 
train_specificity=0.8539325594902039, 
train_balance_acc=0.6087844371795654,
 train_f1_score=0.4545454680919647,
 train_auc=0.7209397554397583

Epoch [49/200]:, eval_loss=0.019, 
eval_confusionMatrix:
tensor([[ 5, 17],
        [ 2,  8]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=0.800000011920929, 
eval_precision=0.3199999928474426, 
eval_specificity=0.22727273404598236, 
eval_balance_acc=0.5136363506317139,
 eval_f1_score=0.4571428596973419,
 eval_auc=0.4545454680919647


Epoch: 50/200
Training Epoch 50, LR 0.000976:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 50, LR 0.000976:   6%|â–Œ         | 1/18 [00:03<01:04,  3.79s/batch]Training Epoch 50, LR 0.000976:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 50, LR 0.000976:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 50, LR 0.000976:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.16batch/s]Training Epoch 50, LR 0.000976:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 50, LR 0.000976:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 50, LR 0.000976:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 50, LR 0.000976:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 50, LR 0.000976:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 50, LR 0.000976:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 50, LR 0.000976:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 50, LR 0.000976:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 50, LR 0.000976:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 50, LR 0.000976:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.20batch/s]Training Epoch 50, LR 0.000976:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 50, LR 0.000976:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 50, LR 0.000976:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 50, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 50, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 50:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 50:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.54s/batch]Evaluating Epoch 50:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 50:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [50/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[75, 14],
        [31, 24]], device='cuda:0')
train_accuracy=0.6875, 
train_recall=0.4363636374473572, 
train_precision=0.6315789222717285, 
train_specificity=0.8426966071128845, 
train_balance_acc=0.6395301222801208,
 train_f1_score=0.5161290168762207,
 train_auc=0.724412739276886

Epoch [50/200]:, eval_loss=0.018, 
eval_confusionMatrix:
tensor([[ 2, 17],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=1.0, 
eval_precision=0.4333333373069763, 
eval_specificity=0.10526315867900848, 
eval_balance_acc=0.5526315569877625,
 eval_f1_score=0.604651153087616,
 eval_auc=0.5384615063667297


Epoch: 51/200
Training Epoch 51, LR 0.000970:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 51, LR 0.000970:   6%|â–Œ         | 1/18 [00:03<01:04,  3.81s/batch]Training Epoch 51, LR 0.000970:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 51, LR 0.000970:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 51, LR 0.000970:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 51, LR 0.000970:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.37s/batch]Training Epoch 51, LR 0.000970:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 51, LR 0.000970:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 51, LR 0.000970:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 51, LR 0.000970:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.06s/batch]Training Epoch 51, LR 0.000970:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.16batch/s]Training Epoch 51, LR 0.000970:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.39batch/s]Training Epoch 51, LR 0.000970:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 51, LR 0.000970:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.01batch/s]Training Epoch 51, LR 0.000970:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.23batch/s]Training Epoch 51, LR 0.000970:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.45batch/s]Training Epoch 51, LR 0.000970:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.66batch/s]Training Epoch 51, LR 0.000970:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.03batch/s]Training Epoch 51, LR 0.000970: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.25batch/s]Training Epoch 51, LR 0.000970: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.07batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 51:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 51:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.57s/batch]Evaluating Epoch 51:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 51:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [51/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[70, 19],
        [37, 18]], device='cuda:0')
train_accuracy=0.6111111044883728, 
train_recall=0.3272727131843567, 
train_precision=0.4864864945411682, 
train_specificity=0.7865168452262878, 
train_balance_acc=0.5568947792053223,
 train_f1_score=0.3913043439388275,
 train_auc=0.6212462186813354

Epoch [51/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[15,  4],
        [ 9,  4]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.3076923191547394, 
eval_precision=0.5, 
eval_specificity=0.7894737124443054, 
eval_balance_acc=0.5485830307006836,
 eval_f1_score=0.380952388048172,
 eval_auc=0.5587044358253479


Epoch: 52/200
Training Epoch 52, LR 0.000964:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 52, LR 0.000964:   6%|â–Œ         | 1/18 [00:03<01:03,  3.73s/batch]Training Epoch 52, LR 0.000964:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.77s/batch]Training Epoch 52, LR 0.000964:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 52, LR 0.000964:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 52, LR 0.000964:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.25s/batch]Training Epoch 52, LR 0.000964:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.04batch/s]Training Epoch 52, LR 0.000964:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.28batch/s]Training Epoch 52, LR 0.000964:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 52, LR 0.000964:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.06s/batch]Training Epoch 52, LR 0.000964:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.17batch/s]Training Epoch 52, LR 0.000964:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.39batch/s]Training Epoch 52, LR 0.000964:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 52, LR 0.000964:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 52, LR 0.000964:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 52, LR 0.000964:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 52, LR 0.000964:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 52, LR 0.000964:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 52, LR 0.000964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.20batch/s]Training Epoch 52, LR 0.000964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.07batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 52:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 52:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.61s/batch]Evaluating Epoch 52:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 52:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [52/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[78, 12],
        [33, 21]], device='cuda:0')
train_accuracy=0.6875, 
train_recall=0.3888888955116272, 
train_precision=0.6363636255264282, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.6277778148651123,
 train_f1_score=0.48275861144065857,
 train_auc=0.7010288238525391

Epoch [52/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[11,  7],
        [ 6,  8]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.5714285969734192, 
eval_precision=0.5333333611488342, 
eval_specificity=0.6111111044883728, 
eval_balance_acc=0.591269850730896,
 eval_f1_score=0.5517241358757019,
 eval_auc=0.5952380895614624


Epoch: 53/200
Training Epoch 53, LR 0.000957:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 53, LR 0.000957:   6%|â–Œ         | 1/18 [00:03<01:05,  3.86s/batch]Training Epoch 53, LR 0.000957:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 53, LR 0.000957:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 53, LR 0.000957:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 53, LR 0.000957:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.40s/batch]Training Epoch 53, LR 0.000957:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.06s/batch]Training Epoch 53, LR 0.000957:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.18batch/s]Training Epoch 53, LR 0.000957:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.41batch/s]Training Epoch 53, LR 0.000957:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.16s/batch]Training Epoch 53, LR 0.000957:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.08batch/s]Training Epoch 53, LR 0.000957:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.30batch/s]Training Epoch 53, LR 0.000957:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.52batch/s]Training Epoch 53, LR 0.000957:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.14s/batch]Training Epoch 53, LR 0.000957:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.09batch/s]Training Epoch 53, LR 0.000957:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.31batch/s]Training Epoch 53, LR 0.000957:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.52batch/s]Training Epoch 53, LR 0.000957:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:00,  1.01batch/s]Training Epoch 53, LR 0.000957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.23batch/s]Training Epoch 53, LR 0.000957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 53:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 53:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.40s/batch]Evaluating Epoch 53:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:02,  1.49s/batch]Evaluating Epoch 53:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.14batch/s]Evaluating Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.69batch/s]Evaluating Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [53/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[77, 12],
        [29, 26]], device='cuda:0')
train_accuracy=0.7152777910232544, 
train_recall=0.4727272689342499, 
train_precision=0.6842105388641357, 
train_specificity=0.8651685118675232, 
train_balance_acc=0.6689478754997253,
 train_f1_score=0.5591397881507874,
 train_auc=0.751787543296814

Epoch [53/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[13,  6],
        [ 6,  7]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.5384615659713745, 
eval_precision=0.5384615659713745, 
eval_specificity=0.6842105388641357, 
eval_balance_acc=0.6113360524177551,
 eval_f1_score=0.5384615659713745,
 eval_auc=0.6275303363800049


Epoch: 54/200
Training Epoch 54, LR 0.000950:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 54, LR 0.000950:   6%|â–Œ         | 1/18 [00:03<01:01,  3.59s/batch]Training Epoch 54, LR 0.000950:  11%|â–ˆ         | 2/18 [00:03<00:27,  1.72s/batch]Training Epoch 54, LR 0.000950:  17%|â–ˆâ–‹        | 3/18 [00:04<00:16,  1.12s/batch]Training Epoch 54, LR 0.000950:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.19batch/s]Training Epoch 54, LR 0.000950:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:15,  1.23s/batch]Training Epoch 54, LR 0.000950:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.05batch/s]Training Epoch 54, LR 0.000950:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.30batch/s]Training Epoch 54, LR 0.000950:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:07<00:06,  1.53batch/s]Training Epoch 54, LR 0.000950:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:09<00:09,  1.04s/batch]Training Epoch 54, LR 0.000950:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 54, LR 0.000950:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:04,  1.41batch/s]Training Epoch 54, LR 0.000950:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.62batch/s]Training Epoch 54, LR 0.000950:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:12<00:05,  1.00s/batch]Training Epoch 54, LR 0.000950:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.22batch/s]Training Epoch 54, LR 0.000950:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:13<00:02,  1.44batch/s]Training Epoch 54, LR 0.000950:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.64batch/s]Training Epoch 54, LR 0.000950:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:15<00:00,  1.07batch/s]Training Epoch 54, LR 0.000950: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.29batch/s]Training Epoch 54, LR 0.000950: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.10batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 54:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 54:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.57s/batch]Evaluating Epoch 54:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 54:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [54/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[75, 14],
        [27, 28]], device='cuda:0')
train_accuracy=0.7152777910232544, 
train_recall=0.5090909004211426, 
train_precision=0.6666666865348816, 
train_specificity=0.8426966071128845, 
train_balance_acc=0.6758937835693359,
 train_f1_score=0.5773195624351501,
 train_auc=0.7673135995864868

Epoch [54/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[14,  5],
        [ 8,  5]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.38461539149284363, 
eval_precision=0.5, 
eval_specificity=0.7368420958518982, 
eval_balance_acc=0.5607287287712097,
 eval_f1_score=0.43478259444236755,
 eval_auc=0.6275303959846497


Epoch: 55/200
Training Epoch 55, LR 0.000942:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 55, LR 0.000942:   6%|â–Œ         | 1/18 [00:03<01:04,  3.80s/batch]Training Epoch 55, LR 0.000942:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 55, LR 0.000942:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 55, LR 0.000942:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 55, LR 0.000942:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 55, LR 0.000942:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 55, LR 0.000942:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 55, LR 0.000942:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 55, LR 0.000942:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.11s/batch]Training Epoch 55, LR 0.000942:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 55, LR 0.000942:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 55, LR 0.000942:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 55, LR 0.000942:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 55, LR 0.000942:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 55, LR 0.000942:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 55, LR 0.000942:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 55, LR 0.000942:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 55, LR 0.000942: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 55, LR 0.000942: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 55:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 55:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.53s/batch]Evaluating Epoch 55:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 55:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [55/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[73, 16],
        [26, 29]], device='cuda:0')
train_accuracy=0.7083333134651184, 
train_recall=0.5272727012634277, 
train_precision=0.644444465637207, 
train_specificity=0.8202247023582458, 
train_balance_acc=0.6737487316131592,
 train_f1_score=0.5799999833106995,
 train_auc=0.7438201904296875

Epoch [55/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[16,  4],
        [10,  2]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.1666666716337204, 
eval_precision=0.3333333432674408, 
eval_specificity=0.800000011920929, 
eval_balance_acc=0.4833333492279053,
 eval_f1_score=0.2222222238779068,
 eval_auc=0.5666666626930237


Epoch: 56/200
Training Epoch 56, LR 0.000934:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 56, LR 0.000934:   6%|â–Œ         | 1/18 [00:04<01:09,  4.09s/batch]Training Epoch 56, LR 0.000934:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.93s/batch]Training Epoch 56, LR 0.000934:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.23s/batch]Training Epoch 56, LR 0.000934:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 56, LR 0.000934:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 56, LR 0.000934:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 56, LR 0.000934:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.22batch/s]Training Epoch 56, LR 0.000934:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 56, LR 0.000934:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 56, LR 0.000934:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.12batch/s]Training Epoch 56, LR 0.000934:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 56, LR 0.000934:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 56, LR 0.000934:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.15s/batch]Training Epoch 56, LR 0.000934:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.08batch/s]Training Epoch 56, LR 0.000934:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.31batch/s]Training Epoch 56, LR 0.000934:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.52batch/s]Training Epoch 56, LR 0.000934:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.02s/batch]Training Epoch 56, LR 0.000934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 56, LR 0.000934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 56:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 56:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.54s/batch]Evaluating Epoch 56:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 56:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [56/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[75, 15],
        [26, 28]], device='cuda:0')
train_accuracy=0.7152777910232544, 
train_recall=0.5185185074806213, 
train_precision=0.6511628031730652, 
train_specificity=0.8333333134651184, 
train_balance_acc=0.6759259104728699,
 train_f1_score=0.5773195624351501,
 train_auc=0.7288065552711487

Epoch [56/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[13,  6],
        [ 9,  4]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.3076923191547394, 
eval_precision=0.4000000059604645, 
eval_specificity=0.6842105388641357, 
eval_balance_acc=0.49595141410827637,
 eval_f1_score=0.3478260934352875,
 eval_auc=0.5141700506210327


Epoch: 57/200
Training Epoch 57, LR 0.000925:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 57, LR 0.000925:   6%|â–Œ         | 1/18 [00:03<01:03,  3.74s/batch]Training Epoch 57, LR 0.000925:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 57, LR 0.000925:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 57, LR 0.000925:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 57, LR 0.000925:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 57, LR 0.000925:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 57, LR 0.000925:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.23batch/s]Training Epoch 57, LR 0.000925:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 57, LR 0.000925:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 57, LR 0.000925:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 57, LR 0.000925:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 57, LR 0.000925:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 57, LR 0.000925:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 57, LR 0.000925:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.19batch/s]Training Epoch 57, LR 0.000925:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 57, LR 0.000925:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 57, LR 0.000925:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 57, LR 0.000925: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 57, LR 0.000925: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 57:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 57:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.66s/batch]Evaluating Epoch 57:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.60s/batch]Evaluating Epoch 57:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [57/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[78, 12],
        [28, 26]], device='cuda:0')
train_accuracy=0.7222222089767456, 
train_recall=0.48148149251937866, 
train_precision=0.6842105388641357, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.6740740537643433,
 train_f1_score=0.5652173757553101,
 train_auc=0.7450617551803589

Epoch [57/200]:, eval_loss=0.018, 
eval_confusionMatrix:
tensor([[ 5, 16],
        [ 1, 10]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=0.9090909361839294, 
eval_precision=0.38461539149284363, 
eval_specificity=0.2380952388048172, 
eval_balance_acc=0.5735930800437927,
 eval_f1_score=0.5405405163764954,
 eval_auc=0.5454545021057129


Epoch: 58/200
Training Epoch 58, LR 0.000915:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 58, LR 0.000915:   6%|â–Œ         | 1/18 [00:03<01:05,  3.83s/batch]Training Epoch 58, LR 0.000915:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 58, LR 0.000915:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 58, LR 0.000915:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 58, LR 0.000915:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.39s/batch]Training Epoch 58, LR 0.000915:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.06s/batch]Training Epoch 58, LR 0.000915:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.18batch/s]Training Epoch 58, LR 0.000915:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.42batch/s]Training Epoch 58, LR 0.000915:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 58, LR 0.000915:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.11batch/s]Training Epoch 58, LR 0.000915:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 58, LR 0.000915:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 58, LR 0.000915:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.15s/batch]Training Epoch 58, LR 0.000915:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.08batch/s]Training Epoch 58, LR 0.000915:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.30batch/s]Training Epoch 58, LR 0.000915:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.51batch/s]Training Epoch 58, LR 0.000915:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.03s/batch]Training Epoch 58, LR 0.000915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 58, LR 0.000915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 58:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 58:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.35s/batch]Evaluating Epoch 58:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:02,  1.47s/batch]Evaluating Epoch 58:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.15batch/s]Evaluating Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.71batch/s]Evaluating Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [58/200]:, train_loss=0.055, 
train_confusionMatrix:
tensor([[77, 12],
        [22, 33]], device='cuda:0')
train_accuracy=0.7638888955116272, 
train_recall=0.6000000238418579, 
train_precision=0.7333333492279053, 
train_specificity=0.8651685118675232, 
train_balance_acc=0.7325842380523682,
 train_f1_score=0.6600000262260437,
 train_auc=0.790398359298706

Epoch [58/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[18,  1],
        [12,  1]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.07692307978868484, 
eval_precision=0.5, 
eval_specificity=0.9473684430122375, 
eval_balance_acc=0.5121457576751709,
 eval_f1_score=0.13333334028720856,
 eval_auc=0.5910931825637817


Epoch: 59/200
Training Epoch 59, LR 0.000905:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 59, LR 0.000905:   6%|â–Œ         | 1/18 [00:03<01:06,  3.90s/batch]Training Epoch 59, LR 0.000905:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 59, LR 0.000905:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 59, LR 0.000905:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 59, LR 0.000905:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.24s/batch]Training Epoch 59, LR 0.000905:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.04batch/s]Training Epoch 59, LR 0.000905:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.28batch/s]Training Epoch 59, LR 0.000905:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 59, LR 0.000905:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.11s/batch]Training Epoch 59, LR 0.000905:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 59, LR 0.000905:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 59, LR 0.000905:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 59, LR 0.000905:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 59, LR 0.000905:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 59, LR 0.000905:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 59, LR 0.000905:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 59, LR 0.000905:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 59, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 59, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 59:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 59:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 59:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 59:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [59/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[70, 19],
        [20, 35]], device='cuda:0')
train_accuracy=0.7291666865348816, 
train_recall=0.6363636255264282, 
train_precision=0.6481481194496155, 
train_specificity=0.7865168452262878, 
train_balance_acc=0.7114402055740356,
 train_f1_score=0.642201840877533,
 train_auc=0.7548518776893616

Epoch [59/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[16,  4],
        [ 8,  4]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.3333333432674408, 
eval_precision=0.5, 
eval_specificity=0.800000011920929, 
eval_balance_acc=0.5666666626930237,
 eval_f1_score=0.4000000059604645,
 eval_auc=0.5874999761581421


Epoch: 60/200
Training Epoch 60, LR 0.000895:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 60, LR 0.000895:   6%|â–Œ         | 1/18 [00:03<01:07,  3.95s/batch]Training Epoch 60, LR 0.000895:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 60, LR 0.000895:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.20s/batch]Training Epoch 60, LR 0.000895:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 60, LR 0.000895:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.36s/batch]Training Epoch 60, LR 0.000895:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 60, LR 0.000895:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 60, LR 0.000895:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.43batch/s]Training Epoch 60, LR 0.000895:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.17s/batch]Training Epoch 60, LR 0.000895:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.07batch/s]Training Epoch 60, LR 0.000895:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.29batch/s]Training Epoch 60, LR 0.000895:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.51batch/s]Training Epoch 60, LR 0.000895:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.08s/batch]Training Epoch 60, LR 0.000895:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 60, LR 0.000895:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 60, LR 0.000895:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.58batch/s]Training Epoch 60, LR 0.000895:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.02s/batch]Training Epoch 60, LR 0.000895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 60, LR 0.000895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 60:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 60:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.62s/batch]Evaluating Epoch 60:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 60:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [60/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[72, 18],
        [22, 32]], device='cuda:0')
train_accuracy=0.7222222089767456, 
train_recall=0.5925925970077515, 
train_precision=0.6399999856948853, 
train_specificity=0.800000011920929, 
train_balance_acc=0.6962963342666626,
 train_f1_score=0.6153846383094788,
 train_auc=0.7479423880577087

Epoch [60/200]:, eval_loss=0.021, 
eval_confusionMatrix:
tensor([[ 1, 20],
        [ 1, 10]], device='cuda:0')
eval_accuracy=0.34375, 
eval_recall=0.9090909361839294, 
eval_precision=0.3333333432674408, 
eval_specificity=0.0476190485060215, 
eval_balance_acc=0.4783549904823303,
 eval_f1_score=0.4878048896789551,
 eval_auc=0.49567103385925293


Epoch: 61/200
Training Epoch 61, LR 0.000884:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 61, LR 0.000884:   6%|â–Œ         | 1/18 [00:03<01:04,  3.78s/batch]Training Epoch 61, LR 0.000884:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 61, LR 0.000884:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 61, LR 0.000884:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.16batch/s]Training Epoch 61, LR 0.000884:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 61, LR 0.000884:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 61, LR 0.000884:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.23batch/s]Training Epoch 61, LR 0.000884:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 61, LR 0.000884:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 61, LR 0.000884:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 61, LR 0.000884:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.37batch/s]Training Epoch 61, LR 0.000884:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 61, LR 0.000884:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.01s/batch]Training Epoch 61, LR 0.000884:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.21batch/s]Training Epoch 61, LR 0.000884:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.43batch/s]Training Epoch 61, LR 0.000884:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.64batch/s]Training Epoch 61, LR 0.000884:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 61, LR 0.000884: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.24batch/s]Training Epoch 61, LR 0.000884: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.07batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 61:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 61:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.42s/batch]Evaluating Epoch 61:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:02,  1.50s/batch]Evaluating Epoch 61:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.68batch/s]Evaluating Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [61/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[76, 14],
        [33, 21]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.3888888955116272, 
train_precision=0.6000000238418579, 
train_specificity=0.8444444537162781, 
train_balance_acc=0.6166666746139526,
 train_f1_score=0.47191011905670166,
 train_auc=0.7228394746780396

Epoch [61/200]:, eval_loss=0.019, 
eval_confusionMatrix:
tensor([[ 6, 14],
        [ 4,  8]], device='cuda:0')
eval_accuracy=0.4375, 
eval_recall=0.6666666865348816, 
eval_precision=0.3636363744735718, 
eval_specificity=0.30000001192092896, 
eval_balance_acc=0.4833333492279053,
 eval_f1_score=0.47058823704719543,
 eval_auc=0.5250000357627869


Epoch: 62/200
Training Epoch 62, LR 0.000873:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 62, LR 0.000873:   6%|â–Œ         | 1/18 [00:03<01:04,  3.80s/batch]Training Epoch 62, LR 0.000873:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 62, LR 0.000873:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 62, LR 0.000873:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 62, LR 0.000873:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 62, LR 0.000873:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 62, LR 0.000873:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 62, LR 0.000873:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 62, LR 0.000873:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.14s/batch]Training Epoch 62, LR 0.000873:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 62, LR 0.000873:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 62, LR 0.000873:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 62, LR 0.000873:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.10s/batch]Training Epoch 62, LR 0.000873:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.12batch/s]Training Epoch 62, LR 0.000873:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.34batch/s]Training Epoch 62, LR 0.000873:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.55batch/s]Training Epoch 62, LR 0.000873:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.07s/batch]Training Epoch 62, LR 0.000873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.15batch/s]Training Epoch 62, LR 0.000873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 62:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 62:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.71s/batch]Evaluating Epoch 62:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.62s/batch]Evaluating Epoch 62:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [62/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[82,  7],
        [36, 19]], device='cuda:0')
train_accuracy=0.7013888955116272, 
train_recall=0.34545454382896423, 
train_precision=0.7307692170143127, 
train_specificity=0.9213483333587646, 
train_balance_acc=0.6334014534950256,
 train_f1_score=0.4691357910633087,
 train_auc=0.6947906017303467

Epoch [62/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[22,  0],
        [10,  0]], device='cuda:0')
eval_accuracy=0.6875, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.6000000238418579


Epoch: 63/200
Training Epoch 63, LR 0.000861:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 63, LR 0.000861:   6%|â–Œ         | 1/18 [00:03<01:03,  3.75s/batch]Training Epoch 63, LR 0.000861:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 63, LR 0.000861:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 63, LR 0.000861:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 63, LR 0.000861:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 63, LR 0.000861:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 63, LR 0.000861:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:09,  1.22batch/s]Training Epoch 63, LR 0.000861:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 63, LR 0.000861:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.14s/batch]Training Epoch 63, LR 0.000861:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.09batch/s]Training Epoch 63, LR 0.000861:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 63, LR 0.000861:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 63, LR 0.000861:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 63, LR 0.000861:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.17batch/s]Training Epoch 63, LR 0.000861:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 63, LR 0.000861:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 63, LR 0.000861:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 63, LR 0.000861: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 63, LR 0.000861: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 63:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 63:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.46s/batch]Evaluating Epoch 63:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.52s/batch]Evaluating Epoch 63:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.66batch/s]Evaluating Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [63/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[81,  9],
        [33, 21]], device='cuda:0')
train_accuracy=0.7083333134651184, 
train_recall=0.3888888955116272, 
train_precision=0.699999988079071, 
train_specificity=0.8999999761581421, 
train_balance_acc=0.644444465637207,
 train_f1_score=0.5,
 train_auc=0.7065843343734741

Epoch [63/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[17,  2],
        [11,  2]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.1538461595773697, 
eval_precision=0.5, 
eval_specificity=0.8947368264198303, 
eval_balance_acc=0.5242915153503418,
 eval_f1_score=0.23529411852359772,
 eval_auc=0.6518218517303467


Epoch: 64/200
Training Epoch 64, LR 0.000849:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 64, LR 0.000849:   6%|â–Œ         | 1/18 [00:03<01:04,  3.80s/batch]Training Epoch 64, LR 0.000849:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 64, LR 0.000849:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 64, LR 0.000849:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 64, LR 0.000849:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.32s/batch]Training Epoch 64, LR 0.000849:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 64, LR 0.000849:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.23batch/s]Training Epoch 64, LR 0.000849:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 64, LR 0.000849:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 64, LR 0.000849:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.11batch/s]Training Epoch 64, LR 0.000849:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 64, LR 0.000849:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 64, LR 0.000849:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 64, LR 0.000849:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.17batch/s]Training Epoch 64, LR 0.000849:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 64, LR 0.000849:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 64, LR 0.000849:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.00s/batch]Training Epoch 64, LR 0.000849: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.22batch/s]Training Epoch 64, LR 0.000849: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 64:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 64:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.55s/batch]Evaluating Epoch 64:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 64:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [64/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[79, 10],
        [26, 29]], device='cuda:0')
train_accuracy=0.75, 
train_recall=0.5272727012634277, 
train_precision=0.7435897588729858, 
train_specificity=0.8876404762268066, 
train_balance_acc=0.7074565887451172,
 train_f1_score=0.6170212626457214,
 train_auc=0.7716037034988403

Epoch [64/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.5291666984558105


Epoch: 65/200
Training Epoch 65, LR 0.000836:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 65, LR 0.000836:   6%|â–Œ         | 1/18 [00:03<01:03,  3.71s/batch]Training Epoch 65, LR 0.000836:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.76s/batch]Training Epoch 65, LR 0.000836:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.14s/batch]Training Epoch 65, LR 0.000836:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.17batch/s]Training Epoch 65, LR 0.000836:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.32s/batch]Training Epoch 65, LR 0.000836:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 65, LR 0.000836:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.23batch/s]Training Epoch 65, LR 0.000836:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 65, LR 0.000836:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 65, LR 0.000836:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 65, LR 0.000836:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 65, LR 0.000836:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 65, LR 0.000836:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 65, LR 0.000836:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 65, LR 0.000836:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 65, LR 0.000836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.61batch/s]Training Epoch 65, LR 0.000836:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.05s/batch]Training Epoch 65, LR 0.000836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 65, LR 0.000836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 65:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 65:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.53s/batch]Evaluating Epoch 65:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 65:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [65/200]:, train_loss=0.053, 
train_confusionMatrix:
tensor([[78, 11],
        [22, 33]], device='cuda:0')
train_accuracy=0.7708333134651184, 
train_recall=0.6000000238418579, 
train_precision=0.75, 
train_specificity=0.8764045238494873, 
train_balance_acc=0.7382022738456726,
 train_f1_score=0.6666666865348816,
 train_auc=0.806333065032959

Epoch [65/200]:, eval_loss=0.019, 
eval_confusionMatrix:
tensor([[ 6, 16],
        [ 3,  7]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=0.699999988079071, 
eval_precision=0.30434781312942505, 
eval_specificity=0.27272728085517883, 
eval_balance_acc=0.48636364936828613,
 eval_f1_score=0.42424243688583374,
 eval_auc=0.44090908765792847


Epoch: 66/200
Training Epoch 66, LR 0.000823:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 66, LR 0.000823:   6%|â–Œ         | 1/18 [00:03<01:03,  3.74s/batch]Training Epoch 66, LR 0.000823:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 66, LR 0.000823:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 66, LR 0.000823:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 66, LR 0.000823:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:15,  1.23s/batch]Training Epoch 66, LR 0.000823:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.05batch/s]Training Epoch 66, LR 0.000823:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.30batch/s]Training Epoch 66, LR 0.000823:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.53batch/s]Training Epoch 66, LR 0.000823:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:09<00:09,  1.05s/batch]Training Epoch 66, LR 0.000823:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.17batch/s]Training Epoch 66, LR 0.000823:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.39batch/s]Training Epoch 66, LR 0.000823:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 66, LR 0.000823:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 66, LR 0.000823:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.19batch/s]Training Epoch 66, LR 0.000823:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:13<00:02,  1.41batch/s]Training Epoch 66, LR 0.000823:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 66, LR 0.000823:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.03batch/s]Training Epoch 66, LR 0.000823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.25batch/s]Training Epoch 66, LR 0.000823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.08batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 66:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 66:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.84s/batch]Evaluating Epoch 66:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.67s/batch]Evaluating Epoch 66:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.02batch/s]Evaluating Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.53batch/s]Evaluating Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.09s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [66/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[70, 20],
        [23, 31]], device='cuda:0')
train_accuracy=0.7013888955116272, 
train_recall=0.5740740895271301, 
train_precision=0.6078431606292725, 
train_specificity=0.7777777910232544, 
train_balance_acc=0.6759259700775146,
 train_f1_score=0.5904762148857117,
 train_auc=0.7555555701255798

Epoch [66/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[12,  8],
        [ 4,  8]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.6666666865348816, 
eval_precision=0.5, 
eval_specificity=0.6000000238418579, 
eval_balance_acc=0.6333333253860474,
 eval_f1_score=0.5714285969734192,
 eval_auc=0.625


Early stopping
Fold 2 Best Epoch: 16
Best confusionMatrix : tensor([[19,  1],
        [ 8,  4]], device='cuda:0')
Best accuracy : 0.71875, 
Best recall : 0.3333333432674408, 
Best precision : 0.800000011920929, 
Best specificity : 0.949999988079071, 
Best balance_acc : 0.6416666507720947,
 Best f1_score : 0.47058823704719543,
 Best AUC : 0.625


exp:AweSomeNet  seed -> 42
Fold 3/5
[DEBUG] Observer init successfully, program start @2025-04-07_21-44

The name of model will run <class 'Net.AweNet.AweSomeNet'>
Use model : {'Name': 'AweSomeNet', 'Model': <class 'Net.AweNet.AweSomeNet'>, 'dataset': <class 'Dataset.MriPetCliDataset'>, 'shape': (96, 128, 96), 'Loss': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'Optimizer': <class 'torch.optim.adam.Adam'>, 'Lr': 0.001, 'Run': <function run_main_for_awesome_net at 0x7f274773b790>, 'Scheduler': <function get_scheduler at 0x7f274c7ad670>}


===============================================

model parameters: 17357958

===============================================

Prepare completed for fold 3! Launch training!ðŸš€
start training
Epoch: 1/200
Training Epoch 1, LR 0.001000:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 1, LR 0.001000:   6%|â–Œ         | 1/18 [00:03<01:06,  3.93s/batch]Training Epoch 1, LR 0.001000:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 1, LR 0.001000:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 1, LR 0.001000:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 1, LR 0.001000:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 1, LR 0.001000:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 1, LR 0.001000:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.22batch/s]Training Epoch 1, LR 0.001000:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 1, LR 0.001000:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.11s/batch]Training Epoch 1, LR 0.001000:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 1, LR 0.001000:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 1, LR 0.001000:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 1, LR 0.001000:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 1, LR 0.001000:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.18batch/s]Training Epoch 1, LR 0.001000:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 1, LR 0.001000:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 1, LR 0.001000:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 1, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 1, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 1:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 1:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.42s/batch]Evaluating Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.50s/batch]Evaluating Epoch 1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.67batch/s]Evaluating Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [1/200]:, train_loss=0.068, 
train_confusionMatrix:
tensor([[84,  6],
        [50,  4]], device='cuda:0')
train_accuracy=0.6111111044883728, 
train_recall=0.07407407462596893, 
train_precision=0.4000000059604645, 
train_specificity=0.9333333373069763, 
train_balance_acc=0.5037037134170532,
 train_f1_score=0.125,
 train_auc=0.46069955825805664

Epoch [1/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 0, 20],
        [ 0, 12]], device='cuda:0')
eval_accuracy=0.375, 
eval_recall=1.0, 
eval_precision=0.375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5454545617103577,
 eval_auc=0.6666666865348816


Best model saved to ././checkpoints_2025-04-07_21-44/AweSomeNet_best_model_fold3.pth


Epoch: 2/200
Training Epoch 2, LR 0.000976:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 2, LR 0.000976:   6%|â–Œ         | 1/18 [00:03<01:04,  3.77s/batch]Training Epoch 2, LR 0.000976:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 2, LR 0.000976:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 2, LR 0.000976:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 2, LR 0.000976:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.24s/batch]Training Epoch 2, LR 0.000976:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.04batch/s]Training Epoch 2, LR 0.000976:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.29batch/s]Training Epoch 2, LR 0.000976:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 2, LR 0.000976:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.04s/batch]Training Epoch 2, LR 0.000976:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 2, LR 0.000976:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:04,  1.40batch/s]Training Epoch 2, LR 0.000976:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.61batch/s]Training Epoch 2, LR 0.000976:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.01batch/s]Training Epoch 2, LR 0.000976:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.23batch/s]Training Epoch 2, LR 0.000976:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:13<00:02,  1.45batch/s]Training Epoch 2, LR 0.000976:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.65batch/s]Training Epoch 2, LR 0.000976:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 2, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.19batch/s]Training Epoch 2, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.08batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 2:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 2:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [2/200]:, train_loss=0.067, 
train_confusionMatrix:
tensor([[89,  0],
        [55,  0]], device='cuda:0')
train_accuracy=0.6180555820465088, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=1.0, 
train_balance_acc=0.5,
 train_f1_score=0.0,
 train_auc=0.44576096534729004

Epoch [2/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[19,  0],
        [12,  1]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.07692307978868484, 
eval_precision=1.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5384615659713745,
 eval_f1_score=0.1428571492433548,
 eval_auc=0.52226722240448


Best model saved to ././checkpoints_2025-04-07_21-44/AweSomeNet_best_model_fold3.pth


Epoch: 3/200
Training Epoch 3, LR 0.000905:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 3, LR 0.000905:   6%|â–Œ         | 1/18 [00:04<01:09,  4.11s/batch]Training Epoch 3, LR 0.000905:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.93s/batch]Training Epoch 3, LR 0.000905:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.23s/batch]Training Epoch 3, LR 0.000905:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 3, LR 0.000905:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 3, LR 0.000905:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 3, LR 0.000905:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.25batch/s]Training Epoch 3, LR 0.000905:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 3, LR 0.000905:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.11s/batch]Training Epoch 3, LR 0.000905:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.12batch/s]Training Epoch 3, LR 0.000905:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 3, LR 0.000905:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 3, LR 0.000905:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 3, LR 0.000905:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 3, LR 0.000905:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 3, LR 0.000905:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.58batch/s]Training Epoch 3, LR 0.000905:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.06s/batch]Training Epoch 3, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 3, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 3:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 3:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.39s/batch]Evaluating Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.50s/batch]Evaluating Epoch 3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.68batch/s]Evaluating Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [3/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[89,  0],
        [55,  0]], device='cuda:0')
train_accuracy=0.6180555820465088, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=1.0, 
train_balance_acc=0.5,
 train_f1_score=0.0,
 train_auc=0.6200204491615295

Epoch [3/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 0, 21],
        [ 0, 11]], device='cuda:0')
eval_accuracy=0.34375, 
eval_recall=1.0, 
eval_precision=0.34375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5116279125213623,
 eval_auc=0.6406926512718201


Epoch: 4/200
Training Epoch 4, LR 0.000796:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 4, LR 0.000796:   6%|â–Œ         | 1/18 [00:03<01:04,  3.81s/batch]Training Epoch 4, LR 0.000796:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 4, LR 0.000796:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 4, LR 0.000796:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 4, LR 0.000796:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 4, LR 0.000796:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 4, LR 0.000796:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 4, LR 0.000796:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 4, LR 0.000796:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 4, LR 0.000796:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 4, LR 0.000796:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.37batch/s]Training Epoch 4, LR 0.000796:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 4, LR 0.000796:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 4, LR 0.000796:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.15batch/s]Training Epoch 4, LR 0.000796:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 4, LR 0.000796:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 4, LR 0.000796:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 4, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 4, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 4:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 4:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.49s/batch]Evaluating Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 4:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.65batch/s]Evaluating Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [4/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[91,  0],
        [53,  0]], device='cuda:0')
train_accuracy=0.6319444179534912, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=1.0, 
train_balance_acc=0.5,
 train_f1_score=0.0,
 train_auc=0.4891146421432495

Epoch [4/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[ 0, 19],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=1.0, 
eval_precision=0.40625, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5777778029441833,
 eval_auc=0.7165992259979248


Epoch: 5/200
Training Epoch 5, LR 0.000658:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 5, LR 0.000658:   6%|â–Œ         | 1/18 [00:03<01:04,  3.78s/batch]Training Epoch 5, LR 0.000658:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 5, LR 0.000658:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 5, LR 0.000658:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 5, LR 0.000658:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.31s/batch]Training Epoch 5, LR 0.000658:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.00batch/s]Training Epoch 5, LR 0.000658:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 5, LR 0.000658:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 5, LR 0.000658:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.15s/batch]Training Epoch 5, LR 0.000658:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.09batch/s]Training Epoch 5, LR 0.000658:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.31batch/s]Training Epoch 5, LR 0.000658:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 5, LR 0.000658:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 5, LR 0.000658:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 5, LR 0.000658:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 5, LR 0.000658:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 5, LR 0.000658:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 5, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.24batch/s]Training Epoch 5, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 5:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 5:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.78s/batch]Evaluating Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.65s/batch]Evaluating Epoch 5:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [5/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[91,  0],
        [53,  0]], device='cuda:0')
train_accuracy=0.6319444179534912, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=1.0, 
train_balance_acc=0.5,
 train_f1_score=0.0,
 train_auc=0.5382542014122009

Epoch [5/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[ 7, 11],
        [ 2, 12]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.8571428656578064, 
eval_precision=0.52173912525177, 
eval_specificity=0.3888888955116272, 
eval_balance_acc=0.6230158805847168,
 eval_f1_score=0.6486486196517944,
 eval_auc=0.6666666865348816


Epoch: 6/200
Training Epoch 6, LR 0.000505:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 6, LR 0.000505:   6%|â–Œ         | 1/18 [00:03<01:05,  3.84s/batch]Training Epoch 6, LR 0.000505:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 6, LR 0.000505:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 6, LR 0.000505:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 6, LR 0.000505:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 6, LR 0.000505:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 6, LR 0.000505:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 6, LR 0.000505:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 6, LR 0.000505:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.03s/batch]Training Epoch 6, LR 0.000505:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.19batch/s]Training Epoch 6, LR 0.000505:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:04,  1.41batch/s]Training Epoch 6, LR 0.000505:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.62batch/s]Training Epoch 6, LR 0.000505:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.02batch/s]Training Epoch 6, LR 0.000505:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.24batch/s]Training Epoch 6, LR 0.000505:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.45batch/s]Training Epoch 6, LR 0.000505:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.66batch/s]Training Epoch 6, LR 0.000505:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 6, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.23batch/s]Training Epoch 6, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.08batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 6:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 6:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.45s/batch]Evaluating Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.51s/batch]Evaluating Epoch 6:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.68batch/s]Evaluating Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [6/200]:, train_loss=0.066, 
train_confusionMatrix:
tensor([[89,  0],
        [55,  0]], device='cuda:0')
train_accuracy=0.6180555820465088, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=1.0, 
train_balance_acc=0.5,
 train_f1_score=0.0,
 train_auc=0.5440244674682617

Epoch [6/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[ 0, 19],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=1.0, 
eval_precision=0.40625, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5777778029441833,
 eval_auc=0.829959511756897


Epoch: 7/200
Training Epoch 7, LR 0.000352:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 7, LR 0.000352:   6%|â–Œ         | 1/18 [00:03<01:04,  3.78s/batch]Training Epoch 7, LR 0.000352:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 7, LR 0.000352:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 7, LR 0.000352:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 7, LR 0.000352:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:15,  1.22s/batch]Training Epoch 7, LR 0.000352:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.06batch/s]Training Epoch 7, LR 0.000352:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.30batch/s]Training Epoch 7, LR 0.000352:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.53batch/s]Training Epoch 7, LR 0.000352:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 7, LR 0.000352:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.16batch/s]Training Epoch 7, LR 0.000352:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.38batch/s]Training Epoch 7, LR 0.000352:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 7, LR 0.000352:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 7, LR 0.000352:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.14batch/s]Training Epoch 7, LR 0.000352:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 7, LR 0.000352:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 7, LR 0.000352:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.03s/batch]Training Epoch 7, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.19batch/s]Training Epoch 7, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 7:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 7:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 7:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [7/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[89,  0],
        [55,  0]], device='cuda:0')
train_accuracy=0.6180555820465088, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=1.0, 
train_balance_acc=0.5,
 train_f1_score=0.0,
 train_auc=0.6167517900466919

Epoch [7/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[ 0, 19],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=1.0, 
eval_precision=0.40625, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5777778029441833,
 eval_auc=0.7246963977813721


Epoch: 8/200
Training Epoch 8, LR 0.000214:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 8, LR 0.000214:   6%|â–Œ         | 1/18 [00:03<01:06,  3.89s/batch]Training Epoch 8, LR 0.000214:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 8, LR 0.000214:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 8, LR 0.000214:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 8, LR 0.000214:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 8, LR 0.000214:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 8, LR 0.000214:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 8, LR 0.000214:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 8, LR 0.000214:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 8, LR 0.000214:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 8, LR 0.000214:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 8, LR 0.000214:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 8, LR 0.000214:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 8, LR 0.000214:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 8, LR 0.000214:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.33batch/s]Training Epoch 8, LR 0.000214:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.54batch/s]Training Epoch 8, LR 0.000214:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 8, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 8, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 8:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 8:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.77s/batch]Evaluating Epoch 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.65s/batch]Evaluating Epoch 8:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [8/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[90,  0],
        [54,  0]], device='cuda:0')
train_accuracy=0.625, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=1.0, 
train_balance_acc=0.5,
 train_f1_score=0.0,
 train_auc=0.5637860298156738

Epoch [8/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.7666666507720947


Epoch: 9/200
Training Epoch 9, LR 0.000105:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 9, LR 0.000105:   6%|â–Œ         | 1/18 [00:03<01:04,  3.81s/batch]Training Epoch 9, LR 0.000105:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.81s/batch]Training Epoch 9, LR 0.000105:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 9, LR 0.000105:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 9, LR 0.000105:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 9, LR 0.000105:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 9, LR 0.000105:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 9, LR 0.000105:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 9, LR 0.000105:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 9, LR 0.000105:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.11batch/s]Training Epoch 9, LR 0.000105:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 9, LR 0.000105:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 9, LR 0.000105:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 9, LR 0.000105:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.17batch/s]Training Epoch 9, LR 0.000105:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 9, LR 0.000105:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 9, LR 0.000105:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.12s/batch]Training Epoch 9, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.11batch/s]Training Epoch 9, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 9:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 9:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.66s/batch]Evaluating Epoch 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.60s/batch]Evaluating Epoch 9:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.06batch/s]Evaluating Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.59batch/s]Evaluating Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [9/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[90,  0],
        [54,  0]], device='cuda:0')
train_accuracy=0.625, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=1.0, 
train_balance_acc=0.5,
 train_f1_score=0.0,
 train_auc=0.5238683223724365

Epoch [9/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[19,  0],
        [13,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.785425066947937


Epoch: 10/200
Training Epoch 10, LR 0.000034:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 10, LR 0.000034:   6%|â–Œ         | 1/18 [00:03<01:04,  3.77s/batch]Training Epoch 10, LR 0.000034:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 10, LR 0.000034:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 10, LR 0.000034:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 10, LR 0.000034:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.28s/batch]Training Epoch 10, LR 0.000034:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 10, LR 0.000034:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 10, LR 0.000034:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 10, LR 0.000034:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.15s/batch]Training Epoch 10, LR 0.000034:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.09batch/s]Training Epoch 10, LR 0.000034:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.31batch/s]Training Epoch 10, LR 0.000034:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.52batch/s]Training Epoch 10, LR 0.000034:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 10, LR 0.000034:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.16batch/s]Training Epoch 10, LR 0.000034:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 10, LR 0.000034:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 10, LR 0.000034:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 10, LR 0.000034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 10, LR 0.000034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 10:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 10:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.53s/batch]Evaluating Epoch 10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [10/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[91,  0],
        [53,  0]], device='cuda:0')
train_accuracy=0.6319444179534912, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=1.0, 
train_balance_acc=0.5,
 train_f1_score=0.0,
 train_auc=0.6591333150863647

Epoch [10/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[18,  0],
        [14,  0]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.8571428656578064


Epoch: 11/200
Training Epoch 11, LR 0.001000:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 11, LR 0.001000:   6%|â–Œ         | 1/18 [00:03<01:06,  3.93s/batch]Training Epoch 11, LR 0.001000:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.86s/batch]Training Epoch 11, LR 0.001000:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 11, LR 0.001000:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 11, LR 0.001000:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.31s/batch]Training Epoch 11, LR 0.001000:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.00batch/s]Training Epoch 11, LR 0.001000:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.24batch/s]Training Epoch 11, LR 0.001000:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 11, LR 0.001000:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.05s/batch]Training Epoch 11, LR 0.001000:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.17batch/s]Training Epoch 11, LR 0.001000:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.39batch/s]Training Epoch 11, LR 0.001000:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 11, LR 0.001000:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 11, LR 0.001000:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 11, LR 0.001000:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.33batch/s]Training Epoch 11, LR 0.001000:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.54batch/s]Training Epoch 11, LR 0.001000:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 11, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 11, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 11:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 11:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.77s/batch]Evaluating Epoch 11:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.64s/batch]Evaluating Epoch 11:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [11/200]:, train_loss=0.066, 
train_confusionMatrix:
tensor([[85,  4],
        [54,  1]], device='cuda:0')
train_accuracy=0.5972222089767456, 
train_recall=0.0181818176060915, 
train_precision=0.20000000298023224, 
train_specificity=0.9550561904907227, 
train_balance_acc=0.4866189956665039,
 train_f1_score=0.03333333507180214,
 train_auc=0.5074565410614014

Epoch [11/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[19,  0],
        [13,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.43319839239120483


Epoch: 12/200
Training Epoch 12, LR 0.000997:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 12, LR 0.000997:   6%|â–Œ         | 1/18 [00:04<01:08,  4.04s/batch]Training Epoch 12, LR 0.000997:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.90s/batch]Training Epoch 12, LR 0.000997:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.22s/batch]Training Epoch 12, LR 0.000997:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 12, LR 0.000997:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.31s/batch]Training Epoch 12, LR 0.000997:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.00batch/s]Training Epoch 12, LR 0.000997:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.24batch/s]Training Epoch 12, LR 0.000997:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 12, LR 0.000997:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 12, LR 0.000997:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.10batch/s]Training Epoch 12, LR 0.000997:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 12, LR 0.000997:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 12, LR 0.000997:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 12, LR 0.000997:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 12, LR 0.000997:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 12, LR 0.000997:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 12, LR 0.000997:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 12, LR 0.000997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 12, LR 0.000997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 12:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 12:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.57s/batch]Evaluating Epoch 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 12:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [12/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[89,  1],
        [50,  4]], device='cuda:0')
train_accuracy=0.6458333134651184, 
train_recall=0.07407407462596893, 
train_precision=0.800000011920929, 
train_specificity=0.9888888597488403, 
train_balance_acc=0.5314814448356628,
 train_f1_score=0.1355932205915451,
 train_auc=0.5329217910766602

Epoch [12/200]:, eval_loss=0.020, 
eval_confusionMatrix:
tensor([[ 0, 19],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=1.0, 
eval_precision=0.40625, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5777778029441833,
 eval_auc=0.4898785352706909


Epoch: 13/200
Training Epoch 13, LR 0.000989:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 13, LR 0.000989:   6%|â–Œ         | 1/18 [00:04<01:09,  4.06s/batch]Training Epoch 13, LR 0.000989:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.91s/batch]Training Epoch 13, LR 0.000989:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.23s/batch]Training Epoch 13, LR 0.000989:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 13, LR 0.000989:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 13, LR 0.000989:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 13, LR 0.000989:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.25batch/s]Training Epoch 13, LR 0.000989:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 13, LR 0.000989:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 13, LR 0.000989:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 13, LR 0.000989:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 13, LR 0.000989:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 13, LR 0.000989:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 13, LR 0.000989:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.20batch/s]Training Epoch 13, LR 0.000989:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.42batch/s]Training Epoch 13, LR 0.000989:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 13, LR 0.000989:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 13, LR 0.000989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 13, LR 0.000989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 13:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 13:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.76s/batch]Evaluating Epoch 13:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.64s/batch]Evaluating Epoch 13:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [13/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[88,  2],
        [52,  2]], device='cuda:0')
train_accuracy=0.625, 
train_recall=0.03703703731298447, 
train_precision=0.5, 
train_specificity=0.9777777791023254, 
train_balance_acc=0.5074074268341064,
 train_f1_score=0.06896551698446274,
 train_auc=0.557201623916626

Epoch [13/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[ 0, 18],
        [ 0, 14]], device='cuda:0')
eval_accuracy=0.4375, 
eval_recall=1.0, 
eval_precision=0.4375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.6086956262588501,
 eval_auc=0.5555555820465088


Epoch: 14/200
Training Epoch 14, LR 0.000976:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 14, LR 0.000976:   6%|â–Œ         | 1/18 [00:03<01:03,  3.76s/batch]Training Epoch 14, LR 0.000976:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 14, LR 0.000976:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 14, LR 0.000976:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 14, LR 0.000976:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.26s/batch]Training Epoch 14, LR 0.000976:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 14, LR 0.000976:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 14, LR 0.000976:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 14, LR 0.000976:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 14, LR 0.000976:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.02batch/s]Training Epoch 14, LR 0.000976:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.24batch/s]Training Epoch 14, LR 0.000976:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:04,  1.46batch/s]Training Epoch 14, LR 0.000976:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.08batch/s]Training Epoch 14, LR 0.000976:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 14, LR 0.000976:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 14, LR 0.000976:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 14, LR 0.000976:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.14batch/s]Training Epoch 14, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.15batch/s]Training Epoch 14, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 14:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 14:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.55s/batch]Evaluating Epoch 14:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 14:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [14/200]:, train_loss=0.064, 
train_confusionMatrix:
tensor([[90,  1],
        [53,  0]], device='cuda:0')
train_accuracy=0.625, 
train_recall=0.0, 
train_precision=0.0, 
train_specificity=0.9890109896659851, 
train_balance_acc=0.49450549483299255,
 train_f1_score=0.0,
 train_auc=0.61600661277771

Epoch [14/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.40416666865348816


Epoch: 15/200
Training Epoch 15, LR 0.000957:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 15, LR 0.000957:   6%|â–Œ         | 1/18 [00:03<01:07,  3.96s/batch]Training Epoch 15, LR 0.000957:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.88s/batch]Training Epoch 15, LR 0.000957:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 15, LR 0.000957:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 15, LR 0.000957:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 15, LR 0.000957:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 15, LR 0.000957:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.24batch/s]Training Epoch 15, LR 0.000957:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 15, LR 0.000957:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.06s/batch]Training Epoch 15, LR 0.000957:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.16batch/s]Training Epoch 15, LR 0.000957:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.38batch/s]Training Epoch 15, LR 0.000957:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 15, LR 0.000957:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.02batch/s]Training Epoch 15, LR 0.000957:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.23batch/s]Training Epoch 15, LR 0.000957:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.45batch/s]Training Epoch 15, LR 0.000957:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.66batch/s]Training Epoch 15, LR 0.000957:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 15, LR 0.000957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.23batch/s]Training Epoch 15, LR 0.000957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 15:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 15:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.60s/batch]Evaluating Epoch 15:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 15:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [15/200]:, train_loss=0.064, 
train_confusionMatrix:
tensor([[86,  3],
        [52,  3]], device='cuda:0')
train_accuracy=0.6180555820465088, 
train_recall=0.05454545468091965, 
train_precision=0.5, 
train_specificity=0.966292142868042, 
train_balance_acc=0.5104187726974487,
 train_f1_score=0.09836065769195557,
 train_auc=0.6151174306869507

Epoch [15/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.5458333492279053


Epoch: 16/200
Training Epoch 16, LR 0.000934:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 16, LR 0.000934:   6%|â–Œ         | 1/18 [00:03<01:03,  3.71s/batch]Training Epoch 16, LR 0.000934:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.77s/batch]Training Epoch 16, LR 0.000934:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 16, LR 0.000934:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.17batch/s]Training Epoch 16, LR 0.000934:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 16, LR 0.000934:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 16, LR 0.000934:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 16, LR 0.000934:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 16, LR 0.000934:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 16, LR 0.000934:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.14batch/s]Training Epoch 16, LR 0.000934:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 16, LR 0.000934:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 16, LR 0.000934:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 16, LR 0.000934:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 16, LR 0.000934:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 16, LR 0.000934:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.61batch/s]Training Epoch 16, LR 0.000934:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 16, LR 0.000934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 16, LR 0.000934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 16:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 16:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.55s/batch]Evaluating Epoch 16:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 16:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [16/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[85,  5],
        [47,  7]], device='cuda:0')
train_accuracy=0.6388888955116272, 
train_recall=0.12962962687015533, 
train_precision=0.5833333134651184, 
train_specificity=0.9444444179534912, 
train_balance_acc=0.5370370149612427,
 train_f1_score=0.21212121844291687,
 train_auc=0.6851851940155029

Epoch [16/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[ 0, 21],
        [ 0, 11]], device='cuda:0')
eval_accuracy=0.34375, 
eval_recall=1.0, 
eval_precision=0.34375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5116279125213623,
 eval_auc=0.42424240708351135


Epoch: 17/200
Training Epoch 17, LR 0.000905:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 17, LR 0.000905:   6%|â–Œ         | 1/18 [00:04<01:09,  4.08s/batch]Training Epoch 17, LR 0.000905:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.92s/batch]Training Epoch 17, LR 0.000905:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.23s/batch]Training Epoch 17, LR 0.000905:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 17, LR 0.000905:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 17, LR 0.000905:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 17, LR 0.000905:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 17, LR 0.000905:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 17, LR 0.000905:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 17, LR 0.000905:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.11batch/s]Training Epoch 17, LR 0.000905:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 17, LR 0.000905:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 17, LR 0.000905:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 17, LR 0.000905:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.17batch/s]Training Epoch 17, LR 0.000905:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 17, LR 0.000905:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.59batch/s]Training Epoch 17, LR 0.000905:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.00s/batch]Training Epoch 17, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.22batch/s]Training Epoch 17, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 17:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 17:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 17:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 17:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [17/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[80, 11],
        [38, 15]], device='cuda:0')
train_accuracy=0.6597222089767456, 
train_recall=0.2830188572406769, 
train_precision=0.5769230723381042, 
train_specificity=0.8791208863258362, 
train_balance_acc=0.5810698866844177,
 train_f1_score=0.37974682450294495,
 train_auc=0.6187020540237427

Epoch [17/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[18,  1],
        [11,  2]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.1538461595773697, 
eval_precision=0.6666666865348816, 
eval_specificity=0.9473684430122375, 
eval_balance_acc=0.5506073236465454,
 eval_f1_score=0.25,
 eval_auc=0.4736842215061188


Epoch: 18/200
Training Epoch 18, LR 0.000873:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 18, LR 0.000873:   6%|â–Œ         | 1/18 [00:03<01:04,  3.77s/batch]Training Epoch 18, LR 0.000873:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 18, LR 0.000873:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 18, LR 0.000873:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 18, LR 0.000873:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 18, LR 0.000873:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 18, LR 0.000873:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 18, LR 0.000873:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 18, LR 0.000873:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 18, LR 0.000873:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 18, LR 0.000873:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 18, LR 0.000873:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 18, LR 0.000873:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 18, LR 0.000873:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 18, LR 0.000873:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 18, LR 0.000873:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 18, LR 0.000873:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 18, LR 0.000873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 18, LR 0.000873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 18:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 18:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.48s/batch]Evaluating Epoch 18:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.52s/batch]Evaluating Epoch 18:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.66batch/s]Evaluating Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [18/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[78, 12],
        [38, 16]], device='cuda:0')
train_accuracy=0.6527777910232544, 
train_recall=0.29629629850387573, 
train_precision=0.5714285969734192, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.5814814567565918,
 train_f1_score=0.39024388790130615,
 train_auc=0.6716049313545227

Epoch [18/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[19,  0],
        [13,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.39676111936569214


Epoch: 19/200
Training Epoch 19, LR 0.000836:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 19, LR 0.000836:   6%|â–Œ         | 1/18 [00:03<01:03,  3.73s/batch]Training Epoch 19, LR 0.000836:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 19, LR 0.000836:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 19, LR 0.000836:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 19, LR 0.000836:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.28s/batch]Training Epoch 19, LR 0.000836:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 19, LR 0.000836:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 19, LR 0.000836:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 19, LR 0.000836:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 19, LR 0.000836:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 19, LR 0.000836:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.37batch/s]Training Epoch 19, LR 0.000836:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.59batch/s]Training Epoch 19, LR 0.000836:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 19, LR 0.000836:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.14batch/s]Training Epoch 19, LR 0.000836:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 19, LR 0.000836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 19, LR 0.000836:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.00s/batch]Training Epoch 19, LR 0.000836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.22batch/s]Training Epoch 19, LR 0.000836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 19:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 19:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.44s/batch]Evaluating Epoch 19:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.51s/batch]Evaluating Epoch 19:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.66batch/s]Evaluating Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [19/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[76, 13],
        [36, 19]], device='cuda:0')
train_accuracy=0.6597222089767456, 
train_recall=0.34545454382896423, 
train_precision=0.59375, 
train_specificity=0.8539325594902039, 
train_balance_acc=0.5996935367584229,
 train_f1_score=0.4367816150188446,
 train_auc=0.6224719285964966

Epoch [19/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[22,  0],
        [10,  0]], device='cuda:0')
eval_accuracy=0.6875, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.2863636314868927


Best model saved to ././checkpoints_2025-04-07_21-44/AweSomeNet_best_model_fold3.pth


Epoch: 20/200
Training Epoch 20, LR 0.000796:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 20, LR 0.000796:   6%|â–Œ         | 1/18 [00:03<01:05,  3.83s/batch]Training Epoch 20, LR 0.000796:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 20, LR 0.000796:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 20, LR 0.000796:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 20, LR 0.000796:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 20, LR 0.000796:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 20, LR 0.000796:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.23batch/s]Training Epoch 20, LR 0.000796:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 20, LR 0.000796:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.19s/batch]Training Epoch 20, LR 0.000796:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.06batch/s]Training Epoch 20, LR 0.000796:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.28batch/s]Training Epoch 20, LR 0.000796:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:04,  1.49batch/s]Training Epoch 20, LR 0.000796:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 20, LR 0.000796:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.16batch/s]Training Epoch 20, LR 0.000796:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 20, LR 0.000796:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.58batch/s]Training Epoch 20, LR 0.000796:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.03s/batch]Training Epoch 20, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 20, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 20:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 20:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 20:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 20:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [20/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[71, 18],
        [39, 16]], device='cuda:0')
train_accuracy=0.6041666865348816, 
train_recall=0.290909081697464, 
train_precision=0.47058823704719543, 
train_specificity=0.7977527976036072, 
train_balance_acc=0.5443309545516968,
 train_f1_score=0.3595505654811859,
 train_auc=0.6206332445144653

Epoch [20/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[ 5, 15],
        [ 1, 11]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.9166666865348816, 
eval_precision=0.42307692766189575, 
eval_specificity=0.25, 
eval_balance_acc=0.5833333730697632,
 eval_f1_score=0.5789473652839661,
 eval_auc=0.625


Epoch: 21/200
Training Epoch 21, LR 0.000753:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 21, LR 0.000753:   6%|â–Œ         | 1/18 [00:03<01:05,  3.88s/batch]Training Epoch 21, LR 0.000753:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 21, LR 0.000753:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 21, LR 0.000753:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 21, LR 0.000753:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 21, LR 0.000753:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 21, LR 0.000753:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.22batch/s]Training Epoch 21, LR 0.000753:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 21, LR 0.000753:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.18s/batch]Training Epoch 21, LR 0.000753:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.06batch/s]Training Epoch 21, LR 0.000753:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.29batch/s]Training Epoch 21, LR 0.000753:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.50batch/s]Training Epoch 21, LR 0.000753:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 21, LR 0.000753:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.17batch/s]Training Epoch 21, LR 0.000753:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 21, LR 0.000753:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.60batch/s]Training Epoch 21, LR 0.000753:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 21, LR 0.000753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.23batch/s]Training Epoch 21, LR 0.000753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 21:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 21:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.41s/batch]Evaluating Epoch 21:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:02,  1.50s/batch]Evaluating Epoch 21:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.68batch/s]Evaluating Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [21/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[70, 20],
        [33, 21]], device='cuda:0')
train_accuracy=0.6319444179534912, 
train_recall=0.3888888955116272, 
train_precision=0.5121951103210449, 
train_specificity=0.7777777910232544, 
train_balance_acc=0.5833333730697632,
 train_f1_score=0.4421052634716034,
 train_auc=0.65390944480896

Epoch [21/200]:, eval_loss=0.012, 
eval_confusionMatrix:
tensor([[15,  5],
        [ 5,  7]], device='cuda:0')
eval_accuracy=0.6875, 
eval_recall=0.5833333134651184, 
eval_precision=0.5833333134651184, 
eval_specificity=0.75, 
eval_balance_acc=0.6666666269302368,
 eval_f1_score=0.5833333134651184,
 eval_auc=0.7875000238418579


Epoch: 22/200
Training Epoch 22, LR 0.000706:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 22, LR 0.000706:   6%|â–Œ         | 1/18 [00:03<01:05,  3.85s/batch]Training Epoch 22, LR 0.000706:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 22, LR 0.000706:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 22, LR 0.000706:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 22, LR 0.000706:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 22, LR 0.000706:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 22, LR 0.000706:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 22, LR 0.000706:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 22, LR 0.000706:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 22, LR 0.000706:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 22, LR 0.000706:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 22, LR 0.000706:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 22, LR 0.000706:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 22, LR 0.000706:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 22, LR 0.000706:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 22, LR 0.000706:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 22, LR 0.000706:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 22, LR 0.000706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 22, LR 0.000706: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 22:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 22:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.60s/batch]Evaluating Epoch 22:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 22:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [22/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[69, 21],
        [32, 22]], device='cuda:0')
train_accuracy=0.6319444179534912, 
train_recall=0.40740740299224854, 
train_precision=0.5116279125213623, 
train_specificity=0.7666666507720947, 
train_balance_acc=0.5870370268821716,
 train_f1_score=0.4536082446575165,
 train_auc=0.6491769552230835

Epoch [22/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[18,  0],
        [14,  0]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.460317462682724


Epoch: 23/200
Training Epoch 23, LR 0.000658:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 23, LR 0.000658:   6%|â–Œ         | 1/18 [00:04<01:08,  4.06s/batch]Training Epoch 23, LR 0.000658:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.91s/batch]Training Epoch 23, LR 0.000658:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.22s/batch]Training Epoch 23, LR 0.000658:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.11batch/s]Training Epoch 23, LR 0.000658:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.36s/batch]Training Epoch 23, LR 0.000658:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 23, LR 0.000658:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 23, LR 0.000658:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 23, LR 0.000658:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 23, LR 0.000658:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.11batch/s]Training Epoch 23, LR 0.000658:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 23, LR 0.000658:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 23, LR 0.000658:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.13s/batch]Training Epoch 23, LR 0.000658:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.10batch/s]Training Epoch 23, LR 0.000658:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:15<00:02,  1.32batch/s]Training Epoch 23, LR 0.000658:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.53batch/s]Training Epoch 23, LR 0.000658:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.06s/batch]Training Epoch 23, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 23, LR 0.000658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 23:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 23:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 23:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 23:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [23/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[70, 19],
        [29, 26]], device='cuda:0')
train_accuracy=0.6666666865348816, 
train_recall=0.4727272689342499, 
train_precision=0.5777778029441833, 
train_specificity=0.7865168452262878, 
train_balance_acc=0.6296220421791077,
 train_f1_score=0.5199999809265137,
 train_auc=0.726659893989563

Epoch [23/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[ 0, 19],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=1.0, 
eval_precision=0.40625, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5777778029441833,
 eval_auc=0.647773265838623


Epoch: 24/200
Training Epoch 24, LR 0.000608:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 24, LR 0.000608:   6%|â–Œ         | 1/18 [00:03<01:06,  3.91s/batch]Training Epoch 24, LR 0.000608:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 24, LR 0.000608:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 24, LR 0.000608:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 24, LR 0.000608:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 24, LR 0.000608:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.00batch/s]Training Epoch 24, LR 0.000608:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 24, LR 0.000608:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 24, LR 0.000608:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 24, LR 0.000608:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.11batch/s]Training Epoch 24, LR 0.000608:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 24, LR 0.000608:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 24, LR 0.000608:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 24, LR 0.000608:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.18batch/s]Training Epoch 24, LR 0.000608:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 24, LR 0.000608:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 24, LR 0.000608:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.03batch/s]Training Epoch 24, LR 0.000608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.25batch/s]Training Epoch 24, LR 0.000608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 24:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 24:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.47s/batch]Evaluating Epoch 24:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.52s/batch]Evaluating Epoch 24:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.68batch/s]Evaluating Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [24/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[67, 23],
        [29, 25]], device='cuda:0')
train_accuracy=0.6388888955116272, 
train_recall=0.46296295523643494, 
train_precision=0.5208333134651184, 
train_specificity=0.7444444298744202, 
train_balance_acc=0.6037036776542664,
 train_f1_score=0.4901960790157318,
 train_auc=0.6565843820571899

Epoch [24/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[20,  0],
        [10,  2]], device='cuda:0')
eval_accuracy=0.6875, 
eval_recall=0.1666666716337204, 
eval_precision=1.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5833333134651184,
 eval_f1_score=0.2857142984867096,
 eval_auc=0.6708333492279053


Epoch: 25/200
Training Epoch 25, LR 0.000557:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 25, LR 0.000557:   6%|â–Œ         | 1/18 [00:03<01:02,  3.68s/batch]Training Epoch 25, LR 0.000557:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.75s/batch]Training Epoch 25, LR 0.000557:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.14s/batch]Training Epoch 25, LR 0.000557:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.18batch/s]Training Epoch 25, LR 0.000557:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.26s/batch]Training Epoch 25, LR 0.000557:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 25, LR 0.000557:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 25, LR 0.000557:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 25, LR 0.000557:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.11s/batch]Training Epoch 25, LR 0.000557:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 25, LR 0.000557:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 25, LR 0.000557:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 25, LR 0.000557:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 25, LR 0.000557:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.15batch/s]Training Epoch 25, LR 0.000557:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 25, LR 0.000557:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 25, LR 0.000557:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.05s/batch]Training Epoch 25, LR 0.000557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 25, LR 0.000557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 25:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 25:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.60s/batch]Evaluating Epoch 25:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 25:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [25/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[71, 18],
        [25, 30]], device='cuda:0')
train_accuracy=0.7013888955116272, 
train_recall=0.5454545617103577, 
train_precision=0.625, 
train_specificity=0.7977527976036072, 
train_balance_acc=0.6716036796569824,
 train_f1_score=0.582524299621582,
 train_auc=0.737487256526947

Epoch [25/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[10, 10],
        [ 3,  9]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.75, 
eval_precision=0.4736842215061188, 
eval_specificity=0.5, 
eval_balance_acc=0.625,
 eval_f1_score=0.5806451439857483,
 eval_auc=0.6208333373069763


Epoch: 26/200
Training Epoch 26, LR 0.000505:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 26, LR 0.000505:   6%|â–Œ         | 1/18 [00:03<01:03,  3.71s/batch]Training Epoch 26, LR 0.000505:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.77s/batch]Training Epoch 26, LR 0.000505:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 26, LR 0.000505:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.17batch/s]Training Epoch 26, LR 0.000505:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.26s/batch]Training Epoch 26, LR 0.000505:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 26, LR 0.000505:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 26, LR 0.000505:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 26, LR 0.000505:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 26, LR 0.000505:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 26, LR 0.000505:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.36batch/s]Training Epoch 26, LR 0.000505:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 26, LR 0.000505:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 26, LR 0.000505:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.16batch/s]Training Epoch 26, LR 0.000505:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 26, LR 0.000505:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 26, LR 0.000505:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 26, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 26, LR 0.000505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 26:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 26:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.47s/batch]Evaluating Epoch 26:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.52s/batch]Evaluating Epoch 26:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.66batch/s]Evaluating Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [26/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[65, 24],
        [23, 32]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.581818163394928, 
train_precision=0.5714285969734192, 
train_specificity=0.7303370833396912, 
train_balance_acc=0.6560776233673096,
 train_f1_score=0.5765765905380249,
 train_auc=0.7005106806755066

Epoch [26/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 4, 15],
        [ 5,  8]], device='cuda:0')
eval_accuracy=0.375, 
eval_recall=0.6153846383094788, 
eval_precision=0.3478260934352875, 
eval_specificity=0.21052631735801697, 
eval_balance_acc=0.41295546293258667,
 eval_f1_score=0.4444444477558136,
 eval_auc=0.3117408752441406


Epoch: 27/200
Training Epoch 27, LR 0.000453:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 27, LR 0.000453:   6%|â–Œ         | 1/18 [00:03<01:04,  3.82s/batch]Training Epoch 27, LR 0.000453:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 27, LR 0.000453:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 27, LR 0.000453:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 27, LR 0.000453:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 27, LR 0.000453:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 27, LR 0.000453:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 27, LR 0.000453:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 27, LR 0.000453:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 27, LR 0.000453:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 27, LR 0.000453:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 27, LR 0.000453:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 27, LR 0.000453:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.09s/batch]Training Epoch 27, LR 0.000453:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 27, LR 0.000453:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 27, LR 0.000453:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.56batch/s]Training Epoch 27, LR 0.000453:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 27, LR 0.000453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 27, LR 0.000453: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 27:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 27:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.47s/batch]Evaluating Epoch 27:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 27:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [27/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[77, 14],
        [25, 28]], device='cuda:0')
train_accuracy=0.7291666865348816, 
train_recall=0.5283018946647644, 
train_precision=0.6666666865348816, 
train_specificity=0.8461538553237915, 
train_balance_acc=0.6872278451919556,
 train_f1_score=0.5894736647605896,
 train_auc=0.7422766089439392

Epoch [27/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  1],
        [11,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.9523809552192688, 
eval_balance_acc=0.4761904776096344,
 eval_f1_score=0.0,
 eval_auc=0.4588744640350342


Epoch: 28/200
Training Epoch 28, LR 0.000402:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 28, LR 0.000402:   6%|â–Œ         | 1/18 [00:03<01:06,  3.93s/batch]Training Epoch 28, LR 0.000402:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 28, LR 0.000402:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 28, LR 0.000402:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 28, LR 0.000402:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.26s/batch]Training Epoch 28, LR 0.000402:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 28, LR 0.000402:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 28, LR 0.000402:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 28, LR 0.000402:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 28, LR 0.000402:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 28, LR 0.000402:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 28, LR 0.000402:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 28, LR 0.000402:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 28, LR 0.000402:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 28, LR 0.000402:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 28, LR 0.000402:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 28, LR 0.000402:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.05s/batch]Training Epoch 28, LR 0.000402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 28, LR 0.000402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 28:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 28:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.64s/batch]Evaluating Epoch 28:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.59s/batch]Evaluating Epoch 28:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [28/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[77, 14],
        [29, 24]], device='cuda:0')
train_accuracy=0.7013888955116272, 
train_recall=0.4528301954269409, 
train_precision=0.6315789222717285, 
train_specificity=0.8461538553237915, 
train_balance_acc=0.6494920253753662,
 train_f1_score=0.5274725556373596,
 train_auc=0.7317022085189819

Epoch [28/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[17,  3],
        [10,  2]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.1666666716337204, 
eval_precision=0.4000000059604645, 
eval_specificity=0.8500000238418579, 
eval_balance_acc=0.5083333253860474,
 eval_f1_score=0.23529411852359772,
 eval_auc=0.5249999761581421


Epoch: 29/200
Training Epoch 29, LR 0.000352:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 29, LR 0.000352:   6%|â–Œ         | 1/18 [00:03<01:04,  3.81s/batch]Training Epoch 29, LR 0.000352:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.81s/batch]Training Epoch 29, LR 0.000352:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 29, LR 0.000352:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 29, LR 0.000352:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.28s/batch]Training Epoch 29, LR 0.000352:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 29, LR 0.000352:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 29, LR 0.000352:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 29, LR 0.000352:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 29, LR 0.000352:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 29, LR 0.000352:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 29, LR 0.000352:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 29, LR 0.000352:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 29, LR 0.000352:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.16batch/s]Training Epoch 29, LR 0.000352:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 29, LR 0.000352:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 29, LR 0.000352:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 29, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 29, LR 0.000352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 29:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 29:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.67s/batch]Evaluating Epoch 29:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.61s/batch]Evaluating Epoch 29:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.06batch/s]Evaluating Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [29/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[70, 19],
        [22, 33]], device='cuda:0')
train_accuracy=0.7152777910232544, 
train_recall=0.6000000238418579, 
train_precision=0.6346153616905212, 
train_specificity=0.7865168452262878, 
train_balance_acc=0.6932584047317505,
 train_f1_score=0.6168224215507507,
 train_auc=0.7859039306640625

Epoch [29/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[13,  8],
        [ 9,  2]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=0.1818181872367859, 
eval_precision=0.20000000298023224, 
eval_specificity=0.6190476417541504, 
eval_balance_acc=0.40043291449546814,
 eval_f1_score=0.190476194024086,
 eval_auc=0.40692639350891113


Epoch: 30/200
Training Epoch 30, LR 0.000304:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 30, LR 0.000304:   6%|â–Œ         | 1/18 [00:03<01:07,  3.95s/batch]Training Epoch 30, LR 0.000304:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.86s/batch]Training Epoch 30, LR 0.000304:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.20s/batch]Training Epoch 30, LR 0.000304:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 30, LR 0.000304:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.37s/batch]Training Epoch 30, LR 0.000304:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.05s/batch]Training Epoch 30, LR 0.000304:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 30, LR 0.000304:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.43batch/s]Training Epoch 30, LR 0.000304:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.16s/batch]Training Epoch 30, LR 0.000304:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.08batch/s]Training Epoch 30, LR 0.000304:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.29batch/s]Training Epoch 30, LR 0.000304:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.51batch/s]Training Epoch 30, LR 0.000304:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 30, LR 0.000304:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.20batch/s]Training Epoch 30, LR 0.000304:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.42batch/s]Training Epoch 30, LR 0.000304:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.62batch/s]Training Epoch 30, LR 0.000304:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.03batch/s]Training Epoch 30, LR 0.000304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.25batch/s]Training Epoch 30, LR 0.000304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 30:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 30:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.75s/batch]Evaluating Epoch 30:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.64s/batch]Evaluating Epoch 30:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [30/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[69, 22],
        [25, 28]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.5283018946647644, 
train_precision=0.5600000023841858, 
train_specificity=0.7582417726516724, 
train_balance_acc=0.643271803855896,
 train_f1_score=0.5436893105506897,
 train_auc=0.719883918762207

Epoch [30/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[ 6, 14],
        [ 3,  9]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=0.75, 
eval_precision=0.3913043439388275, 
eval_specificity=0.30000001192092896, 
eval_balance_acc=0.5249999761581421,
 eval_f1_score=0.5142857432365417,
 eval_auc=0.612500011920929


Epoch: 31/200
Training Epoch 31, LR 0.000258:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 31, LR 0.000258:   6%|â–Œ         | 1/18 [00:04<01:09,  4.09s/batch]Training Epoch 31, LR 0.000258:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.94s/batch]Training Epoch 31, LR 0.000258:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.24s/batch]Training Epoch 31, LR 0.000258:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.10batch/s]Training Epoch 31, LR 0.000258:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 31, LR 0.000258:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 31, LR 0.000258:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 31, LR 0.000258:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 31, LR 0.000258:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.14s/batch]Training Epoch 31, LR 0.000258:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.10batch/s]Training Epoch 31, LR 0.000258:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 31, LR 0.000258:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.53batch/s]Training Epoch 31, LR 0.000258:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.08s/batch]Training Epoch 31, LR 0.000258:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 31, LR 0.000258:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 31, LR 0.000258:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 31, LR 0.000258:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.02s/batch]Training Epoch 31, LR 0.000258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 31, LR 0.000258: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 31:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 31:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.63s/batch]Evaluating Epoch 31:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 31:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [31/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[67, 23],
        [27, 27]], device='cuda:0')
train_accuracy=0.6527777910232544, 
train_recall=0.5, 
train_precision=0.5400000214576721, 
train_specificity=0.7444444298744202, 
train_balance_acc=0.6222221851348877,
 train_f1_score=0.5192307829856873,
 train_auc=0.6899176836013794

Epoch [31/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[ 9, 10],
        [ 6,  7]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.5384615659713745, 
eval_precision=0.4117647111415863, 
eval_specificity=0.4736842215061188, 
eval_balance_acc=0.5060728788375854,
 eval_f1_score=0.46666666865348816,
 eval_auc=0.5020242929458618


Epoch: 32/200
Training Epoch 32, LR 0.000214:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 32, LR 0.000214:   6%|â–Œ         | 1/18 [00:03<01:07,  3.98s/batch]Training Epoch 32, LR 0.000214:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.88s/batch]Training Epoch 32, LR 0.000214:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 32, LR 0.000214:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 32, LR 0.000214:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.31s/batch]Training Epoch 32, LR 0.000214:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 32, LR 0.000214:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.23batch/s]Training Epoch 32, LR 0.000214:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 32, LR 0.000214:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 32, LR 0.000214:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 32, LR 0.000214:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 32, LR 0.000214:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 32, LR 0.000214:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 32, LR 0.000214:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.19batch/s]Training Epoch 32, LR 0.000214:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.42batch/s]Training Epoch 32, LR 0.000214:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 32, LR 0.000214:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 32, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.24batch/s]Training Epoch 32, LR 0.000214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 32:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 32:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.50s/batch]Evaluating Epoch 32:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 32:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.00s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [32/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[75, 14],
        [23, 32]], device='cuda:0')
train_accuracy=0.7430555820465088, 
train_recall=0.581818163394928, 
train_precision=0.695652186870575, 
train_specificity=0.8426966071128845, 
train_balance_acc=0.7122573852539062,
 train_f1_score=0.6336633563041687,
 train_auc=0.7411644458770752

Epoch [32/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[ 7, 11],
        [ 5,  9]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.6428571343421936, 
eval_precision=0.44999998807907104, 
eval_specificity=0.3888888955116272, 
eval_balance_acc=0.5158730149269104,
 eval_f1_score=0.529411792755127,
 eval_auc=0.6031745672225952


Epoch: 33/200
Training Epoch 33, LR 0.000174:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 33, LR 0.000174:   6%|â–Œ         | 1/18 [00:03<01:05,  3.86s/batch]Training Epoch 33, LR 0.000174:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 33, LR 0.000174:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 33, LR 0.000174:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 33, LR 0.000174:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.25s/batch]Training Epoch 33, LR 0.000174:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 33, LR 0.000174:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 33, LR 0.000174:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 33, LR 0.000174:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.02s/batch]Training Epoch 33, LR 0.000174:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.17batch/s]Training Epoch 33, LR 0.000174:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.39batch/s]Training Epoch 33, LR 0.000174:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 33, LR 0.000174:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.01s/batch]Training Epoch 33, LR 0.000174:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.10batch/s]Training Epoch 33, LR 0.000174:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.32batch/s]Training Epoch 33, LR 0.000174:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.53batch/s]Training Epoch 33, LR 0.000174:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.06batch/s]Training Epoch 33, LR 0.000174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.19batch/s]Training Epoch 33, LR 0.000174: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 33:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 33:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.46s/batch]Evaluating Epoch 33:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.51s/batch]Evaluating Epoch 33:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.66batch/s]Evaluating Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [33/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[77, 12],
        [20, 35]], device='cuda:0')
train_accuracy=0.7777777910232544, 
train_recall=0.6363636255264282, 
train_precision=0.7446808218955994, 
train_specificity=0.8651685118675232, 
train_balance_acc=0.7507660388946533,
 train_f1_score=0.686274528503418,
 train_auc=0.7669050097465515

Epoch [33/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[15,  5],
        [10,  2]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.1666666716337204, 
eval_precision=0.2857142984867096, 
eval_specificity=0.75, 
eval_balance_acc=0.4583333432674408,
 eval_f1_score=0.21052631735801697,
 eval_auc=0.5541666746139526


Epoch: 34/200
Training Epoch 34, LR 0.000137:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 34, LR 0.000137:   6%|â–Œ         | 1/18 [00:03<01:04,  3.80s/batch]Training Epoch 34, LR 0.000137:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 34, LR 0.000137:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 34, LR 0.000137:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 34, LR 0.000137:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 34, LR 0.000137:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 34, LR 0.000137:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 34, LR 0.000137:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 34, LR 0.000137:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.18s/batch]Training Epoch 34, LR 0.000137:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.07batch/s]Training Epoch 34, LR 0.000137:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.29batch/s]Training Epoch 34, LR 0.000137:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.51batch/s]Training Epoch 34, LR 0.000137:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 34, LR 0.000137:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 34, LR 0.000137:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 34, LR 0.000137:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 34, LR 0.000137:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.02s/batch]Training Epoch 34, LR 0.000137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 34, LR 0.000137: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 34:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 34:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.60s/batch]Evaluating Epoch 34:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 34:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [34/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[79, 11],
        [27, 27]], device='cuda:0')
train_accuracy=0.7361111044883728, 
train_recall=0.5, 
train_precision=0.7105262875556946, 
train_specificity=0.8777777552604675, 
train_balance_acc=0.6888889074325562,
 train_f1_score=0.5869565010070801,
 train_auc=0.7781893014907837

Epoch [34/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[15,  5],
        [10,  2]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.1666666716337204, 
eval_precision=0.2857142984867096, 
eval_specificity=0.75, 
eval_balance_acc=0.4583333432674408,
 eval_f1_score=0.21052631735801697,
 eval_auc=0.5458333492279053


Epoch: 35/200
Training Epoch 35, LR 0.000105:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 35, LR 0.000105:   6%|â–Œ         | 1/18 [00:03<01:03,  3.71s/batch]Training Epoch 35, LR 0.000105:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.77s/batch]Training Epoch 35, LR 0.000105:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 35, LR 0.000105:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.17batch/s]Training Epoch 35, LR 0.000105:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 35, LR 0.000105:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 35, LR 0.000105:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 35, LR 0.000105:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 35, LR 0.000105:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.05s/batch]Training Epoch 35, LR 0.000105:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 35, LR 0.000105:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.40batch/s]Training Epoch 35, LR 0.000105:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.61batch/s]Training Epoch 35, LR 0.000105:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 35, LR 0.000105:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.17batch/s]Training Epoch 35, LR 0.000105:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 35, LR 0.000105:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 35, LR 0.000105:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.08s/batch]Training Epoch 35, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.14batch/s]Training Epoch 35, LR 0.000105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 35:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 35:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.57s/batch]Evaluating Epoch 35:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 35:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [35/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[78, 11],
        [20, 35]], device='cuda:0')
train_accuracy=0.7847222089767456, 
train_recall=0.6363636255264282, 
train_precision=0.760869562625885, 
train_specificity=0.8764045238494873, 
train_balance_acc=0.7563840746879578,
 train_f1_score=0.6930692791938782,
 train_auc=0.7754851579666138

Epoch [35/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[16,  3],
        [11,  2]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.1538461595773697, 
eval_precision=0.4000000059604645, 
eval_specificity=0.8421052694320679, 
eval_balance_acc=0.4979757070541382,
 eval_f1_score=0.2222222238779068,
 eval_auc=0.5789473652839661


Epoch: 36/200
Training Epoch 36, LR 0.000076:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 36, LR 0.000076:   6%|â–Œ         | 1/18 [00:03<01:03,  3.75s/batch]Training Epoch 36, LR 0.000076:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 36, LR 0.000076:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 36, LR 0.000076:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 36, LR 0.000076:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 36, LR 0.000076:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 36, LR 0.000076:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 36, LR 0.000076:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 36, LR 0.000076:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.11s/batch]Training Epoch 36, LR 0.000076:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 36, LR 0.000076:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 36, LR 0.000076:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 36, LR 0.000076:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 36, LR 0.000076:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.17batch/s]Training Epoch 36, LR 0.000076:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 36, LR 0.000076:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 36, LR 0.000076:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 36, LR 0.000076: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 36, LR 0.000076: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 36:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 36:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.41s/batch]Evaluating Epoch 36:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:02,  1.49s/batch]Evaluating Epoch 36:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.14batch/s]Evaluating Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.69batch/s]Evaluating Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [36/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[74, 16],
        [21, 33]], device='cuda:0')
train_accuracy=0.7430555820465088, 
train_recall=0.6111111044883728, 
train_precision=0.6734693646430969, 
train_specificity=0.8222222328186035, 
train_balance_acc=0.7166666984558105,
 train_f1_score=0.6407766938209534,
 train_auc=0.7543209791183472

Epoch [36/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[17,  2],
        [11,  2]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.1538461595773697, 
eval_precision=0.5, 
eval_specificity=0.8947368264198303, 
eval_balance_acc=0.5242915153503418,
 eval_f1_score=0.23529411852359772,
 eval_auc=0.6194332242012024


Epoch: 37/200
Training Epoch 37, LR 0.000053:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 37, LR 0.000053:   6%|â–Œ         | 1/18 [00:03<01:06,  3.91s/batch]Training Epoch 37, LR 0.000053:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 37, LR 0.000053:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.20s/batch]Training Epoch 37, LR 0.000053:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 37, LR 0.000053:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.27s/batch]Training Epoch 37, LR 0.000053:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 37, LR 0.000053:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 37, LR 0.000053:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 37, LR 0.000053:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 37, LR 0.000053:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 37, LR 0.000053:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.37batch/s]Training Epoch 37, LR 0.000053:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 37, LR 0.000053:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 37, LR 0.000053:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 37, LR 0.000053:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 37, LR 0.000053:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 37, LR 0.000053:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 37, LR 0.000053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 37, LR 0.000053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 37:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 37:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.45s/batch]Evaluating Epoch 37:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.51s/batch]Evaluating Epoch 37:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.66batch/s]Evaluating Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [37/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[70, 19],
        [25, 30]], device='cuda:0')
train_accuracy=0.6944444179534912, 
train_recall=0.5454545617103577, 
train_precision=0.6122449040412903, 
train_specificity=0.7865168452262878, 
train_balance_acc=0.6659857034683228,
 train_f1_score=0.5769230723381042,
 train_auc=0.7417773008346558

Epoch [37/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[14,  5],
        [ 9,  4]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.3076923191547394, 
eval_precision=0.4444444477558136, 
eval_specificity=0.7368420958518982, 
eval_balance_acc=0.52226722240448,
 eval_f1_score=0.3636363744735718,
 eval_auc=0.5506072640419006


Epoch: 38/200
Training Epoch 38, LR 0.000034:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 38, LR 0.000034:   6%|â–Œ         | 1/18 [00:03<01:04,  3.79s/batch]Training Epoch 38, LR 0.000034:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 38, LR 0.000034:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 38, LR 0.000034:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.16batch/s]Training Epoch 38, LR 0.000034:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.27s/batch]Training Epoch 38, LR 0.000034:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 38, LR 0.000034:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 38, LR 0.000034:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 38, LR 0.000034:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.14s/batch]Training Epoch 38, LR 0.000034:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 38, LR 0.000034:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 38, LR 0.000034:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 38, LR 0.000034:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 38, LR 0.000034:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.16batch/s]Training Epoch 38, LR 0.000034:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 38, LR 0.000034:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 38, LR 0.000034:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.06s/batch]Training Epoch 38, LR 0.000034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.16batch/s]Training Epoch 38, LR 0.000034: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 38:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 38:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.72s/batch]Evaluating Epoch 38:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.62s/batch]Evaluating Epoch 38:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [38/200]:, train_loss=0.057, 
train_confusionMatrix:
tensor([[74, 16],
        [22, 32]], device='cuda:0')
train_accuracy=0.7361111044883728, 
train_recall=0.5925925970077515, 
train_precision=0.6666666865348816, 
train_specificity=0.8222222328186035, 
train_balance_acc=0.7074074149131775,
 train_f1_score=0.6274510025978088,
 train_auc=0.7652263641357422

Epoch [38/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[13,  5],
        [10,  4]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.2857142984867096, 
eval_precision=0.4444444477558136, 
eval_specificity=0.7222222089767456, 
eval_balance_acc=0.5039682388305664,
 eval_f1_score=0.3478260934352875,
 eval_auc=0.579365074634552


Epoch: 39/200
Training Epoch 39, LR 0.000021:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 39, LR 0.000021:   6%|â–Œ         | 1/18 [00:03<01:04,  3.81s/batch]Training Epoch 39, LR 0.000021:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 39, LR 0.000021:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 39, LR 0.000021:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 39, LR 0.000021:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.31s/batch]Training Epoch 39, LR 0.000021:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 39, LR 0.000021:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 39, LR 0.000021:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 39, LR 0.000021:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 39, LR 0.000021:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 39, LR 0.000021:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 39, LR 0.000021:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 39, LR 0.000021:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 39, LR 0.000021:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 39, LR 0.000021:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 39, LR 0.000021:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.61batch/s]Training Epoch 39, LR 0.000021:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 39, LR 0.000021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.23batch/s]Training Epoch 39, LR 0.000021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 39:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 39:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.47s/batch]Evaluating Epoch 39:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 39:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [39/200]:, train_loss=0.054, 
train_confusionMatrix:
tensor([[75, 15],
        [21, 33]], device='cuda:0')
train_accuracy=0.75, 
train_recall=0.6111111044883728, 
train_precision=0.6875, 
train_specificity=0.8333333134651184, 
train_balance_acc=0.7222222089767456,
 train_f1_score=0.6470588445663452,
 train_auc=0.8018518090248108

Epoch [39/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[15,  5],
        [ 9,  3]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.25, 
eval_precision=0.375, 
eval_specificity=0.75, 
eval_balance_acc=0.5,
 eval_f1_score=0.30000001192092896,
 eval_auc=0.5833333134651184


Epoch: 40/200
Training Epoch 40, LR 0.000013:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 40, LR 0.000013:   6%|â–Œ         | 1/18 [00:03<01:00,  3.54s/batch]Training Epoch 40, LR 0.000013:  11%|â–ˆ         | 2/18 [00:03<00:27,  1.70s/batch]Training Epoch 40, LR 0.000013:  17%|â–ˆâ–‹        | 3/18 [00:04<00:16,  1.11s/batch]Training Epoch 40, LR 0.000013:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.20batch/s]Training Epoch 40, LR 0.000013:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:15,  1.21s/batch]Training Epoch 40, LR 0.000013:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.06batch/s]Training Epoch 40, LR 0.000013:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.30batch/s]Training Epoch 40, LR 0.000013:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:07<00:06,  1.53batch/s]Training Epoch 40, LR 0.000013:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:09<00:09,  1.06s/batch]Training Epoch 40, LR 0.000013:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.17batch/s]Training Epoch 40, LR 0.000013:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.39batch/s]Training Epoch 40, LR 0.000013:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 40, LR 0.000013:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:12<00:04,  1.00batch/s]Training Epoch 40, LR 0.000013:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.22batch/s]Training Epoch 40, LR 0.000013:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:13<00:02,  1.44batch/s]Training Epoch 40, LR 0.000013:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.64batch/s]Training Epoch 40, LR 0.000013:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.00batch/s]Training Epoch 40, LR 0.000013: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.22batch/s]Training Epoch 40, LR 0.000013: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.09batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 40:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 40:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.72s/batch]Evaluating Epoch 40:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.62s/batch]Evaluating Epoch 40:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [40/200]:, train_loss=0.053, 
train_confusionMatrix:
tensor([[81, 10],
        [18, 35]], device='cuda:0')
train_accuracy=0.8055555820465088, 
train_recall=0.6603773832321167, 
train_precision=0.7777777910232544, 
train_specificity=0.8901098966598511, 
train_balance_acc=0.7752436399459839,
 train_f1_score=0.7142857313156128,
 train_auc=0.8042712211608887

Epoch [40/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[16,  5],
        [ 7,  4]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.3636363744735718, 
eval_precision=0.4444444477558136, 
eval_specificity=0.761904776096344, 
eval_balance_acc=0.5627706050872803,
 eval_f1_score=0.4000000059604645,
 eval_auc=0.5930736064910889


Epoch: 41/200
Training Epoch 41, LR 0.001000:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 41, LR 0.001000:   6%|â–Œ         | 1/18 [00:03<01:07,  3.94s/batch]Training Epoch 41, LR 0.001000:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 41, LR 0.001000:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 41, LR 0.001000:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 41, LR 0.001000:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.27s/batch]Training Epoch 41, LR 0.001000:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 41, LR 0.001000:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 41, LR 0.001000:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 41, LR 0.001000:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 41, LR 0.001000:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 41, LR 0.001000:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.37batch/s]Training Epoch 41, LR 0.001000:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 41, LR 0.001000:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 41, LR 0.001000:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 41, LR 0.001000:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 41, LR 0.001000:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.61batch/s]Training Epoch 41, LR 0.001000:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 41, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 41, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 41:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 41:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.67s/batch]Evaluating Epoch 41:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.60s/batch]Evaluating Epoch 41:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.06batch/s]Evaluating Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.58batch/s]Evaluating Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [41/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[76, 14],
        [27, 27]], device='cuda:0')
train_accuracy=0.7152777910232544, 
train_recall=0.5, 
train_precision=0.6585366129875183, 
train_specificity=0.8444444537162781, 
train_balance_acc=0.6722222566604614,
 train_f1_score=0.5684210658073425,
 train_auc=0.7561728358268738

Epoch [41/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[10, 11],
        [ 8,  3]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=0.27272728085517883, 
eval_precision=0.2142857164144516, 
eval_specificity=0.4761904776096344, 
eval_balance_acc=0.3744588792324066,
 eval_f1_score=0.23999999463558197,
 eval_auc=0.41558438539505005


Epoch: 42/200
Training Epoch 42, LR 0.001000:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 42, LR 0.001000:   6%|â–Œ         | 1/18 [00:03<01:02,  3.70s/batch]Training Epoch 42, LR 0.001000:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.76s/batch]Training Epoch 42, LR 0.001000:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.15s/batch]Training Epoch 42, LR 0.001000:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 42, LR 0.001000:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.28s/batch]Training Epoch 42, LR 0.001000:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 42, LR 0.001000:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 42, LR 0.001000:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 42, LR 0.001000:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 42, LR 0.001000:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 42, LR 0.001000:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 42, LR 0.001000:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 42, LR 0.001000:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.08s/batch]Training Epoch 42, LR 0.001000:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.14batch/s]Training Epoch 42, LR 0.001000:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 42, LR 0.001000:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 42, LR 0.001000:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 42, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 42, LR 0.001000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 42:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 42:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.62s/batch]Evaluating Epoch 42:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 42:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [42/200]:, train_loss=0.055, 
train_confusionMatrix:
tensor([[74, 16],
        [22, 32]], device='cuda:0')
train_accuracy=0.7361111044883728, 
train_recall=0.5925925970077515, 
train_precision=0.6666666865348816, 
train_specificity=0.8222222328186035, 
train_balance_acc=0.7074074149131775,
 train_f1_score=0.6274510025978088,
 train_auc=0.7790123224258423

Epoch [42/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[11,  8],
        [ 5,  8]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.6153846383094788, 
eval_precision=0.5, 
eval_specificity=0.5789473652839661, 
eval_balance_acc=0.5971660017967224,
 eval_f1_score=0.5517241358757019,
 eval_auc=0.5991902947425842


Epoch: 43/200
Training Epoch 43, LR 0.000999:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 43, LR 0.000999:   6%|â–Œ         | 1/18 [00:03<01:04,  3.81s/batch]Training Epoch 43, LR 0.000999:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.81s/batch]Training Epoch 43, LR 0.000999:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 43, LR 0.000999:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 43, LR 0.000999:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.27s/batch]Training Epoch 43, LR 0.000999:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 43, LR 0.000999:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 43, LR 0.000999:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 43, LR 0.000999:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.06s/batch]Training Epoch 43, LR 0.000999:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.09batch/s]Training Epoch 43, LR 0.000999:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 43, LR 0.000999:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 43, LR 0.000999:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.02batch/s]Training Epoch 43, LR 0.000999:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.14batch/s]Training Epoch 43, LR 0.000999:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.36batch/s]Training Epoch 43, LR 0.000999:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 43, LR 0.000999:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.03batch/s]Training Epoch 43, LR 0.000999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.21batch/s]Training Epoch 43, LR 0.000999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 43:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 43:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.43s/batch]Evaluating Epoch 43:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:02,  1.50s/batch]Evaluating Epoch 43:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.68batch/s]Evaluating Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [43/200]:, train_loss=0.058, 
train_confusionMatrix:
tensor([[66, 24],
        [20, 34]], device='cuda:0')
train_accuracy=0.6944444179534912, 
train_recall=0.6296296119689941, 
train_precision=0.5862069129943848, 
train_specificity=0.7333333492279053, 
train_balance_acc=0.6814814805984497,
 train_f1_score=0.6071428656578064,
 train_auc=0.7444444298744202

Epoch [43/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[18,  3],
        [11,  0]], device='cuda:0')
eval_accuracy=0.5625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.8571428656578064, 
eval_balance_acc=0.4285714328289032,
 eval_f1_score=0.0,
 eval_auc=0.32900431752204895


Epoch: 44/200
Training Epoch 44, LR 0.000997:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 44, LR 0.000997:   6%|â–Œ         | 1/18 [00:03<01:04,  3.77s/batch]Training Epoch 44, LR 0.000997:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.79s/batch]Training Epoch 44, LR 0.000997:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 44, LR 0.000997:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 44, LR 0.000997:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.36s/batch]Training Epoch 44, LR 0.000997:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 44, LR 0.000997:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 44, LR 0.000997:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 44, LR 0.000997:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.11s/batch]Training Epoch 44, LR 0.000997:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 44, LR 0.000997:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 44, LR 0.000997:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 44, LR 0.000997:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 44, LR 0.000997:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.19batch/s]Training Epoch 44, LR 0.000997:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 44, LR 0.000997:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.61batch/s]Training Epoch 44, LR 0.000997:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 44, LR 0.000997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.23batch/s]Training Epoch 44, LR 0.000997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 44:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 44:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.45s/batch]Evaluating Epoch 44:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 44:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.62batch/s]Evaluating Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [44/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[65, 25],
        [21, 33]], device='cuda:0')
train_accuracy=0.6805555820465088, 
train_recall=0.6111111044883728, 
train_precision=0.568965494632721, 
train_specificity=0.7222222089767456, 
train_balance_acc=0.6666666269302368,
 train_f1_score=0.5892857313156128,
 train_auc=0.6913579702377319

Epoch [44/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.3020833134651184


Epoch: 45/200
Training Epoch 45, LR 0.000995:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 45, LR 0.000995:   6%|â–Œ         | 1/18 [00:03<01:05,  3.88s/batch]Training Epoch 45, LR 0.000995:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 45, LR 0.000995:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 45, LR 0.000995:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 45, LR 0.000995:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.25s/batch]Training Epoch 45, LR 0.000995:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 45, LR 0.000995:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 45, LR 0.000995:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 45, LR 0.000995:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.14s/batch]Training Epoch 45, LR 0.000995:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.09batch/s]Training Epoch 45, LR 0.000995:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 45, LR 0.000995:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 45, LR 0.000995:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 45, LR 0.000995:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.16batch/s]Training Epoch 45, LR 0.000995:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 45, LR 0.000995:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 45, LR 0.000995:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 45, LR 0.000995: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.23batch/s]Training Epoch 45, LR 0.000995: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 45:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 45:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.45s/batch]Evaluating Epoch 45:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.51s/batch]Evaluating Epoch 45:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.67batch/s]Evaluating Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [45/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[69, 20],
        [28, 27]], device='cuda:0')
train_accuracy=0.6666666865348816, 
train_recall=0.4909090995788574, 
train_precision=0.5744680762290955, 
train_specificity=0.7752808928489685, 
train_balance_acc=0.6330950260162354,
 train_f1_score=0.529411792755127,
 train_auc=0.6563841104507446

Epoch [45/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.4375


Epoch: 46/200
Training Epoch 46, LR 0.000992:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 46, LR 0.000992:   6%|â–Œ         | 1/18 [00:03<01:06,  3.89s/batch]Training Epoch 46, LR 0.000992:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 46, LR 0.000992:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 46, LR 0.000992:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 46, LR 0.000992:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.33s/batch]Training Epoch 46, LR 0.000992:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 46, LR 0.000992:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.22batch/s]Training Epoch 46, LR 0.000992:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 46, LR 0.000992:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.17s/batch]Training Epoch 46, LR 0.000992:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.08batch/s]Training Epoch 46, LR 0.000992:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.30batch/s]Training Epoch 46, LR 0.000992:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.51batch/s]Training Epoch 46, LR 0.000992:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.07s/batch]Training Epoch 46, LR 0.000992:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 46, LR 0.000992:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 46, LR 0.000992:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.57batch/s]Training Epoch 46, LR 0.000992:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 46, LR 0.000992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.18batch/s]Training Epoch 46, LR 0.000992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 46:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 46:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.54s/batch]Evaluating Epoch 46:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 46:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [46/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[77, 12],
        [36, 19]], device='cuda:0')
train_accuracy=0.6666666865348816, 
train_recall=0.34545454382896423, 
train_precision=0.6129032373428345, 
train_specificity=0.8651685118675232, 
train_balance_acc=0.6053115129470825,
 train_f1_score=0.44186046719551086,
 train_auc=0.7344228625297546

Epoch [46/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[14,  4],
        [ 8,  6]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.4285714328289032, 
eval_precision=0.6000000238418579, 
eval_specificity=0.7777777910232544, 
eval_balance_acc=0.60317462682724,
 eval_f1_score=0.5,
 eval_auc=0.6190476417541504


Epoch: 47/200
Training Epoch 47, LR 0.000989:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 47, LR 0.000989:   6%|â–Œ         | 1/18 [00:03<01:04,  3.80s/batch]Training Epoch 47, LR 0.000989:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 47, LR 0.000989:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 47, LR 0.000989:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 47, LR 0.000989:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.26s/batch]Training Epoch 47, LR 0.000989:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 47, LR 0.000989:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 47, LR 0.000989:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 47, LR 0.000989:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 47, LR 0.000989:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 47, LR 0.000989:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 47, LR 0.000989:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 47, LR 0.000989:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.03s/batch]Training Epoch 47, LR 0.000989:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.19batch/s]Training Epoch 47, LR 0.000989:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.41batch/s]Training Epoch 47, LR 0.000989:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 47, LR 0.000989:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 47, LR 0.000989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.23batch/s]Training Epoch 47, LR 0.000989: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 47:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 47:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.57s/batch]Evaluating Epoch 47:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 47:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [47/200]:, train_loss=0.061, 
train_confusionMatrix:
tensor([[71, 19],
        [27, 27]], device='cuda:0')
train_accuracy=0.6805555820465088, 
train_recall=0.5, 
train_precision=0.5869565010070801, 
train_specificity=0.7888888716697693, 
train_balance_acc=0.644444465637207,
 train_f1_score=0.5400000214576721,
 train_auc=0.681892991065979

Epoch [47/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[16,  3],
        [13,  0]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.8421052694320679, 
eval_balance_acc=0.42105263471603394,
 eval_f1_score=0.0,
 eval_auc=0.449392706155777


Epoch: 48/200
Training Epoch 48, LR 0.000985:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 48, LR 0.000985:   6%|â–Œ         | 1/18 [00:03<01:06,  3.89s/batch]Training Epoch 48, LR 0.000985:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 48, LR 0.000985:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 48, LR 0.000985:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 48, LR 0.000985:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.27s/batch]Training Epoch 48, LR 0.000985:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 48, LR 0.000985:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 48, LR 0.000985:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 48, LR 0.000985:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.09s/batch]Training Epoch 48, LR 0.000985:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 48, LR 0.000985:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 48, LR 0.000985:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 48, LR 0.000985:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.11s/batch]Training Epoch 48, LR 0.000985:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 48, LR 0.000985:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.33batch/s]Training Epoch 48, LR 0.000985:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.54batch/s]Training Epoch 48, LR 0.000985:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.05s/batch]Training Epoch 48, LR 0.000985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 48, LR 0.000985: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 48:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 48:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.65s/batch]Evaluating Epoch 48:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.60s/batch]Evaluating Epoch 48:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.59batch/s]Evaluating Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [48/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[75, 15],
        [28, 26]], device='cuda:0')
train_accuracy=0.7013888955116272, 
train_recall=0.48148149251937866, 
train_precision=0.6341463327407837, 
train_specificity=0.8333333134651184, 
train_balance_acc=0.6574074029922485,
 train_f1_score=0.5473684072494507,
 train_auc=0.7096707820892334

Epoch [48/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[19,  0],
        [13,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.7125505805015564


Epoch: 49/200
Training Epoch 49, LR 0.000981:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 49, LR 0.000981:   6%|â–Œ         | 1/18 [00:03<01:06,  3.89s/batch]Training Epoch 49, LR 0.000981:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 49, LR 0.000981:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 49, LR 0.000981:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 49, LR 0.000981:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:18,  1.46s/batch]Training Epoch 49, LR 0.000981:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:08<00:13,  1.10s/batch]Training Epoch 49, LR 0.000981:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.15batch/s]Training Epoch 49, LR 0.000981:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:07,  1.38batch/s]Training Epoch 49, LR 0.000981:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.13s/batch]Training Epoch 49, LR 0.000981:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.10batch/s]Training Epoch 49, LR 0.000981:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 49, LR 0.000981:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:12<00:03,  1.54batch/s]Training Epoch 49, LR 0.000981:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.05s/batch]Training Epoch 49, LR 0.000981:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.17batch/s]Training Epoch 49, LR 0.000981:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 49, LR 0.000981:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.60batch/s]Training Epoch 49, LR 0.000981:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:00,  1.03batch/s]Training Epoch 49, LR 0.000981: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.25batch/s]Training Epoch 49, LR 0.000981: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 49:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 49:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 49:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.57s/batch]Evaluating Epoch 49:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [49/200]:, train_loss=0.061, 
train_confusionMatrix:
tensor([[75, 14],
        [38, 17]], device='cuda:0')
train_accuracy=0.6388888955116272, 
train_recall=0.30909091234207153, 
train_precision=0.5483871102333069, 
train_specificity=0.8426966071128845, 
train_balance_acc=0.575893759727478,
 train_f1_score=0.39534884691238403,
 train_auc=0.7148109674453735

Epoch [49/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[13,  5],
        [10,  4]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.2857142984867096, 
eval_precision=0.4444444477558136, 
eval_specificity=0.7222222089767456, 
eval_balance_acc=0.5039682388305664,
 eval_f1_score=0.3478260934352875,
 eval_auc=0.5436508059501648


Epoch: 50/200
Training Epoch 50, LR 0.000976:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 50, LR 0.000976:   6%|â–Œ         | 1/18 [00:03<01:03,  3.76s/batch]Training Epoch 50, LR 0.000976:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.78s/batch]Training Epoch 50, LR 0.000976:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 50, LR 0.000976:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:12,  1.16batch/s]Training Epoch 50, LR 0.000976:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.31s/batch]Training Epoch 50, LR 0.000976:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 50, LR 0.000976:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 50, LR 0.000976:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 50, LR 0.000976:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.17s/batch]Training Epoch 50, LR 0.000976:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.07batch/s]Training Epoch 50, LR 0.000976:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.29batch/s]Training Epoch 50, LR 0.000976:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.51batch/s]Training Epoch 50, LR 0.000976:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.05s/batch]Training Epoch 50, LR 0.000976:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.17batch/s]Training Epoch 50, LR 0.000976:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 50, LR 0.000976:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 50, LR 0.000976:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.00s/batch]Training Epoch 50, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.22batch/s]Training Epoch 50, LR 0.000976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 50:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 50:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.78s/batch]Evaluating Epoch 50:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.65s/batch]Evaluating Epoch 50:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.07s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [50/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[77, 14],
        [28, 25]], device='cuda:0')
train_accuracy=0.7083333134651184, 
train_recall=0.4716981053352356, 
train_precision=0.6410256624221802, 
train_specificity=0.8461538553237915, 
train_balance_acc=0.6589260101318359,
 train_f1_score=0.54347825050354,
 train_auc=0.7368857860565186

Epoch [50/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[11,  8],
        [ 9,  4]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=0.3076923191547394, 
eval_precision=0.3333333432674408, 
eval_specificity=0.5789473652839661, 
eval_balance_acc=0.4433198571205139,
 eval_f1_score=0.3199999928474426,
 eval_auc=0.5141700506210327


Epoch: 51/200
Training Epoch 51, LR 0.000970:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 51, LR 0.000970:   6%|â–Œ         | 1/18 [00:03<01:05,  3.87s/batch]Training Epoch 51, LR 0.000970:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 51, LR 0.000970:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 51, LR 0.000970:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 51, LR 0.000970:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.28s/batch]Training Epoch 51, LR 0.000970:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 51, LR 0.000970:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 51, LR 0.000970:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 51, LR 0.000970:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.07s/batch]Training Epoch 51, LR 0.000970:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.16batch/s]Training Epoch 51, LR 0.000970:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.38batch/s]Training Epoch 51, LR 0.000970:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 51, LR 0.000970:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 51, LR 0.000970:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 51, LR 0.000970:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 51, LR 0.000970:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 51, LR 0.000970:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 51, LR 0.000970: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.22batch/s]Training Epoch 51, LR 0.000970: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 51:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 51:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.49s/batch]Evaluating Epoch 51:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.52s/batch]Evaluating Epoch 51:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.66batch/s]Evaluating Epoch 51: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [51/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[71, 19],
        [25, 29]], device='cuda:0')
train_accuracy=0.6944444179534912, 
train_recall=0.5370370149612427, 
train_precision=0.6041666865348816, 
train_specificity=0.7888888716697693, 
train_balance_acc=0.6629629135131836,
 train_f1_score=0.5686274766921997,
 train_auc=0.7481480836868286

Epoch [51/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 1, 17],
        [ 0, 14]], device='cuda:0')
eval_accuracy=0.46875, 
eval_recall=1.0, 
eval_precision=0.4516128897666931, 
eval_specificity=0.0555555559694767, 
eval_balance_acc=0.5277777910232544,
 eval_f1_score=0.6222222447395325,
 eval_auc=0.6785714030265808


Epoch: 52/200
Training Epoch 52, LR 0.000964:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 52, LR 0.000964:   6%|â–Œ         | 1/18 [00:03<01:06,  3.91s/batch]Training Epoch 52, LR 0.000964:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 52, LR 0.000964:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 52, LR 0.000964:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 52, LR 0.000964:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.24s/batch]Training Epoch 52, LR 0.000964:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.04batch/s]Training Epoch 52, LR 0.000964:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.28batch/s]Training Epoch 52, LR 0.000964:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 52, LR 0.000964:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 52, LR 0.000964:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 52, LR 0.000964:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.37batch/s]Training Epoch 52, LR 0.000964:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 52, LR 0.000964:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 52, LR 0.000964:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 52, LR 0.000964:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 52, LR 0.000964:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.61batch/s]Training Epoch 52, LR 0.000964:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 52, LR 0.000964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.24batch/s]Training Epoch 52, LR 0.000964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 52:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 52:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.42s/batch]Evaluating Epoch 52:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:02,  1.50s/batch]Evaluating Epoch 52:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.13batch/s]Evaluating Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.68batch/s]Evaluating Epoch 52: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [52/200]:, train_loss=0.056, 
train_confusionMatrix:
tensor([[78, 12],
        [23, 31]], device='cuda:0')
train_accuracy=0.7569444179534912, 
train_recall=0.5740740895271301, 
train_precision=0.7209302186965942, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.7203704118728638,
 train_f1_score=0.6391752362251282,
 train_auc=0.7738683223724365

Epoch [52/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[16,  4],
        [ 7,  5]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.4166666567325592, 
eval_precision=0.5555555820465088, 
eval_specificity=0.800000011920929, 
eval_balance_acc=0.6083333492279053,
 eval_f1_score=0.4761904776096344,
 eval_auc=0.5666666626930237


Epoch: 53/200
Training Epoch 53, LR 0.000957:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 53, LR 0.000957:   6%|â–Œ         | 1/18 [00:03<01:05,  3.86s/batch]Training Epoch 53, LR 0.000957:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 53, LR 0.000957:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 53, LR 0.000957:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 53, LR 0.000957:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 53, LR 0.000957:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.00batch/s]Training Epoch 53, LR 0.000957:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 53, LR 0.000957:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 53, LR 0.000957:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.18s/batch]Training Epoch 53, LR 0.000957:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.06batch/s]Training Epoch 53, LR 0.000957:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.28batch/s]Training Epoch 53, LR 0.000957:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:04,  1.50batch/s]Training Epoch 53, LR 0.000957:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.11s/batch]Training Epoch 53, LR 0.000957:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 53, LR 0.000957:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.32batch/s]Training Epoch 53, LR 0.000957:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.53batch/s]Training Epoch 53, LR 0.000957:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.03s/batch]Training Epoch 53, LR 0.000957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 53, LR 0.000957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 53:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 53:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.49s/batch]Evaluating Epoch 53:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 53:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.65batch/s]Evaluating Epoch 53: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.00batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [53/200]:, train_loss=0.059, 
train_confusionMatrix:
tensor([[76, 13],
        [35, 20]], device='cuda:0')
train_accuracy=0.6666666865348816, 
train_recall=0.3636363744735718, 
train_precision=0.6060606241226196, 
train_specificity=0.8539325594902039, 
train_balance_acc=0.6087844371795654,
 train_f1_score=0.4545454680919647,
 train_auc=0.7403472661972046

Epoch [53/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[16,  5],
        [11,  0]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=0.761904776096344, 
eval_balance_acc=0.380952388048172,
 eval_f1_score=0.0,
 eval_auc=0.43290042877197266


Epoch: 54/200
Training Epoch 54, LR 0.000950:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 54, LR 0.000950:   6%|â–Œ         | 1/18 [00:03<01:02,  3.69s/batch]Training Epoch 54, LR 0.000950:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.76s/batch]Training Epoch 54, LR 0.000950:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.14s/batch]Training Epoch 54, LR 0.000950:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.17batch/s]Training Epoch 54, LR 0.000950:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.29s/batch]Training Epoch 54, LR 0.000950:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 54, LR 0.000950:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 54, LR 0.000950:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 54, LR 0.000950:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 54, LR 0.000950:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.13batch/s]Training Epoch 54, LR 0.000950:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 54, LR 0.000950:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 54, LR 0.000950:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 54, LR 0.000950:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.16batch/s]Training Epoch 54, LR 0.000950:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 54, LR 0.000950:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.59batch/s]Training Epoch 54, LR 0.000950:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.01s/batch]Training Epoch 54, LR 0.000950: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.21batch/s]Training Epoch 54, LR 0.000950: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 54:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 54:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.50s/batch]Evaluating Epoch 54:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.63s/batch]Evaluating Epoch 54:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.04batch/s]Evaluating Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 54: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.05s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [54/200]:, train_loss=0.052, 
train_confusionMatrix:
tensor([[75, 15],
        [17, 37]], device='cuda:0')
train_accuracy=0.7777777910232544, 
train_recall=0.6851851940155029, 
train_precision=0.7115384340286255, 
train_specificity=0.8333333134651184, 
train_balance_acc=0.7592592239379883,
 train_f1_score=0.698113203048706,
 train_auc=0.8296296000480652

Epoch [54/200]:, eval_loss=0.020, 
eval_confusionMatrix:
tensor([[ 0, 20],
        [ 0, 12]], device='cuda:0')
eval_accuracy=0.375, 
eval_recall=1.0, 
eval_precision=0.375, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5454545617103577,
 eval_auc=0.4541666805744171


Epoch: 55/200
Training Epoch 55, LR 0.000942:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 55, LR 0.000942:   6%|â–Œ         | 1/18 [00:03<01:04,  3.81s/batch]Training Epoch 55, LR 0.000942:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.81s/batch]Training Epoch 55, LR 0.000942:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 55, LR 0.000942:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 55, LR 0.000942:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 55, LR 0.000942:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 55, LR 0.000942:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 55, LR 0.000942:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 55, LR 0.000942:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 55, LR 0.000942:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 55, LR 0.000942:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 55, LR 0.000942:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 55, LR 0.000942:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 55, LR 0.000942:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.18batch/s]Training Epoch 55, LR 0.000942:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.39batch/s]Training Epoch 55, LR 0.000942:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.60batch/s]Training Epoch 55, LR 0.000942:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.01batch/s]Training Epoch 55, LR 0.000942: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.22batch/s]Training Epoch 55, LR 0.000942: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 55:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 55:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.61s/batch]Evaluating Epoch 55:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.58s/batch]Evaluating Epoch 55:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.08batch/s]Evaluating Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.61batch/s]Evaluating Epoch 55: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [55/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[68, 22],
        [23, 31]], device='cuda:0')
train_accuracy=0.6875, 
train_recall=0.5740740895271301, 
train_precision=0.5849056839942932, 
train_specificity=0.7555555701255798, 
train_balance_acc=0.664814829826355,
 train_f1_score=0.5794392228126526,
 train_auc=0.7055555582046509

Epoch [55/200]:, eval_loss=0.018, 
eval_confusionMatrix:
tensor([[ 2, 16],
        [ 0, 14]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=1.0, 
eval_precision=0.46666666865348816, 
eval_specificity=0.1111111119389534, 
eval_balance_acc=0.5555555820465088,
 eval_f1_score=0.6363636255264282,
 eval_auc=0.567460298538208


Epoch: 56/200
Training Epoch 56, LR 0.000934:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 56, LR 0.000934:   6%|â–Œ         | 1/18 [00:03<01:06,  3.90s/batch]Training Epoch 56, LR 0.000934:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 56, LR 0.000934:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 56, LR 0.000934:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 56, LR 0.000934:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.26s/batch]Training Epoch 56, LR 0.000934:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.03batch/s]Training Epoch 56, LR 0.000934:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 56, LR 0.000934:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 56, LR 0.000934:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.19s/batch]Training Epoch 56, LR 0.000934:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.05batch/s]Training Epoch 56, LR 0.000934:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.27batch/s]Training Epoch 56, LR 0.000934:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:04,  1.49batch/s]Training Epoch 56, LR 0.000934:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.11s/batch]Training Epoch 56, LR 0.000934:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.12batch/s]Training Epoch 56, LR 0.000934:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.34batch/s]Training Epoch 56, LR 0.000934:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.55batch/s]Training Epoch 56, LR 0.000934:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.02s/batch]Training Epoch 56, LR 0.000934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 56, LR 0.000934: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 56:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 56:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.50s/batch]Evaluating Epoch 56:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 56:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 56: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [56/200]:, train_loss=0.070, 
train_confusionMatrix:
tensor([[60, 29],
        [35, 20]], device='cuda:0')
train_accuracy=0.5555555820465088, 
train_recall=0.3636363744735718, 
train_precision=0.40816327929496765, 
train_specificity=0.6741573214530945, 
train_balance_acc=0.5188968181610107,
 train_f1_score=0.38461539149284363,
 train_auc=0.5260469913482666

Epoch [56/200]:, eval_loss=0.013, 
eval_confusionMatrix:
tensor([[12,  8],
        [ 4,  8]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.6666666865348816, 
eval_precision=0.5, 
eval_specificity=0.6000000238418579, 
eval_balance_acc=0.6333333253860474,
 eval_f1_score=0.5714285969734192,
 eval_auc=0.7708333134651184


Epoch: 57/200
Training Epoch 57, LR 0.000925:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 57, LR 0.000925:   6%|â–Œ         | 1/18 [00:03<01:02,  3.67s/batch]Training Epoch 57, LR 0.000925:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.75s/batch]Training Epoch 57, LR 0.000925:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.14s/batch]Training Epoch 57, LR 0.000925:  22%|â–ˆâ–ˆâ–       | 4/18 [00:04<00:11,  1.18batch/s]Training Epoch 57, LR 0.000925:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:15,  1.19s/batch]Training Epoch 57, LR 0.000925:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.08batch/s]Training Epoch 57, LR 0.000925:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.33batch/s]Training Epoch 57, LR 0.000925:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:07<00:06,  1.55batch/s]Training Epoch 57, LR 0.000925:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:09<00:08,  1.00batch/s]Training Epoch 57, LR 0.000925:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 57, LR 0.000925:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.37batch/s]Training Epoch 57, LR 0.000925:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 57, LR 0.000925:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:12<00:04,  1.03batch/s]Training Epoch 57, LR 0.000925:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.14batch/s]Training Epoch 57, LR 0.000925:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:13<00:02,  1.36batch/s]Training Epoch 57, LR 0.000925:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.57batch/s]Training Epoch 57, LR 0.000925:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:15<00:00,  1.06batch/s]Training Epoch 57, LR 0.000925: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.20batch/s]Training Epoch 57, LR 0.000925: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.08batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 57:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 57:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.63s/batch]Evaluating Epoch 57:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.59s/batch]Evaluating Epoch 57:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.07batch/s]Evaluating Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.60batch/s]Evaluating Epoch 57: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [57/200]:, train_loss=0.068, 
train_confusionMatrix:
tensor([[64, 26],
        [34, 20]], device='cuda:0')
train_accuracy=0.5833333134651184, 
train_recall=0.37037035822868347, 
train_precision=0.43478259444236755, 
train_specificity=0.7111111283302307, 
train_balance_acc=0.5407407283782959,
 train_f1_score=0.4000000059604645,
 train_auc=0.557201623916626

Epoch [57/200]:, eval_loss=0.017, 
eval_confusionMatrix:
tensor([[ 5, 15],
        [ 6,  6]], device='cuda:0')
eval_accuracy=0.34375, 
eval_recall=0.5, 
eval_precision=0.2857142984867096, 
eval_specificity=0.25, 
eval_balance_acc=0.375,
 eval_f1_score=0.3636363744735718,
 eval_auc=0.5


Epoch: 58/200
Training Epoch 58, LR 0.000915:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 58, LR 0.000915:   6%|â–Œ         | 1/18 [00:03<01:06,  3.91s/batch]Training Epoch 58, LR 0.000915:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 58, LR 0.000915:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.20s/batch]Training Epoch 58, LR 0.000915:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 58, LR 0.000915:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 58, LR 0.000915:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 58, LR 0.000915:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.24batch/s]Training Epoch 58, LR 0.000915:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 58, LR 0.000915:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.14s/batch]Training Epoch 58, LR 0.000915:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.10batch/s]Training Epoch 58, LR 0.000915:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 58, LR 0.000915:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 58, LR 0.000915:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 58, LR 0.000915:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.16batch/s]Training Epoch 58, LR 0.000915:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.38batch/s]Training Epoch 58, LR 0.000915:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.59batch/s]Training Epoch 58, LR 0.000915:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 58, LR 0.000915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 58, LR 0.000915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 58:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 58:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.72s/batch]Evaluating Epoch 58:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.62s/batch]Evaluating Epoch 58:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.56batch/s]Evaluating Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [58/200]:, train_loss=0.064, 
train_confusionMatrix:
tensor([[78, 13],
        [45,  8]], device='cuda:0')
train_accuracy=0.5972222089767456, 
train_recall=0.15094339847564697, 
train_precision=0.380952388048172, 
train_specificity=0.8571428656578064, 
train_balance_acc=0.5040431022644043,
 train_f1_score=0.21621622145175934,
 train_auc=0.5880157351493835

Epoch [58/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[16,  3],
        [ 9,  4]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.3076923191547394, 
eval_precision=0.5714285969734192, 
eval_specificity=0.8421052694320679, 
eval_balance_acc=0.5748987793922424,
 eval_f1_score=0.4000000059604645,
 eval_auc=0.4858299493789673


Epoch: 59/200
Training Epoch 59, LR 0.000905:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 59, LR 0.000905:   6%|â–Œ         | 1/18 [00:03<01:05,  3.87s/batch]Training Epoch 59, LR 0.000905:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 59, LR 0.000905:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 59, LR 0.000905:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 59, LR 0.000905:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.36s/batch]Training Epoch 59, LR 0.000905:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 59, LR 0.000905:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 59, LR 0.000905:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 59, LR 0.000905:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.11s/batch]Training Epoch 59, LR 0.000905:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 59, LR 0.000905:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.34batch/s]Training Epoch 59, LR 0.000905:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.56batch/s]Training Epoch 59, LR 0.000905:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.04s/batch]Training Epoch 59, LR 0.000905:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.18batch/s]Training Epoch 59, LR 0.000905:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.40batch/s]Training Epoch 59, LR 0.000905:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.61batch/s]Training Epoch 59, LR 0.000905:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.13s/batch]Training Epoch 59, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.10batch/s]Training Epoch 59, LR 0.000905: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 59:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 59:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.59s/batch]Evaluating Epoch 59:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.61s/batch]Evaluating Epoch 59:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.06batch/s]Evaluating Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.59batch/s]Evaluating Epoch 59: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [59/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[83,  7],
        [42, 12]], device='cuda:0')
train_accuracy=0.6597222089767456, 
train_recall=0.2222222238779068, 
train_precision=0.6315789222717285, 
train_specificity=0.9222221970558167, 
train_balance_acc=0.5722222328186035,
 train_f1_score=0.3287671208381653,
 train_auc=0.6281893253326416

Epoch [59/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[21,  0],
        [10,  1]], device='cuda:0')
eval_accuracy=0.6875, 
eval_recall=0.09090909361839294, 
eval_precision=1.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5454545617103577,
 eval_f1_score=0.1666666716337204,
 eval_auc=0.6060605645179749


Epoch: 60/200
Training Epoch 60, LR 0.000895:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 60, LR 0.000895:   6%|â–Œ         | 1/18 [00:03<01:05,  3.88s/batch]Training Epoch 60, LR 0.000895:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.84s/batch]Training Epoch 60, LR 0.000895:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 60, LR 0.000895:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 60, LR 0.000895:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.31s/batch]Training Epoch 60, LR 0.000895:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.01s/batch]Training Epoch 60, LR 0.000895:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.23batch/s]Training Epoch 60, LR 0.000895:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.46batch/s]Training Epoch 60, LR 0.000895:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 60, LR 0.000895:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.11batch/s]Training Epoch 60, LR 0.000895:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 60, LR 0.000895:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.55batch/s]Training Epoch 60, LR 0.000895:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 60, LR 0.000895:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.16batch/s]Training Epoch 60, LR 0.000895:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 60, LR 0.000895:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.58batch/s]Training Epoch 60, LR 0.000895:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 60, LR 0.000895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 60, LR 0.000895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 60:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 60:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.76s/batch]Evaluating Epoch 60:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.64s/batch]Evaluating Epoch 60:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.04batch/s]Evaluating Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.55batch/s]Evaluating Epoch 60: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.08s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [60/200]:, train_loss=0.065, 
train_confusionMatrix:
tensor([[82,  8],
        [42, 12]], device='cuda:0')
train_accuracy=0.6527777910232544, 
train_recall=0.2222222238779068, 
train_precision=0.6000000238418579, 
train_specificity=0.9111111164093018, 
train_balance_acc=0.5666666626930237,
 train_f1_score=0.3243243098258972,
 train_auc=0.5748971104621887

Epoch [60/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[19,  0],
        [13,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.5789473652839661


Epoch: 61/200
Training Epoch 61, LR 0.000884:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 61, LR 0.000884:   6%|â–Œ         | 1/18 [00:03<01:07,  3.96s/batch]Training Epoch 61, LR 0.000884:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 61, LR 0.000884:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 61, LR 0.000884:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 61, LR 0.000884:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 61, LR 0.000884:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 61, LR 0.000884:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 61, LR 0.000884:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.44batch/s]Training Epoch 61, LR 0.000884:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.16s/batch]Training Epoch 61, LR 0.000884:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.08batch/s]Training Epoch 61, LR 0.000884:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.31batch/s]Training Epoch 61, LR 0.000884:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.52batch/s]Training Epoch 61, LR 0.000884:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.09s/batch]Training Epoch 61, LR 0.000884:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.13batch/s]Training Epoch 61, LR 0.000884:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.35batch/s]Training Epoch 61, LR 0.000884:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.56batch/s]Training Epoch 61, LR 0.000884:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.02s/batch]Training Epoch 61, LR 0.000884: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 61, LR 0.000884: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 61:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 61:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.47s/batch]Evaluating Epoch 61:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.51s/batch]Evaluating Epoch 61:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.67batch/s]Evaluating Epoch 61: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [61/200]:, train_loss=0.064, 
train_confusionMatrix:
tensor([[82,  8],
        [43, 11]], device='cuda:0')
train_accuracy=0.6458333134651184, 
train_recall=0.20370370149612427, 
train_precision=0.5789473652839661, 
train_specificity=0.9111111164093018, 
train_balance_acc=0.5574073791503906,
 train_f1_score=0.30136987566947937,
 train_auc=0.6269547939300537

Epoch [61/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[19,  0],
        [13,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.4412955641746521


Epoch: 62/200
Training Epoch 62, LR 0.000873:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 62, LR 0.000873:   6%|â–Œ         | 1/18 [00:03<01:06,  3.90s/batch]Training Epoch 62, LR 0.000873:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 62, LR 0.000873:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 62, LR 0.000873:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 62, LR 0.000873:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.28s/batch]Training Epoch 62, LR 0.000873:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 62, LR 0.000873:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.25batch/s]Training Epoch 62, LR 0.000873:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 62, LR 0.000873:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 62, LR 0.000873:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.14batch/s]Training Epoch 62, LR 0.000873:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.36batch/s]Training Epoch 62, LR 0.000873:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 62, LR 0.000873:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.11s/batch]Training Epoch 62, LR 0.000873:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 62, LR 0.000873:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.33batch/s]Training Epoch 62, LR 0.000873:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.54batch/s]Training Epoch 62, LR 0.000873:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.02s/batch]Training Epoch 62, LR 0.000873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.20batch/s]Training Epoch 62, LR 0.000873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 62:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 62:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.76s/batch]Evaluating Epoch 62:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.63s/batch]Evaluating Epoch 62:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.05batch/s]Evaluating Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.57batch/s]Evaluating Epoch 62: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.06s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [62/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[80, 10],
        [37, 17]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.31481480598449707, 
train_precision=0.6296296119689941, 
train_specificity=0.8888888955116272, 
train_balance_acc=0.6018518209457397,
 train_f1_score=0.4197530746459961,
 train_auc=0.6399176716804504

Epoch [62/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[19,  1],
        [11,  1]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0833333358168602, 
eval_precision=0.5, 
eval_specificity=0.949999988079071, 
eval_balance_acc=0.5166666507720947,
 eval_f1_score=0.1428571492433548,
 eval_auc=0.5333333611488342


Epoch: 63/200
Training Epoch 63, LR 0.000861:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 63, LR 0.000861:   6%|â–Œ         | 1/18 [00:03<01:07,  3.97s/batch]Training Epoch 63, LR 0.000861:  11%|â–ˆ         | 2/18 [00:04<00:30,  1.88s/batch]Training Epoch 63, LR 0.000861:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.21s/batch]Training Epoch 63, LR 0.000861:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 63, LR 0.000861:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.29s/batch]Training Epoch 63, LR 0.000861:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.01batch/s]Training Epoch 63, LR 0.000861:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:08,  1.25batch/s]Training Epoch 63, LR 0.000861:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.48batch/s]Training Epoch 63, LR 0.000861:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.11s/batch]Training Epoch 63, LR 0.000861:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.12batch/s]Training Epoch 63, LR 0.000861:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.35batch/s]Training Epoch 63, LR 0.000861:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.57batch/s]Training Epoch 63, LR 0.000861:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 63, LR 0.000861:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.20batch/s]Training Epoch 63, LR 0.000861:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.42batch/s]Training Epoch 63, LR 0.000861:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.63batch/s]Training Epoch 63, LR 0.000861:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.03batch/s]Training Epoch 63, LR 0.000861: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.24batch/s]Training Epoch 63, LR 0.000861: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.05batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 63:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 63:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.52s/batch]Evaluating Epoch 63:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.54s/batch]Evaluating Epoch 63:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.06batch/s]Evaluating Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.59batch/s]Evaluating Epoch 63: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.03s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [63/200]:, train_loss=0.062, 
train_confusionMatrix:
tensor([[77, 13],
        [35, 19]], device='cuda:0')
train_accuracy=0.6666666865348816, 
train_recall=0.35185185074806213, 
train_precision=0.59375, 
train_specificity=0.855555534362793, 
train_balance_acc=0.6037036776542664,
 train_f1_score=0.44186046719551086,
 train_auc=0.6277777552604675

Epoch [63/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[13,  6],
        [ 9,  4]], device='cuda:0')
eval_accuracy=0.53125, 
eval_recall=0.3076923191547394, 
eval_precision=0.4000000059604645, 
eval_specificity=0.6842105388641357, 
eval_balance_acc=0.49595141410827637,
 eval_f1_score=0.3478260934352875,
 eval_auc=0.5910930633544922


Epoch: 64/200
Training Epoch 64, LR 0.000849:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 64, LR 0.000849:   6%|â–Œ         | 1/18 [00:03<01:04,  3.80s/batch]Training Epoch 64, LR 0.000849:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 64, LR 0.000849:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 64, LR 0.000849:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 64, LR 0.000849:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.30s/batch]Training Epoch 64, LR 0.000849:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.00s/batch]Training Epoch 64, LR 0.000849:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.24batch/s]Training Epoch 64, LR 0.000849:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.47batch/s]Training Epoch 64, LR 0.000849:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.10s/batch]Training Epoch 64, LR 0.000849:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:08,  1.01s/batch]Training Epoch 64, LR 0.000849:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.21batch/s]Training Epoch 64, LR 0.000849:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:04,  1.43batch/s]Training Epoch 64, LR 0.000849:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 64, LR 0.000849:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.11batch/s]Training Epoch 64, LR 0.000849:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.33batch/s]Training Epoch 64, LR 0.000849:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.54batch/s]Training Epoch 64, LR 0.000849:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 64, LR 0.000849: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 64, LR 0.000849: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.02batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 64:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 64:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.55s/batch]Evaluating Epoch 64:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.56s/batch]Evaluating Epoch 64:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.09batch/s]Evaluating Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.62batch/s]Evaluating Epoch 64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [64/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[78, 12],
        [35, 19]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.35185185074806213, 
train_precision=0.6129032373428345, 
train_specificity=0.8666666746139526, 
train_balance_acc=0.6092592477798462,
 train_f1_score=0.4470588266849518,
 train_auc=0.7150205373764038

Epoch [64/200]:, eval_loss=0.014, 
eval_confusionMatrix:
tensor([[14,  5],
        [ 6,  7]], device='cuda:0')
eval_accuracy=0.65625, 
eval_recall=0.5384615659713745, 
eval_precision=0.5833333134651184, 
eval_specificity=0.7368420958518982, 
eval_balance_acc=0.637651801109314,
 eval_f1_score=0.5600000023841858,
 eval_auc=0.659919023513794


Epoch: 65/200
Training Epoch 65, LR 0.000836:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 65, LR 0.000836:   6%|â–Œ         | 1/18 [00:03<01:06,  3.93s/batch]Training Epoch 65, LR 0.000836:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.87s/batch]Training Epoch 65, LR 0.000836:  17%|â–ˆâ–‹        | 3/18 [00:04<00:18,  1.20s/batch]Training Epoch 65, LR 0.000836:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.12batch/s]Training Epoch 65, LR 0.000836:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.36s/batch]Training Epoch 65, LR 0.000836:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.04s/batch]Training Epoch 65, LR 0.000836:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.20batch/s]Training Epoch 65, LR 0.000836:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.43batch/s]Training Epoch 65, LR 0.000836:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.12s/batch]Training Epoch 65, LR 0.000836:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:11<00:07,  1.11batch/s]Training Epoch 65, LR 0.000836:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.33batch/s]Training Epoch 65, LR 0.000836:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.54batch/s]Training Epoch 65, LR 0.000836:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:14<00:05,  1.14s/batch]Training Epoch 65, LR 0.000836:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.09batch/s]Training Epoch 65, LR 0.000836:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.31batch/s]Training Epoch 65, LR 0.000836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.52batch/s]Training Epoch 65, LR 0.000836:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:17<00:01,  1.04s/batch]Training Epoch 65, LR 0.000836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 65, LR 0.000836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 65:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 65:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.77s/batch]Evaluating Epoch 65:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.66s/batch]Evaluating Epoch 65:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.03batch/s]Evaluating Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.53batch/s]Evaluating Epoch 65: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.08s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [65/200]:, train_loss=0.061, 
train_confusionMatrix:
tensor([[74, 15],
        [31, 24]], device='cuda:0')
train_accuracy=0.6805555820465088, 
train_recall=0.4363636374473572, 
train_precision=0.6153846383094788, 
train_specificity=0.8314606547355652, 
train_balance_acc=0.6339121460914612,
 train_f1_score=0.5106382966041565,
 train_auc=0.6764044761657715

Epoch [65/200]:, eval_loss=0.018, 
eval_confusionMatrix:
tensor([[13,  5],
        [11,  3]], device='cuda:0')
eval_accuracy=0.5, 
eval_recall=0.2142857164144516, 
eval_precision=0.375, 
eval_specificity=0.7222222089767456, 
eval_balance_acc=0.4682539701461792,
 eval_f1_score=0.27272728085517883,
 eval_auc=0.5


Epoch: 66/200
Training Epoch 66, LR 0.000823:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 66, LR 0.000823:   6%|â–Œ         | 1/18 [00:03<01:04,  3.79s/batch]Training Epoch 66, LR 0.000823:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 66, LR 0.000823:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.17s/batch]Training Epoch 66, LR 0.000823:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 66, LR 0.000823:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.26s/batch]Training Epoch 66, LR 0.000823:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 66, LR 0.000823:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.27batch/s]Training Epoch 66, LR 0.000823:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.50batch/s]Training Epoch 66, LR 0.000823:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.04s/batch]Training Epoch 66, LR 0.000823:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 66, LR 0.000823:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:04,  1.40batch/s]Training Epoch 66, LR 0.000823:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.61batch/s]Training Epoch 66, LR 0.000823:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:04,  1.02batch/s]Training Epoch 66, LR 0.000823:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:13<00:03,  1.21batch/s]Training Epoch 66, LR 0.000823:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:13<00:02,  1.43batch/s]Training Epoch 66, LR 0.000823:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.63batch/s]Training Epoch 66, LR 0.000823:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.02batch/s]Training Epoch 66, LR 0.000823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.24batch/s]Training Epoch 66, LR 0.000823: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.08batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 66:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 66:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.47s/batch]Evaluating Epoch 66:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.52s/batch]Evaluating Epoch 66:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.12batch/s]Evaluating Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.66batch/s]Evaluating Epoch 66: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.01batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [66/200]:, train_loss=0.061, 
train_confusionMatrix:
tensor([[76, 13],
        [34, 21]], device='cuda:0')
train_accuracy=0.6736111044883728, 
train_recall=0.38181817531585693, 
train_precision=0.6176470518112183, 
train_specificity=0.8539325594902039, 
train_balance_acc=0.617875337600708,
 train_f1_score=0.47191011905670166,
 train_auc=0.6574054956436157

Epoch [66/200]:, eval_loss=0.019, 
eval_confusionMatrix:
tensor([[ 8, 12],
        [ 7,  5]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=0.4166666567325592, 
eval_precision=0.29411765933036804, 
eval_specificity=0.4000000059604645, 
eval_balance_acc=0.40833333134651184,
 eval_f1_score=0.3448275923728943,
 eval_auc=0.3291666805744171


Epoch: 67/200
Training Epoch 67, LR 0.000810:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 67, LR 0.000810:   6%|â–Œ         | 1/18 [00:03<01:04,  3.79s/batch]Training Epoch 67, LR 0.000810:  11%|â–ˆ         | 2/18 [00:04<00:28,  1.80s/batch]Training Epoch 67, LR 0.000810:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.16s/batch]Training Epoch 67, LR 0.000810:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.15batch/s]Training Epoch 67, LR 0.000810:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.35s/batch]Training Epoch 67, LR 0.000810:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.03s/batch]Training Epoch 67, LR 0.000810:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.21batch/s]Training Epoch 67, LR 0.000810:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 67, LR 0.000810:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:10,  1.15s/batch]Training Epoch 67, LR 0.000810:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:07,  1.09batch/s]Training Epoch 67, LR 0.000810:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.32batch/s]Training Epoch 67, LR 0.000810:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.53batch/s]Training Epoch 67, LR 0.000810:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.06s/batch]Training Epoch 67, LR 0.000810:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.15batch/s]Training Epoch 67, LR 0.000810:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.37batch/s]Training Epoch 67, LR 0.000810:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:15<00:01,  1.59batch/s]Training Epoch 67, LR 0.000810:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.03s/batch]Training Epoch 67, LR 0.000810: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.19batch/s]Training Epoch 67, LR 0.000810: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.03batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 67:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 67:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.55s/batch]Evaluating Epoch 67:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.55s/batch]Evaluating Epoch 67:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.10batch/s]Evaluating Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.63batch/s]Evaluating Epoch 67: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [67/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[79, 11],
        [33, 21]], device='cuda:0')
train_accuracy=0.6944444179534912, 
train_recall=0.3888888955116272, 
train_precision=0.65625, 
train_specificity=0.8777777552604675, 
train_balance_acc=0.6333333253860474,
 train_f1_score=0.4883720874786377,
 train_auc=0.681892991065979

Epoch [67/200]:, eval_loss=0.019, 
eval_confusionMatrix:
tensor([[ 0, 19],
        [ 0, 13]], device='cuda:0')
eval_accuracy=0.40625, 
eval_recall=1.0, 
eval_precision=0.40625, 
eval_specificity=0.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.5777778029441833,
 eval_auc=0.6153846383094788


Epoch: 68/200
Training Epoch 68, LR 0.000796:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 68, LR 0.000796:   6%|â–Œ         | 1/18 [00:03<01:05,  3.85s/batch]Training Epoch 68, LR 0.000796:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.82s/batch]Training Epoch 68, LR 0.000796:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 68, LR 0.000796:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 68, LR 0.000796:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:16,  1.28s/batch]Training Epoch 68, LR 0.000796:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.02batch/s]Training Epoch 68, LR 0.000796:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.26batch/s]Training Epoch 68, LR 0.000796:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.49batch/s]Training Epoch 68, LR 0.000796:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.06s/batch]Training Epoch 68, LR 0.000796:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.17batch/s]Training Epoch 68, LR 0.000796:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.39batch/s]Training Epoch 68, LR 0.000796:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.60batch/s]Training Epoch 68, LR 0.000796:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.14s/batch]Training Epoch 68, LR 0.000796:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.09batch/s]Training Epoch 68, LR 0.000796:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.31batch/s]Training Epoch 68, LR 0.000796:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.52batch/s]Training Epoch 68, LR 0.000796:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:01,  1.04s/batch]Training Epoch 68, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.17batch/s]Training Epoch 68, LR 0.000796: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.04batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 68:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 68:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:11,  3.80s/batch]Evaluating Epoch 68:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.66s/batch]Evaluating Epoch 68:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:00,  1.03batch/s]Evaluating Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.54batch/s]Evaluating Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.08s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [68/200]:, train_loss=0.060, 
train_confusionMatrix:
tensor([[77, 14],
        [27, 26]], device='cuda:0')
train_accuracy=0.7152777910232544, 
train_recall=0.49056604504585266, 
train_precision=0.6499999761581421, 
train_specificity=0.8461538553237915, 
train_balance_acc=0.6683599352836609,
 train_f1_score=0.5591397881507874,
 train_auc=0.6562305688858032

Epoch [68/200]:, eval_loss=0.015, 
eval_confusionMatrix:
tensor([[20,  0],
        [12,  0]], device='cuda:0')
eval_accuracy=0.625, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.4125000238418579


Epoch: 69/200
Training Epoch 69, LR 0.000782:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 69, LR 0.000782:   6%|â–Œ         | 1/18 [00:03<01:06,  3.91s/batch]Training Epoch 69, LR 0.000782:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.85s/batch]Training Epoch 69, LR 0.000782:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.19s/batch]Training Epoch 69, LR 0.000782:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.13batch/s]Training Epoch 69, LR 0.000782:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:07<00:17,  1.34s/batch]Training Epoch 69, LR 0.000782:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:12,  1.02s/batch]Training Epoch 69, LR 0.000782:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:08<00:09,  1.22batch/s]Training Epoch 69, LR 0.000782:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.45batch/s]Training Epoch 69, LR 0.000782:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.08s/batch]Training Epoch 69, LR 0.000782:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.15batch/s]Training Epoch 69, LR 0.000782:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:11<00:05,  1.37batch/s]Training Epoch 69, LR 0.000782:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.58batch/s]Training Epoch 69, LR 0.000782:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:13<00:05,  1.02s/batch]Training Epoch 69, LR 0.000782:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:14<00:03,  1.19batch/s]Training Epoch 69, LR 0.000782:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 15/18 [00:14<00:02,  1.42batch/s]Training Epoch 69, LR 0.000782:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:14<00:01,  1.62batch/s]Training Epoch 69, LR 0.000782:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:16<00:00,  1.05batch/s]Training Epoch 69, LR 0.000782: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:16<00:00,  1.25batch/s]Training Epoch 69, LR 0.000782: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:17<00:00,  1.06batch/s]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Evaluating Epoch 69:   0%|          | 0/4 [00:00<?, ?batch/s]Evaluating Epoch 69:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.49s/batch]Evaluating Epoch 69:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.53s/batch]Evaluating Epoch 69:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:00,  1.11batch/s]Evaluating Epoch 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.64batch/s]Evaluating Epoch 69: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01s/batch]
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Input: torch.Size([8, 1, 256])
Epoch [69/200]:, train_loss=0.063, 
train_confusionMatrix:
tensor([[71, 18],
        [33, 22]], device='cuda:0')
train_accuracy=0.6458333134651184, 
train_recall=0.4000000059604645, 
train_precision=0.550000011920929, 
train_specificity=0.7977527976036072, 
train_balance_acc=0.598876416683197,
 train_f1_score=0.46315789222717285,
 train_auc=0.6239019632339478

Epoch [69/200]:, eval_loss=0.016, 
eval_confusionMatrix:
tensor([[19,  0],
        [13,  0]], device='cuda:0')
eval_accuracy=0.59375, 
eval_recall=0.0, 
eval_precision=0.0, 
eval_specificity=1.0, 
eval_balance_acc=0.5,
 eval_f1_score=0.0,
 eval_auc=0.5829959511756897


Epoch: 70/200
Training Epoch 70, LR 0.000767:   0%|          | 0/18 [00:00<?, ?batch/s]Training Epoch 70, LR 0.000767:   6%|â–Œ         | 1/18 [00:03<01:05,  3.87s/batch]Training Epoch 70, LR 0.000767:  11%|â–ˆ         | 2/18 [00:04<00:29,  1.83s/batch]Training Epoch 70, LR 0.000767:  17%|â–ˆâ–‹        | 3/18 [00:04<00:17,  1.18s/batch]Training Epoch 70, LR 0.000767:  22%|â–ˆâ–ˆâ–       | 4/18 [00:05<00:12,  1.14batch/s]Training Epoch 70, LR 0.000767:  28%|â–ˆâ–ˆâ–Š       | 5/18 [00:06<00:16,  1.24s/batch]Training Epoch 70, LR 0.000767:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 6/18 [00:07<00:11,  1.04batch/s]Training Epoch 70, LR 0.000767:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:07<00:08,  1.28batch/s]Training Epoch 70, LR 0.000767:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:08<00:06,  1.51batch/s]Training Epoch 70, LR 0.000767:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:10<00:09,  1.05s/batch]Training Epoch 70, LR 0.000767:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:10<00:06,  1.18batch/s]Training Epoch 70, LR 0.000767:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:10<00:05,  1.40batch/s]Training Epoch 70, LR 0.000767:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:11<00:03,  1.61batch/s]